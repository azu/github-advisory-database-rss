<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://azu.github.io/github-advisory-database-rss/go.rss</id>
    <title>Security Advisory for Go modules</title>
    <updated>2023-11-15T07:01:22.635Z</updated>
    <generator>github-advisory-database-rss</generator>
    <link rel="alternate" href="https://github.com/advisories?query=type%3Areviewed+ecosystem%3Ago"/>
    <subtitle>Security Advisory for Go modules on GitHub</subtitle>
    <rights>github-advisory-database-rss</rights>
    <category term="CRITICAL"/>
    <category term="HIGH"/>
    <category term="MODERATE"/>
    <category term="LOW"/>
    <entry>
        <title type="html"><![CDATA[[k8s.io/kubernetes] Kubernetes Improper Input Validation vulnerability]]></title>
        <id>https://github.com/advisories/GHSA-hq6q-c2x6-hmch</id>
        <link href="https://github.com/advisories/GHSA-hq6q-c2x6-hmch"/>
        <updated>2023-11-14T22:25:08.000Z</updated>
        <content type="html"><![CDATA[<p>A security issue was discovered in Kubernetes where a user that can create pods and persistent volumes on Windows nodes may be able to escalate to admin privileges on those nodes. Kubernetes clusters are only affected if they are using an in-tree storage plugin for Windows nodes.</p>
<h3 id="references">References</h3>
<ul>
<li><a href="https://nvd.nist.gov/vuln/detail/CVE-2023-5528">https://nvd.nist.gov/vuln/detail/CVE-2023-5528</a></li>
<li><a href="https://github.com/kubernetes/kubernetes/issues/121879">https://github.com/kubernetes/kubernetes/issues/121879</a></li>
<li><a href="https://groups.google.com/g/kubernetes-security-announce/c/SL_d4NR8pzA">https://groups.google.com/g/kubernetes-security-announce/c/SL_d4NR8pzA</a></li>
<li><a href="https://github.com/kubernetes/kubernetes/pull/121881">https://github.com/kubernetes/kubernetes/pull/121881</a></li>
<li><a href="https://github.com/kubernetes/kubernetes/pull/121882">https://github.com/kubernetes/kubernetes/pull/121882</a></li>
<li><a href="https://github.com/kubernetes/kubernetes/pull/121883">https://github.com/kubernetes/kubernetes/pull/121883</a></li>
<li><a href="https://github.com/kubernetes/kubernetes/pull/121884">https://github.com/kubernetes/kubernetes/pull/121884</a></li>
<li><a href="https://github.com/kubernetes/kubernetes/pull/121885">https://github.com/kubernetes/kubernetes/pull/121885</a></li>
<li><a href="https://github.com/advisories/GHSA-hq6q-c2x6-hmch">https://github.com/advisories/GHSA-hq6q-c2x6-hmch</a></li>
</ul>
]]></content>
        <author>
            <name>GitHub</name>
            <email>GitHub@noreply.github.com</email>
            <uri>https://github.com/advisories/GHSA-hq6q-c2x6-hmch</uri>
        </author>
        <category label="severity" term="HIGH"/>
        <published>2023-11-14T21:31:03.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[[k8s.io/kubernetes] Kubernetes Improper Input Validation vulnerability]]></title>
        <id>https://github.com/advisories/GHSA-hq6q-c2x6-hmch</id>
        <link href="https://github.com/advisories/GHSA-hq6q-c2x6-hmch"/>
        <updated>2023-11-14T22:25:08.000Z</updated>
        <content type="html"><![CDATA[<p>A security issue was discovered in Kubernetes where a user that can create pods and persistent volumes on Windows nodes may be able to escalate to admin privileges on those nodes. Kubernetes clusters are only affected if they are using an in-tree storage plugin for Windows nodes.</p>
<h3 id="references">References</h3>
<ul>
<li><a href="https://nvd.nist.gov/vuln/detail/CVE-2023-5528">https://nvd.nist.gov/vuln/detail/CVE-2023-5528</a></li>
<li><a href="https://github.com/kubernetes/kubernetes/issues/121879">https://github.com/kubernetes/kubernetes/issues/121879</a></li>
<li><a href="https://groups.google.com/g/kubernetes-security-announce/c/SL_d4NR8pzA">https://groups.google.com/g/kubernetes-security-announce/c/SL_d4NR8pzA</a></li>
<li><a href="https://github.com/kubernetes/kubernetes/pull/121881">https://github.com/kubernetes/kubernetes/pull/121881</a></li>
<li><a href="https://github.com/kubernetes/kubernetes/pull/121882">https://github.com/kubernetes/kubernetes/pull/121882</a></li>
<li><a href="https://github.com/kubernetes/kubernetes/pull/121883">https://github.com/kubernetes/kubernetes/pull/121883</a></li>
<li><a href="https://github.com/kubernetes/kubernetes/pull/121884">https://github.com/kubernetes/kubernetes/pull/121884</a></li>
<li><a href="https://github.com/kubernetes/kubernetes/pull/121885">https://github.com/kubernetes/kubernetes/pull/121885</a></li>
<li><a href="https://github.com/advisories/GHSA-hq6q-c2x6-hmch">https://github.com/advisories/GHSA-hq6q-c2x6-hmch</a></li>
</ul>
]]></content>
        <author>
            <name>GitHub</name>
            <email>GitHub@noreply.github.com</email>
            <uri>https://github.com/advisories/GHSA-hq6q-c2x6-hmch</uri>
        </author>
        <category label="severity" term="HIGH"/>
        <published>2023-11-14T21:31:03.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[[k8s.io/kubernetes] Kubernetes Improper Input Validation vulnerability]]></title>
        <id>https://github.com/advisories/GHSA-hq6q-c2x6-hmch</id>
        <link href="https://github.com/advisories/GHSA-hq6q-c2x6-hmch"/>
        <updated>2023-11-14T22:25:08.000Z</updated>
        <content type="html"><![CDATA[<p>A security issue was discovered in Kubernetes where a user that can create pods and persistent volumes on Windows nodes may be able to escalate to admin privileges on those nodes. Kubernetes clusters are only affected if they are using an in-tree storage plugin for Windows nodes.</p>
<h3 id="references">References</h3>
<ul>
<li><a href="https://nvd.nist.gov/vuln/detail/CVE-2023-5528">https://nvd.nist.gov/vuln/detail/CVE-2023-5528</a></li>
<li><a href="https://github.com/kubernetes/kubernetes/issues/121879">https://github.com/kubernetes/kubernetes/issues/121879</a></li>
<li><a href="https://groups.google.com/g/kubernetes-security-announce/c/SL_d4NR8pzA">https://groups.google.com/g/kubernetes-security-announce/c/SL_d4NR8pzA</a></li>
<li><a href="https://github.com/kubernetes/kubernetes/pull/121881">https://github.com/kubernetes/kubernetes/pull/121881</a></li>
<li><a href="https://github.com/kubernetes/kubernetes/pull/121882">https://github.com/kubernetes/kubernetes/pull/121882</a></li>
<li><a href="https://github.com/kubernetes/kubernetes/pull/121883">https://github.com/kubernetes/kubernetes/pull/121883</a></li>
<li><a href="https://github.com/kubernetes/kubernetes/pull/121884">https://github.com/kubernetes/kubernetes/pull/121884</a></li>
<li><a href="https://github.com/kubernetes/kubernetes/pull/121885">https://github.com/kubernetes/kubernetes/pull/121885</a></li>
<li><a href="https://github.com/advisories/GHSA-hq6q-c2x6-hmch">https://github.com/advisories/GHSA-hq6q-c2x6-hmch</a></li>
</ul>
]]></content>
        <author>
            <name>GitHub</name>
            <email>GitHub@noreply.github.com</email>
            <uri>https://github.com/advisories/GHSA-hq6q-c2x6-hmch</uri>
        </author>
        <category label="severity" term="HIGH"/>
        <published>2023-11-14T21:31:03.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[[k8s.io/kubernetes] Kubernetes Improper Input Validation vulnerability]]></title>
        <id>https://github.com/advisories/GHSA-hq6q-c2x6-hmch</id>
        <link href="https://github.com/advisories/GHSA-hq6q-c2x6-hmch"/>
        <updated>2023-11-14T22:25:08.000Z</updated>
        <content type="html"><![CDATA[<p>A security issue was discovered in Kubernetes where a user that can create pods and persistent volumes on Windows nodes may be able to escalate to admin privileges on those nodes. Kubernetes clusters are only affected if they are using an in-tree storage plugin for Windows nodes.</p>
<h3 id="references">References</h3>
<ul>
<li><a href="https://nvd.nist.gov/vuln/detail/CVE-2023-5528">https://nvd.nist.gov/vuln/detail/CVE-2023-5528</a></li>
<li><a href="https://github.com/kubernetes/kubernetes/issues/121879">https://github.com/kubernetes/kubernetes/issues/121879</a></li>
<li><a href="https://groups.google.com/g/kubernetes-security-announce/c/SL_d4NR8pzA">https://groups.google.com/g/kubernetes-security-announce/c/SL_d4NR8pzA</a></li>
<li><a href="https://github.com/kubernetes/kubernetes/pull/121881">https://github.com/kubernetes/kubernetes/pull/121881</a></li>
<li><a href="https://github.com/kubernetes/kubernetes/pull/121882">https://github.com/kubernetes/kubernetes/pull/121882</a></li>
<li><a href="https://github.com/kubernetes/kubernetes/pull/121883">https://github.com/kubernetes/kubernetes/pull/121883</a></li>
<li><a href="https://github.com/kubernetes/kubernetes/pull/121884">https://github.com/kubernetes/kubernetes/pull/121884</a></li>
<li><a href="https://github.com/kubernetes/kubernetes/pull/121885">https://github.com/kubernetes/kubernetes/pull/121885</a></li>
<li><a href="https://github.com/advisories/GHSA-hq6q-c2x6-hmch">https://github.com/advisories/GHSA-hq6q-c2x6-hmch</a></li>
</ul>
]]></content>
        <author>
            <name>GitHub</name>
            <email>GitHub@noreply.github.com</email>
            <uri>https://github.com/advisories/GHSA-hq6q-c2x6-hmch</uri>
        </author>
        <category label="severity" term="HIGH"/>
        <published>2023-11-14T21:31:03.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[[github.com/kyverno/kyverno] Attacker can cause Kyverno user to unintentionally consume insecure image]]></title>
        <id>https://github.com/advisories/GHSA-3hfq-cx9j-923w</id>
        <link href="https://github.com/advisories/GHSA-3hfq-cx9j-923w"/>
        <updated>2023-11-14T22:20:10.000Z</updated>
        <content type="html"><![CDATA[<p>An issue was found in Kyverno that allowed an attacker to control the digest of images used by Kyverno users. The issue would require the attacker to compromise the registry that the Kyverno fetch their images from. The attacker could then return a vulnerable image to the the user and leverage that to further escalate their position. As such, the attacker would need to know which images the Kyverno user consumes and know of one of multiple exploitable vulnerabilities in previous digests of the images. Alternatively, if the attacker has compromised the registry, they could craft a malicious image with a different digest with intentionally placed vulnerabilities and deliver the image to the user. </p>
<p>An attacker was not be able to control other parameters of the image than the digest by exploiting this vulnerability.</p>
<p>Users pulling their images from trusted registries are not impacted by this vulnerability. There is no evidence of this being exploited in the wild.</p>
<p>The issue has been patched in 1.11.0. </p>
<p>The vulnerability was found during an ongoing security audit of Kyverno conducted by Ada Logics, facilitated by OSTIF and funded by the CNCF.</p>
<p>Members of the community have raised concerns over the similarity between this vulnerability and the one identified with CVE-2023-46737; They are two different issues with two different root causes and different levels of impact. Some differences are:</p>
<ul>
<li>The current advisory (GHSA-3hfq-cx9j-923w) has its root cause in Kyverno whereas the root cause of CVE-2023-46737 is in Cosigns code base. </li>
<li>The impact of the current advisory (GHSA-3hfq-cx9j-923w) is that an attacker can trick Kyverno into consuming a different image than the one the user requested; The impact of CVE-2023-46737 is an endless data attack resulting in a denial-of-service.</li>
<li>The fix of the current advisory (GHSA-3hfq-cx9j-923w) does not result in users being secure from CVE-2023-46737 and vice versa.</li>
</ul>
<h3 id="references">References</h3>
<ul>
<li><a href="https://github.com/kyverno/kyverno/security/advisories/GHSA-3hfq-cx9j-923w">https://github.com/kyverno/kyverno/security/advisories/GHSA-3hfq-cx9j-923w</a></li>
<li><a href="https://nvd.nist.gov/vuln/detail/CVE-2023-47630">https://nvd.nist.gov/vuln/detail/CVE-2023-47630</a></li>
<li><a href="https://github.com/kyverno/kyverno/releases/tag/v1.11.0">https://github.com/kyverno/kyverno/releases/tag/v1.11.0</a></li>
<li><a href="https://github.com/advisories/GHSA-3hfq-cx9j-923w">https://github.com/advisories/GHSA-3hfq-cx9j-923w</a></li>
</ul>
]]></content>
        <author>
            <name>GitHub</name>
            <email>GitHub@noreply.github.com</email>
            <uri>https://github.com/advisories/GHSA-3hfq-cx9j-923w</uri>
        </author>
        <category label="severity" term="HIGH"/>
        <published>2023-11-14T22:20:09.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[[github.com/juanfont/headscale] Headscale writes bearer tokens to info-level logs]]></title>
        <id>https://github.com/advisories/GHSA-wp76-cf2j-rqq7</id>
        <link href="https://github.com/advisories/GHSA-wp76-cf2j-rqq7"/>
        <updated>2023-11-14T20:35:08.000Z</updated>
        <content type="html"><![CDATA[<p>Headscale through 0.22.3 writes bearer tokens to info-level logs.</p>
<h3 id="references">References</h3>
<ul>
<li><a href="https://nvd.nist.gov/vuln/detail/CVE-2023-47390">https://nvd.nist.gov/vuln/detail/CVE-2023-47390</a></li>
<li><a href="https://github.com/juanfont/headscale/issues/1259">https://github.com/juanfont/headscale/issues/1259</a></li>
<li><a href="https://github.com/advisories/GHSA-wp76-cf2j-rqq7">https://github.com/advisories/GHSA-wp76-cf2j-rqq7</a></li>
</ul>
]]></content>
        <author>
            <name>GitHub</name>
            <email>GitHub@noreply.github.com</email>
            <uri>https://github.com/advisories/GHSA-wp76-cf2j-rqq7</uri>
        </author>
        <category label="severity" term="MODERATE"/>
        <published>2023-11-11T18:30:25.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[[github.com/sigstore/gitsign] Gitsign's Rekor public keys fetched from upstream API instead of local TUF client.]]></title>
        <id>https://github.com/advisories/GHSA-xvrc-2wvh-49vc</id>
        <link href="https://github.com/advisories/GHSA-xvrc-2wvh-49vc"/>
        <updated>2023-11-14T20:31:24.000Z</updated>
        <content type="html"><![CDATA[<h3 id="impact">Impact</h3>
<p>In certain versions of gitsign, Rekor public keys were fetched via the Rekor API, instead of through the local TUF client. If the upstream Rekor server happened to be compromised, gitsign clients could potentially be tricked into trusting incorrect signatures.</p>
<p>There is no known compromise the default public good instance (<code>rekor.sigstore.dev</code>) - anyone using this instance is unlikely to be affected.</p>
<h3 id="patches">Patches</h3>
<p>This was fixed in v0.8.0 via <a href="https://github.com/sigstore/gitsign/pull/399">https://github.com/sigstore/gitsign/pull/399</a></p>
<h3 id="workarounds">Workarounds</h3>
<p>n/a</p>
<h3 id="references">References</h3>
<p><em>Are there any links users can visit to find out more?</em></p>
<p><a href="https://docs.sigstore.dev/about/threat-model/#sigstore-threat-model">https://docs.sigstore.dev/about/threat-model/#sigstore-threat-model</a></p>
<h3 id="references-1">References</h3>
<ul>
<li><a href="https://github.com/sigstore/gitsign/security/advisories/GHSA-xvrc-2wvh-49vc">https://github.com/sigstore/gitsign/security/advisories/GHSA-xvrc-2wvh-49vc</a></li>
<li><a href="https://nvd.nist.gov/vuln/detail/CVE-2023-47122">https://nvd.nist.gov/vuln/detail/CVE-2023-47122</a></li>
<li><a href="https://github.com/sigstore/gitsign/pull/399">https://github.com/sigstore/gitsign/pull/399</a></li>
<li><a href="https://github.com/sigstore/gitsign/commit/cd66ccb03c86a3600955f0c15f6bfeb75f697236">https://github.com/sigstore/gitsign/commit/cd66ccb03c86a3600955f0c15f6bfeb75f697236</a></li>
<li><a href="https://docs.sigstore.dev/about/threat-model/#sigstore-threat-model">https://docs.sigstore.dev/about/threat-model/#sigstore-threat-model</a></li>
<li><a href="https://github.com/advisories/GHSA-xvrc-2wvh-49vc">https://github.com/advisories/GHSA-xvrc-2wvh-49vc</a></li>
</ul>
]]></content>
        <author>
            <name>GitHub</name>
            <email>GitHub@noreply.github.com</email>
            <uri>https://github.com/advisories/GHSA-xvrc-2wvh-49vc</uri>
        </author>
        <category label="severity" term="MODERATE"/>
        <published>2023-11-14T20:31:23.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[[github.com/hyperledger/fabric] Fabric vulnerable to crosslinking transaction attack]]></title>
        <id>https://github.com/advisories/GHSA-v9w2-543f-h69m</id>
        <link href="https://github.com/advisories/GHSA-v9w2-543f-h69m"/>
        <updated>2023-11-14T21:37:11.000Z</updated>
        <content type="html"><![CDATA[<h1 id="short-summary">Short summary</h1>
<p>Combining two molecules to one another, called "cross-linking" results in a molecule with a chemical formula that is composed of all atoms of the original two molecules. </p>
<p>In Fabric, one can take a block of transactions and cross-link the transactions in a way that alters the way the peers parse the transactions. If a first peer receives a block <code>B</code> and a second peer receives a block identical to <code>B</code> but with the transactions being cross-linked, the second peer will parse transactions in a different way and thus its world state will deviate from the first peer. </p>
<p>Orderers or peers cannot detect that a block has its transactions cross-linked, because there is a vulnerability in the way Fabric hashes the transactions of blocks. It simply and naively concatenates them, which is insecure and lets an adversary craft a "cross-linked block" (block with cross-linked transactions) which alters the way peers process transactions. 
For example, it is possible to select a transaction and manipulate a peer to completely avoid processing it, without changing the computed hash of the block.</p>
<p>Additional validations have been added in v2.2.14 and v2.5.5 to detect potential cross-linking issues before processing blocks.</p>
<h2 id="impact">Impact</h2>
<p>In V1 and V2, we only have a crash fault tolerant orderer and as such, the security model Fabric operates in is that the orderer is honest,
but peers may be malicious. As such, a peer that replicates a block from a malicious peer can have a state fork.</p>
<p>In V3 which we did not a release a GA yet (only a preview), we have a byzantine fault tolerant orderering service, so the security model that Fabric operates in such a case includes malicious orderers. If the orderer is malicious, it can cause state forks for peers, and can infect non-malicious orderers with cross-linked blocks.</p>
<h1 id="long-summary">Long summary</h1>
<p>In order to create a signature on a big chunk of data  such as a block, the data needs to be "compressed" first to the input size of the signature algorithm.</p>
<p>In Fabric's case, we use a hash function which compressed a Fabric block from arbitrary size to a 32 byte string.</p>
<p>In order to understand the problem we need to be more specific: The block structure has three parts to it: (1) Header, (2) Transactions, and (3) Metadata.</p>
<p>When hashing the block, the header and metadata are stitched together and then hashed, and this hash of the header and the metadata is what signed (it's a simplification but let's not get into details)</p>
<p>However, the transactions of the block are not part of the above hash. Instead, the header contains a hash, called the "Data hash" and despite the fact that in the comments it is said: "// The hash of the BlockData, by MerkleTree", actually it is far from being the case, and that is where our problem lies.</p>
<p>The problem is that the way the transactions are hashed gives an attacker some freedom in manipulating the data. </p>
<p>To create the Data Hash, the transactions in the block are concatenated to one another, creating a big long byte array and then this big long byte array is hashed, and this is essentially the Data Hash.</p>
<p>The transactions in the block are a list of raw byte arrays, and when they are concatenated they look like this:</p>
<p><code>|$$$$$$$$$$$$|*************|@@@@@@@@@@@@|%%%%%%%%%|</code>  (The vertical lines " | " represent how transactions are separated in a block.)</p>
<p>When the transactions are concatenated in order to be hashed, the payload that is hashed is: 
<code>$$$$$$$$$$$$*************@@@@@@@@@@@@%%%%%%%%%</code></p>
<p>An adversary can't change the bytes of the concatenation, however what it can do, is to modify how transactions are encoded in the block:</p>
<p>For example, consider an adversary wants to manipulate a peer to skip the second transaction (******).</p>
<p>It can then create a block with the transactions as follows:</p>
<p><code>|$$$$$$$$$$$$*************|@@@@@@@@@@@@|%%%%%%%%%| </code></p>
<p>Notice that a block with the above transactions has the same concatenation of bytes as the original block, but the block has one less transaction - the first transaction is a concatenation of the first and second transactions in the original block.</p>
<p>When the peer receives this block, it looks at the first transaction and when it parses it, it completely ignores the ***** bytes, (we will see why soon), and so, an adversary can create a block with the same hash but different transactions and this would create a fork in the network.</p>
<p>I made a small PoC where I created a block with 2 transactions (by invoking two chaincodes at the same time) with a Raft orderer:</p>
<pre><code>    [e][OrdererOrg.orderer] 2023-10-14 23:07:34.076 CEST 0079 INFO [orderer.consensus.etcdraft] propose -&gt; Created block [10] with 2 transactions, there are 0 blocks in flight channel=testchannel node=1
</code></pre>
<p>But right after creating the block, I just modified only its transaction content (without modifying the block hash) and then the peers only detect a single transaction inside that block:</p>
<pre><code>    [e][Org2.peer0] 2023-10-14 23:07:34.079 CEST 0099 INFO [kvledger] commit -&gt; [testchannel] Committed block [10] with 1 transaction(s) in 0ms (state_validation=0ms block_and_pvtdata_commit=0ms state_commit=0ms) commitHash=[c5ecca818da9319af2f276dd01cd1337938f20c3535dd23f95a33933a114fe84]
</code></pre>
<p>The important takeaway from this experiment is that the peer does not detect any tempering was done to the block. If an attacker performs this attack, the network can be forked silently and no one will notice the network was forked until it's too late.</p>
<h1 id="patches">Patches</h1>
<p>Here is the patch I propose (the explanation is further below): </p>
<pre><code>diff --git a/internal/peer/gossip/mcs.go b/internal/peer/gossip/mcs.go
index b46df8b6a..9c3b5c8fd 100644
--- a/internal/peer/gossip/mcs.go
+++ b/internal/peer/gossip/mcs.go
@@ -150,6 +150,10 @@ func (s *MSPMessageCryptoService) VerifyBlock(chainID common.ChannelID, seqNum u
         return fmt.Errorf("Block with id [%d] on channel [%s] does not have metadata. Block not valid.", block.Header.Number, chainID)
     }
 
+	if err := protoutil.VerifyTransactionsAreWellFormed(block); err != nil {
+		return err
+	}
+
     // - Verify that Header.DataHash is equal to the hash of block.Data
     // This is to ensure that the header is consistent with the data carried by this block
     if !bytes.Equal(protoutil.BlockDataHash(block.Data), block.Header.DataHash) {
diff --git a/orderer/common/cluster/util.go b/orderer/common/cluster/util.go
index e229bebfc..05b1bfaa9 100644
--- a/orderer/common/cluster/util.go
+++ b/orderer/common/cluster/util.go
@@ -260,6 +260,9 @@ func VerifyBlockHash(indexInBuffer int, blockBuff []*common.Block) error {
     if block.Header == nil {
         return errors.New("missing block header")
     }
+	if err := protoutil.VerifyTransactionsAreWellFormed(block); err != nil {
+		return err
+	}
     seq := block.Header.Number
     dataHash := protoutil.BlockDataHash(block.Data)
     // Verify data hash matches the hash in the header
diff --git a/orderer/consensus/smartbft/verifier.go b/orderer/consensus/smartbft/verifier.go
index 2b9fdfc4c..f232a1eae 100644
--- a/orderer/consensus/smartbft/verifier.go
+++ b/orderer/consensus/smartbft/verifier.go
@@ -237,6 +237,10 @@ func verifyHashChain(block *cb.Block, prevHeaderHash string) error {
         return errors.Errorf("previous header hash is %s but expected %s", thisHdrHashOfPrevHdr, prevHeaderHash)
     }
 
+	if err := protoutil.VerifyTransactionsAreWellFormed(block); err != nil {
+		return err
+	}
+
     dataHash := hex.EncodeToString(block.Header.DataHash)
     actualHashOfData := hex.EncodeToString(protoutil.BlockDataHash(block.Data))
     if dataHash != actualHashOfData {
diff --git a/protoutil/blockutils.go b/protoutil/blockutils.go
index 8527869e4..fca3c386f 100644
--- a/protoutil/blockutils.go
+++ b/protoutil/blockutils.go
@@ -10,6 +10,7 @@ import (
     "bytes"
     "crypto/sha256"
     "encoding/asn1"
+	"encoding/base64"
     "fmt"
     "math/big"
 
@@ -298,3 +299,35 @@ func searchConsenterIdentityByID(consenters []*cb.Consenter, identifier uint32)
     }
     return nil
 }
+
+func VerifyTransactionsAreWellFormed(block *cb.Block) error {
+	if block == nil || block.Data == nil || len(block.Data.Data) == 0 {
+		return nil
+	}
+
+	for i, rawTx := range block.Data.Data {
+		env := &amp;cb.Envelope{}
+		if err := proto.Unmarshal(rawTx, env); err != nil {
+			return fmt.Errorf("transaction %d is invalid: %v", i, err)
+		}
+
+		if len(env.Payload) == 0 {
+			return fmt.Errorf("transaction %d has no payload", i)
+		}
+
+		if len(env.Signature) == 0 {
+			return fmt.Errorf("transaction %d has no signature", i)
+		}
+
+		expected := MarshalOrPanic(env)
+		if len(expected) &lt; len(rawTx) {
+			return fmt.Errorf("transaction %d has %d trailing bytes", i, len(rawTx)-len(expected))
+		}
+		if !bytes.Equal(expected, rawTx) {
+			return fmt.Errorf("transaction %d (%s) does not match its raw form (%s)", i,
+				base64.StdEncoding.EncodeToString(expected), base64.StdEncoding.EncodeToString(rawTx))
+		}
+	}
+
+	return nil
+}
diff --git a/protoutil/blockutils_test.go b/protoutil/blockutils_test.go
index b2159da9f..2871483f1 100644
--- a/protoutil/blockutils_test.go
+++ b/protoutil/blockutils_test.go
@@ -489,3 +489,109 @@ func TestBlockSignatureVerifierByCreator(t *testing.T) {
     require.Len(t, signatureSet, 1)
     require.Equal(t, []byte("creator1"), signatureSet[0].Identity)
 }
+
+func TestVerifyTransactionsAreWellFormed(t *testing.T) {
+	originalBlock := &amp;cb.Block{
+		Data: &amp;cb.BlockData{
+			Data: [][]byte{
+				marshalOrPanic(&amp;cb.Envelope{
+					Payload:   []byte{1, 2, 3},
+					Signature: []byte{4, 5, 6},
+				}),
+				marshalOrPanic(&amp;cb.Envelope{
+					Payload:   []byte{7, 8, 9},
+					Signature: []byte{10, 11, 12},
+				}),
+			},
+		},
+	}
+
+	forgedBlock := proto.Clone(originalBlock).(*cb.Block)
+	tmp := make([]byte, len(forgedBlock.Data.Data[0])+len(forgedBlock.Data.Data[1]))
+	copy(tmp, forgedBlock.Data.Data[0])
+	copy(tmp[len(forgedBlock.Data.Data[0]):], forgedBlock.Data.Data[1])
+	forgedBlock.Data.Data = [][]byte{tmp} // Replace transactions {0,1} with transaction {0 || 1}
+
+	for _, tst := range []struct {
+		name          string
+		expectedError string
+		block         *cb.Block
+	}{
+		{
+			name: "empty block",
+		},
+		{
+			name:  "no block data",
+			block: &amp;cb.Block{},
+		},
+		{
+			name:  "no transactions",
+			block: &amp;cb.Block{Data: &amp;cb.BlockData{}},
+		},
+		{
+			name: "single transaction",
+			block: &amp;cb.Block{Data: &amp;cb.BlockData{Data: [][]byte{marshalOrPanic(&amp;cb.Envelope{
+				Payload:   []byte{1, 2, 3},
+				Signature: []byte{4, 5, 6},
+			})}}},
+		},
+		{
+			name:  "good block",
+			block: originalBlock,
+		},
+		{
+			name:          "forged block",
+			block:         forgedBlock,
+			expectedError: "transaction 0 has 10 trailing bytes",
+		},
+		{
+			name:          "no signature",
+			expectedError: "transaction 0 has no signature",
+			block: &amp;cb.Block{
+				Data: &amp;cb.BlockData{
+					Data: [][]byte{
+						marshalOrPanic(&amp;cb.Envelope{
+							Payload: []byte{1, 2, 3},
+						}),
+					},
+				},
+			},
+		},
+		{
+			name:          "no payload",
+			expectedError: "transaction 0 has no payload",
+			block: &amp;cb.Block{
+				Data: &amp;cb.BlockData{
+					Data: [][]byte{
+						marshalOrPanic(&amp;cb.Envelope{
+							Signature: []byte{4, 5, 6},
+						}),
+					},
+				},
+			},
+		},
+		{
+			name:          "transaction invalid",
+			expectedError: "transaction 0 is invalid: proto: cannot parse invalid wire-format data",
+			block: &amp;cb.Block{
+				Data: &amp;cb.BlockData{
+					Data: [][]byte{
+						marshalOrPanic(&amp;cb.Envelope{
+							Payload:   []byte{1, 2, 3},
+							Signature: []byte{4, 5, 6},
+						})[9:],
+					},
+				},
+			},
+		},
+	} {
+		t.Run(tst.name, func(t *testing.T) {
+			err := protoutil.VerifyTransactionsAreWellFormed(tst.block)
+			if tst.expectedError == "" {
+				require.NoError(t, err)
+			} else {
+				require.EqualError(t, err, tst.expectedError)
+			}
+		})
+	}
+}
</code></pre>
<p>The idea is as follows:</p>
<p>When we validate that the block's transactions match the hash in the header, we not only hash the transactions are earlier, </p>
<p>but also ensure that if the transactions in the block are encoded into bytes, they re-create the exact split in the original block: <code>|$$$$$$$$$$$$|***********|@@@@@@@@@|%%%%%%%%%%%|</code></p>
<p>More specifically, each transaction in the block is parsed and then re-encoded to bytes, and we check that the original encoding of a transaction is as the second encoding after parsing the original bytes of the transaction.</p>
<p>This fix keeps the legacy way of hashing transactions to create the block data hash, but also aims to check if some manipulation was done.</p>
<p>To understand why the fix works, we need to understand how protobuf, the wire protocol that Fabric uses to encode transactions (and almost anything it sends over the wire or writes to disk) encodes a transaction.</p>
<p>A transaction is a protobuf message with two fields of bytes: (1) Payload and (2) Signature.</p>
<p>When encoding a field of bytes, protobuf first writes a tag for the field (a byte) and then writes the length of the field in variable-length encoding, and then the bytes themselves.</p>
<p>For example, to encode a transaction, protobuf writes 10 (the tag for payload), then two bytes for the length of the payload, then the payload, and then 18, the tag for the signature, and then a single byte for the length of the signature, and finally the signature.</p>
<p>Now, we can understand a proof sketch of why my solution works:</p>
<p>Assume in contradiction that an adversary takes a block of transactions and changes the split of the concatenation in a way that changes the transactions for a peer:</p>
<p>From <code>|$$$$$$$$$$$$|************|@@@@@@@@@@@|...|%%%%%%%|</code> to (for example): From <code>|$$$$$$$$$$$$************|@@@@@@@@@@@|...|%%%%%%%|</code> </p>
<p>Since this split is not identical to the original split, there exists at least one transaction index of different size between the two splits. Let's look at the first transaction that is of different size.</p>
<p>For example, for the split:</p>
<p><code>|$$$$$$$$$$$$|************|@@@@@@@@@@@|...|%%%%%%%|</code>  we have two options:</p>
<ol>
<li><p>The first transaction of different size is smaller in the new split:  <code>|$$$$$$$$$$$$|*****|*******|@@@@@@@@@@@|...|%%%%%%%|</code>  In such a case, it must contain both a payload and a signature, so it needs two fields (we can say we will return an error if one of the two is missing). If the protobuf parser detects it lacks bytes to parse a payload, it will fail with an error. Else, it has enough bytes to parse the payload, and then the signature is parsed. If the signature field is too short then we also error similarly.</p>
</li>
<li><p>The first transaction of different size is bigger in the new split: <code>|$$$$$$$$$$$$|************@@@@|@@@@@@@|...|%%%%%%%|</code> 
In that case, once this transaction is parsed, the extra bytes are skipped, so encoding the transaction to bytes yields a shorter byte array, and we detect a tempering.</p>
</li>
</ol>
<h3 id="references">References</h3>
<ul>
<li><a href="https://github.com/hyperledger/fabric/security/advisories/GHSA-v9w2-543f-h69m">https://github.com/hyperledger/fabric/security/advisories/GHSA-v9w2-543f-h69m</a></li>
<li><a href="https://github.com/hyperledger/fabric/pull/4503">https://github.com/hyperledger/fabric/pull/4503</a></li>
<li><a href="https://github.com/hyperledger/fabric/pull/4504">https://github.com/hyperledger/fabric/pull/4504</a></li>
<li><a href="https://github.com/hyperledger/fabric/commit/389b2e66de9a6fbc6043216d554c97bbbdf0e008">https://github.com/hyperledger/fabric/commit/389b2e66de9a6fbc6043216d554c97bbbdf0e008</a></li>
<li><a href="https://github.com/hyperledger/fabric/commit/93bef10bd3ce3c54d7f3b064f765dbde61da7def">https://github.com/hyperledger/fabric/commit/93bef10bd3ce3c54d7f3b064f765dbde61da7def</a></li>
<li><a href="https://github.com/hyperledger/fabric/releases/tag/v2.2.14">https://github.com/hyperledger/fabric/releases/tag/v2.2.14</a></li>
<li><a href="https://github.com/hyperledger/fabric/releases/tag/v2.5.5">https://github.com/hyperledger/fabric/releases/tag/v2.5.5</a></li>
<li><a href="https://nvd.nist.gov/vuln/detail/CVE-2023-46132">https://nvd.nist.gov/vuln/detail/CVE-2023-46132</a></li>
<li><a href="https://github.com/advisories/GHSA-v9w2-543f-h69m">https://github.com/advisories/GHSA-v9w2-543f-h69m</a></li>
</ul>
]]></content>
        <author>
            <name>GitHub</name>
            <email>GitHub@noreply.github.com</email>
            <uri>https://github.com/advisories/GHSA-v9w2-543f-h69m</uri>
        </author>
        <category label="severity" term="HIGH"/>
        <published>2023-11-14T20:28:34.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[[github.com/hyperledger/fabric] Fabric vulnerable to crosslinking transaction attack]]></title>
        <id>https://github.com/advisories/GHSA-v9w2-543f-h69m</id>
        <link href="https://github.com/advisories/GHSA-v9w2-543f-h69m"/>
        <updated>2023-11-14T21:37:11.000Z</updated>
        <content type="html"><![CDATA[<h1 id="short-summary">Short summary</h1>
<p>Combining two molecules to one another, called "cross-linking" results in a molecule with a chemical formula that is composed of all atoms of the original two molecules. </p>
<p>In Fabric, one can take a block of transactions and cross-link the transactions in a way that alters the way the peers parse the transactions. If a first peer receives a block <code>B</code> and a second peer receives a block identical to <code>B</code> but with the transactions being cross-linked, the second peer will parse transactions in a different way and thus its world state will deviate from the first peer. </p>
<p>Orderers or peers cannot detect that a block has its transactions cross-linked, because there is a vulnerability in the way Fabric hashes the transactions of blocks. It simply and naively concatenates them, which is insecure and lets an adversary craft a "cross-linked block" (block with cross-linked transactions) which alters the way peers process transactions. 
For example, it is possible to select a transaction and manipulate a peer to completely avoid processing it, without changing the computed hash of the block.</p>
<p>Additional validations have been added in v2.2.14 and v2.5.5 to detect potential cross-linking issues before processing blocks.</p>
<h2 id="impact">Impact</h2>
<p>In V1 and V2, we only have a crash fault tolerant orderer and as such, the security model Fabric operates in is that the orderer is honest,
but peers may be malicious. As such, a peer that replicates a block from a malicious peer can have a state fork.</p>
<p>In V3 which we did not a release a GA yet (only a preview), we have a byzantine fault tolerant orderering service, so the security model that Fabric operates in such a case includes malicious orderers. If the orderer is malicious, it can cause state forks for peers, and can infect non-malicious orderers with cross-linked blocks.</p>
<h1 id="long-summary">Long summary</h1>
<p>In order to create a signature on a big chunk of data  such as a block, the data needs to be "compressed" first to the input size of the signature algorithm.</p>
<p>In Fabric's case, we use a hash function which compressed a Fabric block from arbitrary size to a 32 byte string.</p>
<p>In order to understand the problem we need to be more specific: The block structure has three parts to it: (1) Header, (2) Transactions, and (3) Metadata.</p>
<p>When hashing the block, the header and metadata are stitched together and then hashed, and this hash of the header and the metadata is what signed (it's a simplification but let's not get into details)</p>
<p>However, the transactions of the block are not part of the above hash. Instead, the header contains a hash, called the "Data hash" and despite the fact that in the comments it is said: "// The hash of the BlockData, by MerkleTree", actually it is far from being the case, and that is where our problem lies.</p>
<p>The problem is that the way the transactions are hashed gives an attacker some freedom in manipulating the data. </p>
<p>To create the Data Hash, the transactions in the block are concatenated to one another, creating a big long byte array and then this big long byte array is hashed, and this is essentially the Data Hash.</p>
<p>The transactions in the block are a list of raw byte arrays, and when they are concatenated they look like this:</p>
<p><code>|$$$$$$$$$$$$|*************|@@@@@@@@@@@@|%%%%%%%%%|</code>  (The vertical lines " | " represent how transactions are separated in a block.)</p>
<p>When the transactions are concatenated in order to be hashed, the payload that is hashed is: 
<code>$$$$$$$$$$$$*************@@@@@@@@@@@@%%%%%%%%%</code></p>
<p>An adversary can't change the bytes of the concatenation, however what it can do, is to modify how transactions are encoded in the block:</p>
<p>For example, consider an adversary wants to manipulate a peer to skip the second transaction (******).</p>
<p>It can then create a block with the transactions as follows:</p>
<p><code>|$$$$$$$$$$$$*************|@@@@@@@@@@@@|%%%%%%%%%| </code></p>
<p>Notice that a block with the above transactions has the same concatenation of bytes as the original block, but the block has one less transaction - the first transaction is a concatenation of the first and second transactions in the original block.</p>
<p>When the peer receives this block, it looks at the first transaction and when it parses it, it completely ignores the ***** bytes, (we will see why soon), and so, an adversary can create a block with the same hash but different transactions and this would create a fork in the network.</p>
<p>I made a small PoC where I created a block with 2 transactions (by invoking two chaincodes at the same time) with a Raft orderer:</p>
<pre><code>    [e][OrdererOrg.orderer] 2023-10-14 23:07:34.076 CEST 0079 INFO [orderer.consensus.etcdraft] propose -&gt; Created block [10] with 2 transactions, there are 0 blocks in flight channel=testchannel node=1
</code></pre>
<p>But right after creating the block, I just modified only its transaction content (without modifying the block hash) and then the peers only detect a single transaction inside that block:</p>
<pre><code>    [e][Org2.peer0] 2023-10-14 23:07:34.079 CEST 0099 INFO [kvledger] commit -&gt; [testchannel] Committed block [10] with 1 transaction(s) in 0ms (state_validation=0ms block_and_pvtdata_commit=0ms state_commit=0ms) commitHash=[c5ecca818da9319af2f276dd01cd1337938f20c3535dd23f95a33933a114fe84]
</code></pre>
<p>The important takeaway from this experiment is that the peer does not detect any tempering was done to the block. If an attacker performs this attack, the network can be forked silently and no one will notice the network was forked until it's too late.</p>
<h1 id="patches">Patches</h1>
<p>Here is the patch I propose (the explanation is further below): </p>
<pre><code>diff --git a/internal/peer/gossip/mcs.go b/internal/peer/gossip/mcs.go
index b46df8b6a..9c3b5c8fd 100644
--- a/internal/peer/gossip/mcs.go
+++ b/internal/peer/gossip/mcs.go
@@ -150,6 +150,10 @@ func (s *MSPMessageCryptoService) VerifyBlock(chainID common.ChannelID, seqNum u
         return fmt.Errorf("Block with id [%d] on channel [%s] does not have metadata. Block not valid.", block.Header.Number, chainID)
     }
 
+	if err := protoutil.VerifyTransactionsAreWellFormed(block); err != nil {
+		return err
+	}
+
     // - Verify that Header.DataHash is equal to the hash of block.Data
     // This is to ensure that the header is consistent with the data carried by this block
     if !bytes.Equal(protoutil.BlockDataHash(block.Data), block.Header.DataHash) {
diff --git a/orderer/common/cluster/util.go b/orderer/common/cluster/util.go
index e229bebfc..05b1bfaa9 100644
--- a/orderer/common/cluster/util.go
+++ b/orderer/common/cluster/util.go
@@ -260,6 +260,9 @@ func VerifyBlockHash(indexInBuffer int, blockBuff []*common.Block) error {
     if block.Header == nil {
         return errors.New("missing block header")
     }
+	if err := protoutil.VerifyTransactionsAreWellFormed(block); err != nil {
+		return err
+	}
     seq := block.Header.Number
     dataHash := protoutil.BlockDataHash(block.Data)
     // Verify data hash matches the hash in the header
diff --git a/orderer/consensus/smartbft/verifier.go b/orderer/consensus/smartbft/verifier.go
index 2b9fdfc4c..f232a1eae 100644
--- a/orderer/consensus/smartbft/verifier.go
+++ b/orderer/consensus/smartbft/verifier.go
@@ -237,6 +237,10 @@ func verifyHashChain(block *cb.Block, prevHeaderHash string) error {
         return errors.Errorf("previous header hash is %s but expected %s", thisHdrHashOfPrevHdr, prevHeaderHash)
     }
 
+	if err := protoutil.VerifyTransactionsAreWellFormed(block); err != nil {
+		return err
+	}
+
     dataHash := hex.EncodeToString(block.Header.DataHash)
     actualHashOfData := hex.EncodeToString(protoutil.BlockDataHash(block.Data))
     if dataHash != actualHashOfData {
diff --git a/protoutil/blockutils.go b/protoutil/blockutils.go
index 8527869e4..fca3c386f 100644
--- a/protoutil/blockutils.go
+++ b/protoutil/blockutils.go
@@ -10,6 +10,7 @@ import (
     "bytes"
     "crypto/sha256"
     "encoding/asn1"
+	"encoding/base64"
     "fmt"
     "math/big"
 
@@ -298,3 +299,35 @@ func searchConsenterIdentityByID(consenters []*cb.Consenter, identifier uint32)
     }
     return nil
 }
+
+func VerifyTransactionsAreWellFormed(block *cb.Block) error {
+	if block == nil || block.Data == nil || len(block.Data.Data) == 0 {
+		return nil
+	}
+
+	for i, rawTx := range block.Data.Data {
+		env := &amp;cb.Envelope{}
+		if err := proto.Unmarshal(rawTx, env); err != nil {
+			return fmt.Errorf("transaction %d is invalid: %v", i, err)
+		}
+
+		if len(env.Payload) == 0 {
+			return fmt.Errorf("transaction %d has no payload", i)
+		}
+
+		if len(env.Signature) == 0 {
+			return fmt.Errorf("transaction %d has no signature", i)
+		}
+
+		expected := MarshalOrPanic(env)
+		if len(expected) &lt; len(rawTx) {
+			return fmt.Errorf("transaction %d has %d trailing bytes", i, len(rawTx)-len(expected))
+		}
+		if !bytes.Equal(expected, rawTx) {
+			return fmt.Errorf("transaction %d (%s) does not match its raw form (%s)", i,
+				base64.StdEncoding.EncodeToString(expected), base64.StdEncoding.EncodeToString(rawTx))
+		}
+	}
+
+	return nil
+}
diff --git a/protoutil/blockutils_test.go b/protoutil/blockutils_test.go
index b2159da9f..2871483f1 100644
--- a/protoutil/blockutils_test.go
+++ b/protoutil/blockutils_test.go
@@ -489,3 +489,109 @@ func TestBlockSignatureVerifierByCreator(t *testing.T) {
     require.Len(t, signatureSet, 1)
     require.Equal(t, []byte("creator1"), signatureSet[0].Identity)
 }
+
+func TestVerifyTransactionsAreWellFormed(t *testing.T) {
+	originalBlock := &amp;cb.Block{
+		Data: &amp;cb.BlockData{
+			Data: [][]byte{
+				marshalOrPanic(&amp;cb.Envelope{
+					Payload:   []byte{1, 2, 3},
+					Signature: []byte{4, 5, 6},
+				}),
+				marshalOrPanic(&amp;cb.Envelope{
+					Payload:   []byte{7, 8, 9},
+					Signature: []byte{10, 11, 12},
+				}),
+			},
+		},
+	}
+
+	forgedBlock := proto.Clone(originalBlock).(*cb.Block)
+	tmp := make([]byte, len(forgedBlock.Data.Data[0])+len(forgedBlock.Data.Data[1]))
+	copy(tmp, forgedBlock.Data.Data[0])
+	copy(tmp[len(forgedBlock.Data.Data[0]):], forgedBlock.Data.Data[1])
+	forgedBlock.Data.Data = [][]byte{tmp} // Replace transactions {0,1} with transaction {0 || 1}
+
+	for _, tst := range []struct {
+		name          string
+		expectedError string
+		block         *cb.Block
+	}{
+		{
+			name: "empty block",
+		},
+		{
+			name:  "no block data",
+			block: &amp;cb.Block{},
+		},
+		{
+			name:  "no transactions",
+			block: &amp;cb.Block{Data: &amp;cb.BlockData{}},
+		},
+		{
+			name: "single transaction",
+			block: &amp;cb.Block{Data: &amp;cb.BlockData{Data: [][]byte{marshalOrPanic(&amp;cb.Envelope{
+				Payload:   []byte{1, 2, 3},
+				Signature: []byte{4, 5, 6},
+			})}}},
+		},
+		{
+			name:  "good block",
+			block: originalBlock,
+		},
+		{
+			name:          "forged block",
+			block:         forgedBlock,
+			expectedError: "transaction 0 has 10 trailing bytes",
+		},
+		{
+			name:          "no signature",
+			expectedError: "transaction 0 has no signature",
+			block: &amp;cb.Block{
+				Data: &amp;cb.BlockData{
+					Data: [][]byte{
+						marshalOrPanic(&amp;cb.Envelope{
+							Payload: []byte{1, 2, 3},
+						}),
+					},
+				},
+			},
+		},
+		{
+			name:          "no payload",
+			expectedError: "transaction 0 has no payload",
+			block: &amp;cb.Block{
+				Data: &amp;cb.BlockData{
+					Data: [][]byte{
+						marshalOrPanic(&amp;cb.Envelope{
+							Signature: []byte{4, 5, 6},
+						}),
+					},
+				},
+			},
+		},
+		{
+			name:          "transaction invalid",
+			expectedError: "transaction 0 is invalid: proto: cannot parse invalid wire-format data",
+			block: &amp;cb.Block{
+				Data: &amp;cb.BlockData{
+					Data: [][]byte{
+						marshalOrPanic(&amp;cb.Envelope{
+							Payload:   []byte{1, 2, 3},
+							Signature: []byte{4, 5, 6},
+						})[9:],
+					},
+				},
+			},
+		},
+	} {
+		t.Run(tst.name, func(t *testing.T) {
+			err := protoutil.VerifyTransactionsAreWellFormed(tst.block)
+			if tst.expectedError == "" {
+				require.NoError(t, err)
+			} else {
+				require.EqualError(t, err, tst.expectedError)
+			}
+		})
+	}
+}
</code></pre>
<p>The idea is as follows:</p>
<p>When we validate that the block's transactions match the hash in the header, we not only hash the transactions are earlier, </p>
<p>but also ensure that if the transactions in the block are encoded into bytes, they re-create the exact split in the original block: <code>|$$$$$$$$$$$$|***********|@@@@@@@@@|%%%%%%%%%%%|</code></p>
<p>More specifically, each transaction in the block is parsed and then re-encoded to bytes, and we check that the original encoding of a transaction is as the second encoding after parsing the original bytes of the transaction.</p>
<p>This fix keeps the legacy way of hashing transactions to create the block data hash, but also aims to check if some manipulation was done.</p>
<p>To understand why the fix works, we need to understand how protobuf, the wire protocol that Fabric uses to encode transactions (and almost anything it sends over the wire or writes to disk) encodes a transaction.</p>
<p>A transaction is a protobuf message with two fields of bytes: (1) Payload and (2) Signature.</p>
<p>When encoding a field of bytes, protobuf first writes a tag for the field (a byte) and then writes the length of the field in variable-length encoding, and then the bytes themselves.</p>
<p>For example, to encode a transaction, protobuf writes 10 (the tag for payload), then two bytes for the length of the payload, then the payload, and then 18, the tag for the signature, and then a single byte for the length of the signature, and finally the signature.</p>
<p>Now, we can understand a proof sketch of why my solution works:</p>
<p>Assume in contradiction that an adversary takes a block of transactions and changes the split of the concatenation in a way that changes the transactions for a peer:</p>
<p>From <code>|$$$$$$$$$$$$|************|@@@@@@@@@@@|...|%%%%%%%|</code> to (for example): From <code>|$$$$$$$$$$$$************|@@@@@@@@@@@|...|%%%%%%%|</code> </p>
<p>Since this split is not identical to the original split, there exists at least one transaction index of different size between the two splits. Let's look at the first transaction that is of different size.</p>
<p>For example, for the split:</p>
<p><code>|$$$$$$$$$$$$|************|@@@@@@@@@@@|...|%%%%%%%|</code>  we have two options:</p>
<ol>
<li><p>The first transaction of different size is smaller in the new split:  <code>|$$$$$$$$$$$$|*****|*******|@@@@@@@@@@@|...|%%%%%%%|</code>  In such a case, it must contain both a payload and a signature, so it needs two fields (we can say we will return an error if one of the two is missing). If the protobuf parser detects it lacks bytes to parse a payload, it will fail with an error. Else, it has enough bytes to parse the payload, and then the signature is parsed. If the signature field is too short then we also error similarly.</p>
</li>
<li><p>The first transaction of different size is bigger in the new split: <code>|$$$$$$$$$$$$|************@@@@|@@@@@@@|...|%%%%%%%|</code> 
In that case, once this transaction is parsed, the extra bytes are skipped, so encoding the transaction to bytes yields a shorter byte array, and we detect a tempering.</p>
</li>
</ol>
<h3 id="references">References</h3>
<ul>
<li><a href="https://github.com/hyperledger/fabric/security/advisories/GHSA-v9w2-543f-h69m">https://github.com/hyperledger/fabric/security/advisories/GHSA-v9w2-543f-h69m</a></li>
<li><a href="https://github.com/hyperledger/fabric/pull/4503">https://github.com/hyperledger/fabric/pull/4503</a></li>
<li><a href="https://github.com/hyperledger/fabric/pull/4504">https://github.com/hyperledger/fabric/pull/4504</a></li>
<li><a href="https://github.com/hyperledger/fabric/commit/389b2e66de9a6fbc6043216d554c97bbbdf0e008">https://github.com/hyperledger/fabric/commit/389b2e66de9a6fbc6043216d554c97bbbdf0e008</a></li>
<li><a href="https://github.com/hyperledger/fabric/commit/93bef10bd3ce3c54d7f3b064f765dbde61da7def">https://github.com/hyperledger/fabric/commit/93bef10bd3ce3c54d7f3b064f765dbde61da7def</a></li>
<li><a href="https://github.com/hyperledger/fabric/releases/tag/v2.2.14">https://github.com/hyperledger/fabric/releases/tag/v2.2.14</a></li>
<li><a href="https://github.com/hyperledger/fabric/releases/tag/v2.5.5">https://github.com/hyperledger/fabric/releases/tag/v2.5.5</a></li>
<li><a href="https://nvd.nist.gov/vuln/detail/CVE-2023-46132">https://nvd.nist.gov/vuln/detail/CVE-2023-46132</a></li>
<li><a href="https://github.com/advisories/GHSA-v9w2-543f-h69m">https://github.com/advisories/GHSA-v9w2-543f-h69m</a></li>
</ul>
]]></content>
        <author>
            <name>GitHub</name>
            <email>GitHub@noreply.github.com</email>
            <uri>https://github.com/advisories/GHSA-v9w2-543f-h69m</uri>
        </author>
        <category label="severity" term="HIGH"/>
        <published>2023-11-14T20:28:34.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[[github.com/consensys/gnark] gnark's range checker gadget allows wider inputs up to word alignment]]></title>
        <id>https://github.com/advisories/GHSA-rjjm-x32p-m3f7</id>
        <link href="https://github.com/advisories/GHSA-rjjm-x32p-m3f7"/>
        <updated>2023-11-12T15:56:49.000Z</updated>
        <content type="html"><![CDATA[<h3 id="impact">Impact</h3>
<p>gnark provides a gadget in the standard library to allow optimized checking of the bitwidth of the inputs. The gadget works by constructing a fixed lookup table containing all valid entries, partitioning the input and checking that all parts are inside the lookup table. The range checker gadget did not take into account that the highest partition may be less than the width limit, allowing the inputs to be up to 16 bits wider than checked.</p>
<p>Range checking gadget is extensively used in field emulation. Users using any dependant gadget (ECDSA verification, proof recursion etc.) is impacted.</p>
<p>We consider the impact of the vulnerability being low as the number of attacker-modifiable bits is significantly smaller compared to the bit-width of scalar field modulus and it won't be possible to construct inputs which would allow to overflow the scalar field.</p>
<h3 id="patches">Patches</h3>
<p>The issue has been patched in the stable branch of gnark. </p>
<p>Due to low severity of the issue no emergency release will be issued and we follow the existing release plan. Versions v0.9.2 and higher are patched.</p>
<h3 id="workarounds">Workarounds</h3>
<p>We consider the issue very hard to exploit and do not recommend manual remediation. However, it is possible to perform manual bit decomposition using <code>std/math/bits</code> gadget.</p>
<h3 id="references">References</h3>
<p>Initial issue <a href="https://github.com/Consensys/gnark/issues/897">https://github.com/Consensys/gnark/issues/897</a></p>
<h3 id="acknowledgement">Acknowledgement</h3>
<p>The issue was reported by <a href="https://github.com/ultrainstinct30">@ultrainstinct30</a>.</p>
<h3 id="references-1">References</h3>
<ul>
<li><a href="https://github.com/Consensys/gnark/security/advisories/GHSA-rjjm-x32p-m3f7">https://github.com/Consensys/gnark/security/advisories/GHSA-rjjm-x32p-m3f7</a></li>
<li><a href="https://github.com/Consensys/gnark/issues/897">https://github.com/Consensys/gnark/issues/897</a></li>
<li><a href="https://github.com/Consensys/gnark/commit/f528807119e9443df94b8c01fe8ee65abe3c75d8">https://github.com/Consensys/gnark/commit/f528807119e9443df94b8c01fe8ee65abe3c75d8</a></li>
<li><a href="https://github.com/advisories/GHSA-rjjm-x32p-m3f7">https://github.com/advisories/GHSA-rjjm-x32p-m3f7</a></li>
</ul>
]]></content>
        <author>
            <name>GitHub</name>
            <email>GitHub@noreply.github.com</email>
            <uri>https://github.com/advisories/GHSA-rjjm-x32p-m3f7</uri>
        </author>
        <category label="severity" term="LOW"/>
        <published>2023-11-12T15:56:48.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[[go.opentelemetry.io/contrib/instrumentation/google.golang.org/grpc/otelgrpc] otelgrpc DoS vulnerability due to unbound cardinality metrics ]]></title>
        <id>https://github.com/advisories/GHSA-8pgv-569h-w5rw</id>
        <link href="https://github.com/advisories/GHSA-8pgv-569h-w5rw"/>
        <updated>2023-11-12T15:55:40.000Z</updated>
        <content type="html"><![CDATA[<h3 id="summary">Summary</h3>
<p>The grpc Unary Server Interceptor <a href="https://github.com/open-telemetry/opentelemetry-go-contrib/blob/9d4eb7e7706038b07d33f83f76afbe13f53d171d/instrumentation/google.golang.org/grpc/otelgrpc/interceptor.go#L327">opentelemetry-go-contrib/instrumentation/google.golang.org/grpc/otelgrpc/interceptor.go</a></p>
<pre><code>// UnaryServerInterceptor returns a grpc.UnaryServerInterceptor suitable
// for use in a grpc.NewServer call.
func UnaryServerInterceptor(opts ...Option) grpc.UnaryServerInterceptor {
</code></pre>
<p>out of the box adds labels</p>
<ul>
<li><code>net.peer.sock.addr</code></li>
<li><code>net.peer.sock.port</code></li>
</ul>
<p>that have unbound cardinality. It leads to the server's potential memory exhaustion when many malicious requests are sent.</p>
<h3 id="details">Details</h3>
<p>An attacker can easily flood the peer address and port for requests.  </p>
<h3 id="poc">PoC</h3>
<p>Apply the attached patch to the example and run the client multiple times.  Observe how each request will create a unique histogram and how the memory consumption increases during it.</p>
<h3 id="impact">Impact</h3>
<p>In order to be affected, the program has to configure a metrics pipeline, use  <a href="https://github.com/open-telemetry/opentelemetry-go-contrib/blob/9d4eb7e7706038b07d33f83f76afbe13f53d171d/instrumentation/google.golang.org/grpc/otelgrpc/interceptor.go#L327">UnaryServerInterceptor</a>, and does not filter any client IP address and ports via middleware or proxies, etc.</p>
<h3 id="others">Others</h3>
<p>It is similar to already reported vulnerabilities.</p>
<ul>
<li><a href="https://github.com/open-telemetry/opentelemetry-go-contrib/security/advisories/GHSA-rcjv-mgp8-qvmr">GHSA-rcjv-mgp8-qvmr</a> (<a href="https://github.com/open-telemetry/opentelemetry-go-contrib">open-telemetry/opentelemetry-go-contrib</a>)</li>
</ul>
<ul>
<li><a title="GHSA-5r5m-65gx-7vrh" href="https://github.com/open-telemetry/opentelemetry-go-contrib/security/advisories/GHSA-5r5m-65gx-7vrh">GHSA-5r5m-65gx-7vrh</a> (<a href="https://github.com/open-telemetry/opentelemetry-go-contrib">open-telemetry/opentelemetry-go-contrib</a>)</li>
<li><a title="GHSA-cg3q-j54f-5p7p" href="https://github.com/advisories/GHSA-cg3q-j54f-5p7p">GHSA-cg3q-j54f-5p7p</a> (<a href="https://github.com/prometheus/client_golang">prometheus/client_golang</a>)</li>
</ul>
<h3 id="workaround-for-affected-versions">Workaround for affected versions</h3>
<p>As a workaround to stop being affected, a view removing the attributes can be used.</p>
<p>The other possibility is to disable grpc metrics instrumentation by passing <a href="https://github.com/open-telemetry/opentelemetry-go-contrib/blob/instrumentation/google.golang.org/grpc/otelgrpc/v0.45.0/instrumentation/google.golang.org/grpc/otelgrpc/config.go#L138"><code>otelgrpc.WithMeterProvider</code></a> option with <a href="https://pkg.go.dev/go.opentelemetry.io/otel/metric/noop#NewMeterProvider"><code>noop.NewMeterProvider</code></a>.</p>
<h3 id="solution-provided-by-upgrading">Solution provided by upgrading</h3>
<p>In PR <a href="https://github.com/open-telemetry/opentelemetry-go-contrib/pull/4322">#4322</a>, to be released with v0.46.0, the attributes were removed.</p>
<h3 id="references">References</h3>
<ul>
<li><a href="https://github.com/open-telemetry/opentelemetry-go-contrib/pull/4322">#4322</a></li>
</ul>
<h3 id="references-1">References</h3>
<ul>
<li><a href="https://github.com/open-telemetry/opentelemetry-go-contrib/security/advisories/GHSA-8pgv-569h-w5rw">https://github.com/open-telemetry/opentelemetry-go-contrib/security/advisories/GHSA-8pgv-569h-w5rw</a></li>
<li><a href="https://nvd.nist.gov/vuln/detail/CVE-2023-47108">https://nvd.nist.gov/vuln/detail/CVE-2023-47108</a></li>
<li><a href="https://github.com/open-telemetry/opentelemetry-go-contrib/pull/4322">https://github.com/open-telemetry/opentelemetry-go-contrib/pull/4322</a></li>
<li><a href="https://github.com/open-telemetry/opentelemetry-go-contrib/commit/b44dfc9092b157625a5815cb437583cee663333b">https://github.com/open-telemetry/opentelemetry-go-contrib/commit/b44dfc9092b157625a5815cb437583cee663333b</a></li>
<li><a href="https://github.com/open-telemetry/opentelemetry-go-contrib/blob/9d4eb7e7706038b07d33f83f76afbe13f53d171d/instrumentation/google.golang.org/grpc/otelgrpc/interceptor.go#L327">https://github.com/open-telemetry/opentelemetry-go-contrib/blob/9d4eb7e7706038b07d33f83f76afbe13f53d171d/instrumentation/google.golang.org/grpc/otelgrpc/interceptor.go#L327</a></li>
<li><a href="https://github.com/open-telemetry/opentelemetry-go-contrib/blob/instrumentation/google.golang.org/grpc/otelgrpc/v0.45.0/instrumentation/google.golang.org/grpc/otelgrpc/config.go#L138">https://github.com/open-telemetry/opentelemetry-go-contrib/blob/instrumentation/google.golang.org/grpc/otelgrpc/v0.45.0/instrumentation/google.golang.org/grpc/otelgrpc/config.go#L138</a></li>
<li><a href="https://pkg.go.dev/go.opentelemetry.io/otel/metric/noop#NewMeterProvider">https://pkg.go.dev/go.opentelemetry.io/otel/metric/noop#NewMeterProvider</a></li>
<li><a href="https://github.com/advisories/GHSA-8pgv-569h-w5rw">https://github.com/advisories/GHSA-8pgv-569h-w5rw</a></li>
</ul>
]]></content>
        <author>
            <name>GitHub</name>
            <email>GitHub@noreply.github.com</email>
            <uri>https://github.com/advisories/GHSA-8pgv-569h-w5rw</uri>
        </author>
        <category label="severity" term="HIGH"/>
        <published>2023-11-12T15:55:39.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[[github.com/hashicorp/vault] HashiCorp Vault Missing Release of Memory after Effective Lifetime vulnerability]]></title>
        <id>https://github.com/advisories/GHSA-4qhc-v8r6-8vwm</id>
        <link href="https://github.com/advisories/GHSA-4qhc-v8r6-8vwm"/>
        <updated>2023-11-10T00:43:05.000Z</updated>
        <content type="html"><![CDATA[<p>HashiCorp Vault and Vault Enterprise inbound client requests triggering a policy check can lead to an unbounded consumption of memory. A large number of these requests may lead to denial-of-service. Fixed in Vault 1.15.2, 1.14.6, and 1.13.10.</p>
<h3 id="references">References</h3>
<ul>
<li><a href="https://nvd.nist.gov/vuln/detail/CVE-2023-5954">https://nvd.nist.gov/vuln/detail/CVE-2023-5954</a></li>
<li><a href="https://discuss.hashicorp.com/t/hcsec-2023-33-vault-requests-triggering-policy-checks-may-lead-to-unbounded-memory-consumption/59926">https://discuss.hashicorp.com/t/hcsec-2023-33-vault-requests-triggering-policy-checks-may-lead-to-unbounded-memory-consumption/59926</a></li>
<li><a href="https://github.com/advisories/GHSA-4qhc-v8r6-8vwm">https://github.com/advisories/GHSA-4qhc-v8r6-8vwm</a></li>
</ul>
]]></content>
        <author>
            <name>GitHub</name>
            <email>GitHub@noreply.github.com</email>
            <uri>https://github.com/advisories/GHSA-4qhc-v8r6-8vwm</uri>
        </author>
        <category label="severity" term="MODERATE"/>
        <published>2023-11-09T21:30:39.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[[github.com/hashicorp/vault] HashiCorp Vault Missing Release of Memory after Effective Lifetime vulnerability]]></title>
        <id>https://github.com/advisories/GHSA-4qhc-v8r6-8vwm</id>
        <link href="https://github.com/advisories/GHSA-4qhc-v8r6-8vwm"/>
        <updated>2023-11-10T00:43:05.000Z</updated>
        <content type="html"><![CDATA[<p>HashiCorp Vault and Vault Enterprise inbound client requests triggering a policy check can lead to an unbounded consumption of memory. A large number of these requests may lead to denial-of-service. Fixed in Vault 1.15.2, 1.14.6, and 1.13.10.</p>
<h3 id="references">References</h3>
<ul>
<li><a href="https://nvd.nist.gov/vuln/detail/CVE-2023-5954">https://nvd.nist.gov/vuln/detail/CVE-2023-5954</a></li>
<li><a href="https://discuss.hashicorp.com/t/hcsec-2023-33-vault-requests-triggering-policy-checks-may-lead-to-unbounded-memory-consumption/59926">https://discuss.hashicorp.com/t/hcsec-2023-33-vault-requests-triggering-policy-checks-may-lead-to-unbounded-memory-consumption/59926</a></li>
<li><a href="https://github.com/advisories/GHSA-4qhc-v8r6-8vwm">https://github.com/advisories/GHSA-4qhc-v8r6-8vwm</a></li>
</ul>
]]></content>
        <author>
            <name>GitHub</name>
            <email>GitHub@noreply.github.com</email>
            <uri>https://github.com/advisories/GHSA-4qhc-v8r6-8vwm</uri>
        </author>
        <category label="severity" term="MODERATE"/>
        <published>2023-11-09T21:30:39.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[[github.com/hashicorp/vault] HashiCorp Vault Missing Release of Memory after Effective Lifetime vulnerability]]></title>
        <id>https://github.com/advisories/GHSA-4qhc-v8r6-8vwm</id>
        <link href="https://github.com/advisories/GHSA-4qhc-v8r6-8vwm"/>
        <updated>2023-11-10T00:43:05.000Z</updated>
        <content type="html"><![CDATA[<p>HashiCorp Vault and Vault Enterprise inbound client requests triggering a policy check can lead to an unbounded consumption of memory. A large number of these requests may lead to denial-of-service. Fixed in Vault 1.15.2, 1.14.6, and 1.13.10.</p>
<h3 id="references">References</h3>
<ul>
<li><a href="https://nvd.nist.gov/vuln/detail/CVE-2023-5954">https://nvd.nist.gov/vuln/detail/CVE-2023-5954</a></li>
<li><a href="https://discuss.hashicorp.com/t/hcsec-2023-33-vault-requests-triggering-policy-checks-may-lead-to-unbounded-memory-consumption/59926">https://discuss.hashicorp.com/t/hcsec-2023-33-vault-requests-triggering-policy-checks-may-lead-to-unbounded-memory-consumption/59926</a></li>
<li><a href="https://github.com/advisories/GHSA-4qhc-v8r6-8vwm">https://github.com/advisories/GHSA-4qhc-v8r6-8vwm</a></li>
</ul>
]]></content>
        <author>
            <name>GitHub</name>
            <email>GitHub@noreply.github.com</email>
            <uri>https://github.com/advisories/GHSA-4qhc-v8r6-8vwm</uri>
        </author>
        <category label="severity" term="MODERATE"/>
        <published>2023-11-09T21:30:39.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[[github.com/sigstore/cosign] Cosign vulnerable to possible endless data attack from attacker-controlled registry]]></title>
        <id>https://github.com/advisories/GHSA-vfp6-jrw2-99g9</id>
        <link href="https://github.com/advisories/GHSA-vfp6-jrw2-99g9"/>
        <updated>2023-11-14T21:38:50.000Z</updated>
        <content type="html"><![CDATA[<h3 id="summary">Summary</h3>
<p>Cosign is susceptible to a denial of service by an attacker controlled registry. An attacker who controls a remote registry can return a high number of attestations and/or signatures to Cosign and cause Cosign to enter a long loop resulting in an endless data attack. The root cause is that Cosign loops through all attestations fetched from the remote registry in <code>pkg/cosign.FetchAttestations</code>.</p>
<p>The attacker needs to compromise the registry or make a request to a registry they control. When doing so, the attacker must return a high number of attestations in the response to Cosign. The result will be that the attacker can cause Cosign to go into a long or infinite loop that will prevent other users from verifying their data. In Kyvernos case, an attacker whose privileges are limited to making requests to the cluster can make a request with an image reference to their own registry, trigger the infinite loop and deny other users from completing their admission requests. Alternatively, the attacker can obtain control of the registry used by an organization and return a high number of attestations instead the expected number of attestations.</p>
<p>The vulnerable loop in Cosign starts on line 154 below:
<a href="https://github.com/sigstore/cosign/blob/004443228442850fb28f248fd59765afad99b6df/pkg/cosign/fetch.go#L135-L196">https://github.com/sigstore/cosign/blob/004443228442850fb28f248fd59765afad99b6df/pkg/cosign/fetch.go#L135-L196</a></p>
<p>The <code>l</code> slice is controllable by an attacker who controls the remote registry.</p>
<p>Many cloud-native projects consider the remote registry to be untrusted, including Crossplane, Notary and Kyverno. We consider the same to be the case for Cosign, since users are not in control of whether the registry returns the expected data.</p>
<p>TUF's security model labels this type of vulnerability an <a href="https://theupdateframework.io/security/">"Endless data attack"</a>, but an attacker could use this as a type of rollback attack, in case the user attempts to deploy a patched version of a vulnerable image; The attacker could prevent this upgrade by causing Cosign to get stuck in an infinite loop and never complete.</p>
<h3 id="mitigation">Mitigation</h3>
<p>The issue can be mitigated rather simply by setting a limit to the limit of attestations that Cosign will loop through. The limit does not need to be high to be within the vast majority of use cases and still prevent the endless data attack.</p>
<h3 id="references">References</h3>
<ul>
<li><a href="https://github.com/sigstore/cosign/security/advisories/GHSA-vfp6-jrw2-99g9">https://github.com/sigstore/cosign/security/advisories/GHSA-vfp6-jrw2-99g9</a></li>
<li><a href="https://nvd.nist.gov/vuln/detail/CVE-2023-46737">https://nvd.nist.gov/vuln/detail/CVE-2023-46737</a></li>
<li><a href="https://github.com/sigstore/cosign/commit/8ac891ff0e29ddc67965423bee8f826219c6eb0f">https://github.com/sigstore/cosign/commit/8ac891ff0e29ddc67965423bee8f826219c6eb0f</a></li>
<li><a href="https://github.com/sigstore/cosign/releases/tag/v2.2.1">https://github.com/sigstore/cosign/releases/tag/v2.2.1</a></li>
<li><a href="https://github.com/advisories/GHSA-vfp6-jrw2-99g9">https://github.com/advisories/GHSA-vfp6-jrw2-99g9</a></li>
</ul>
]]></content>
        <author>
            <name>GitHub</name>
            <email>GitHub@noreply.github.com</email>
            <uri>https://github.com/advisories/GHSA-vfp6-jrw2-99g9</uri>
        </author>
        <category label="severity" term="LOW"/>
        <published>2023-11-08T15:02:51.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[[github.com/sigstore/cosign/v2] Cosign vulnerable to possible endless data attack from attacker-controlled registry]]></title>
        <id>https://github.com/advisories/GHSA-vfp6-jrw2-99g9</id>
        <link href="https://github.com/advisories/GHSA-vfp6-jrw2-99g9"/>
        <updated>2023-11-14T21:38:50.000Z</updated>
        <content type="html"><![CDATA[<h3 id="summary">Summary</h3>
<p>Cosign is susceptible to a denial of service by an attacker controlled registry. An attacker who controls a remote registry can return a high number of attestations and/or signatures to Cosign and cause Cosign to enter a long loop resulting in an endless data attack. The root cause is that Cosign loops through all attestations fetched from the remote registry in <code>pkg/cosign.FetchAttestations</code>.</p>
<p>The attacker needs to compromise the registry or make a request to a registry they control. When doing so, the attacker must return a high number of attestations in the response to Cosign. The result will be that the attacker can cause Cosign to go into a long or infinite loop that will prevent other users from verifying their data. In Kyvernos case, an attacker whose privileges are limited to making requests to the cluster can make a request with an image reference to their own registry, trigger the infinite loop and deny other users from completing their admission requests. Alternatively, the attacker can obtain control of the registry used by an organization and return a high number of attestations instead the expected number of attestations.</p>
<p>The vulnerable loop in Cosign starts on line 154 below:
<a href="https://github.com/sigstore/cosign/blob/004443228442850fb28f248fd59765afad99b6df/pkg/cosign/fetch.go#L135-L196">https://github.com/sigstore/cosign/blob/004443228442850fb28f248fd59765afad99b6df/pkg/cosign/fetch.go#L135-L196</a></p>
<p>The <code>l</code> slice is controllable by an attacker who controls the remote registry.</p>
<p>Many cloud-native projects consider the remote registry to be untrusted, including Crossplane, Notary and Kyverno. We consider the same to be the case for Cosign, since users are not in control of whether the registry returns the expected data.</p>
<p>TUF's security model labels this type of vulnerability an <a href="https://theupdateframework.io/security/">"Endless data attack"</a>, but an attacker could use this as a type of rollback attack, in case the user attempts to deploy a patched version of a vulnerable image; The attacker could prevent this upgrade by causing Cosign to get stuck in an infinite loop and never complete.</p>
<h3 id="mitigation">Mitigation</h3>
<p>The issue can be mitigated rather simply by setting a limit to the limit of attestations that Cosign will loop through. The limit does not need to be high to be within the vast majority of use cases and still prevent the endless data attack.</p>
<h3 id="references">References</h3>
<ul>
<li><a href="https://github.com/sigstore/cosign/security/advisories/GHSA-vfp6-jrw2-99g9">https://github.com/sigstore/cosign/security/advisories/GHSA-vfp6-jrw2-99g9</a></li>
<li><a href="https://nvd.nist.gov/vuln/detail/CVE-2023-46737">https://nvd.nist.gov/vuln/detail/CVE-2023-46737</a></li>
<li><a href="https://github.com/sigstore/cosign/commit/8ac891ff0e29ddc67965423bee8f826219c6eb0f">https://github.com/sigstore/cosign/commit/8ac891ff0e29ddc67965423bee8f826219c6eb0f</a></li>
<li><a href="https://github.com/sigstore/cosign/releases/tag/v2.2.1">https://github.com/sigstore/cosign/releases/tag/v2.2.1</a></li>
<li><a href="https://github.com/advisories/GHSA-vfp6-jrw2-99g9">https://github.com/advisories/GHSA-vfp6-jrw2-99g9</a></li>
</ul>
]]></content>
        <author>
            <name>GitHub</name>
            <email>GitHub@noreply.github.com</email>
            <uri>https://github.com/advisories/GHSA-vfp6-jrw2-99g9</uri>
        </author>
        <category label="severity" term="LOW"/>
        <published>2023-11-08T15:02:51.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[[github.com/slsa-framework/slsa-verifier] slsa-verifier vulnerable to mproper validation of npm's publish attestations]]></title>
        <id>https://github.com/advisories/GHSA-r2xv-vpr2-42m9</id>
        <link href="https://github.com/advisories/GHSA-r2xv-vpr2-42m9"/>
        <updated>2023-11-09T16:14:41.000Z</updated>
        <content type="html"><![CDATA[<h3 id="summary">Summary</h3>
<p><code>slsa-verifier&lt;=2.4.0</code> does not correctly verify npm's <a href="https://github.com/npm/attestation/tree/main/specs/publish/v0.1">publish</a> attestations signature.</p>
<h3 id="proof-of-concept">Proof of concept</h3>
<p>Steps to reproduce:</p>
<ol>
<li><code>curl -Sso attestations.json $(npm view @trishankatdatadog/supreme-goggles --json | jq -r '.dist.attestations.url')</code></li>
<li><code>curl -Sso supreme-goggles.tgz "$(npm view @trishankatdatadog/supreme-goggles --json | jq -r '.dist.tarball')"</code></li>
<li>In <code>attestations.json</code>, take the value addressed by the <code>jq</code> selector <code>.attestations[0].bundle.dsseEnvelope.payload</code>, base64decode it, tamper with it, base64encode that, and replace the original value with that. Save the file as <code>attestations_tampered.json</code>.
Here is an example command to replace the package name with <code>@attacker/malicious</code>:
<code>jq -r ".attestations[0].bundle.dsseEnvelope.payload = \"$(jq -r '.attestations[0].bundle.dsseEnvelope.payload | @base64d' &lt; attestations.json | jq '.subject[0].name = "pkg:npm/%40attacker/malicious"' | base64 -w0)\"" &lt; attestations.json &gt; attestations_tampered.json</code></li>
<li><code>SLSA_VERIFIER_EXPERIMENTAL=1 slsa-verifier verify-npm-package supreme-goggles.tgz --attestations-path attestations_tampered.json --builder-id "https://github.com/actions/runner/github-hosted" --package-name "@trishankatdatadog/supreme-goggles" --package-version 1.0.5 --source-uri github.com/trishankatdatadog/supreme-goggles</code></li>
<li>The result is that <code>slsa-verifier</code> fails to detect this tampering of the publish attestation (unlike with the provenance attestation) and returns <code>PASSED</code>.</li>
</ol>
<h3 id="impact">Impact</h3>
<p>An attacker who controls what packages and attestations are shown to a user <em>can</em> associate a package with an arbitrary name and version that do <em>not</em> match what the user expects from the publish attestation. Furthermore, the package digest in the publish attestation need <em>not</em> match its counterpart in the provenance attestation. However, the attacker <em>cannot</em> associate the given package with an arbitrary source and builder that the user does not expect from the provenance attestation. Thus, the attacker could, for example, convince package managers to install authentic but older versions of packages that contain known, exploitable vulnerabilities.</p>
<p>Severity is considered low because 1) it does not invalidate the provenance and 2) support for npm is currently experimental.</p>
<h3 id="patches">Patches</h3>
<p>Fixed by PR <a href="https://github.com/slsa-framework/slsa-verifier/pull/705">#705</a> and released in versions <code>&gt;=2.4.1</code>.</p>
<h3 id="workarounds">Workarounds</h3>
<p>There is no easy way for users to fix or remediate this vulnerability without upgrading, short of verifying npm's publish attestations themselves, <em>and</em> cross-verifying it against GHA's provenance attestations.</p>
<h3 id="references">References</h3>
<ul>
<li><a href="https://openssf.slack.com/archives/C03PDLFET5W/p1695330038983179">Original OpenSSF Slack thread</a></li>
</ul>
<h3 id="references-1">References</h3>
<ul>
<li><a href="https://github.com/slsa-framework/slsa-verifier/security/advisories/GHSA-r2xv-vpr2-42m9">https://github.com/slsa-framework/slsa-verifier/security/advisories/GHSA-r2xv-vpr2-42m9</a></li>
<li><a href="https://github.com/slsa-framework/slsa-verifier/pull/705">https://github.com/slsa-framework/slsa-verifier/pull/705</a></li>
<li><a href="https://github.com/slsa-framework/slsa-verifier/commit/f6ae402f458b347d2c414f1d053fc1f8257888d0">https://github.com/slsa-framework/slsa-verifier/commit/f6ae402f458b347d2c414f1d053fc1f8257888d0</a></li>
<li><a href="https://github.com/npm/attestation/tree/main/specs/publish/v0.1">https://github.com/npm/attestation/tree/main/specs/publish/v0.1</a></li>
<li><a href="https://openssf.slack.com/archives/C03PDLFET5W/p1695330038983179">https://openssf.slack.com/archives/C03PDLFET5W/p1695330038983179</a></li>
<li><a href="https://github.com/advisories/GHSA-r2xv-vpr2-42m9">https://github.com/advisories/GHSA-r2xv-vpr2-42m9</a></li>
</ul>
]]></content>
        <author>
            <name>GitHub</name>
            <email>GitHub@noreply.github.com</email>
            <uri>https://github.com/advisories/GHSA-r2xv-vpr2-42m9</uri>
        </author>
        <category label="severity" term="LOW"/>
        <published>2023-11-08T19:15:55.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[[github.com/slsa-framework/slsa-verifier/v2] slsa-verifier vulnerable to mproper validation of npm's publish attestations]]></title>
        <id>https://github.com/advisories/GHSA-r2xv-vpr2-42m9</id>
        <link href="https://github.com/advisories/GHSA-r2xv-vpr2-42m9"/>
        <updated>2023-11-09T16:14:41.000Z</updated>
        <content type="html"><![CDATA[<h3 id="summary">Summary</h3>
<p><code>slsa-verifier&lt;=2.4.0</code> does not correctly verify npm's <a href="https://github.com/npm/attestation/tree/main/specs/publish/v0.1">publish</a> attestations signature.</p>
<h3 id="proof-of-concept">Proof of concept</h3>
<p>Steps to reproduce:</p>
<ol>
<li><code>curl -Sso attestations.json $(npm view @trishankatdatadog/supreme-goggles --json | jq -r '.dist.attestations.url')</code></li>
<li><code>curl -Sso supreme-goggles.tgz "$(npm view @trishankatdatadog/supreme-goggles --json | jq -r '.dist.tarball')"</code></li>
<li>In <code>attestations.json</code>, take the value addressed by the <code>jq</code> selector <code>.attestations[0].bundle.dsseEnvelope.payload</code>, base64decode it, tamper with it, base64encode that, and replace the original value with that. Save the file as <code>attestations_tampered.json</code>.
Here is an example command to replace the package name with <code>@attacker/malicious</code>:
<code>jq -r ".attestations[0].bundle.dsseEnvelope.payload = \"$(jq -r '.attestations[0].bundle.dsseEnvelope.payload | @base64d' &lt; attestations.json | jq '.subject[0].name = "pkg:npm/%40attacker/malicious"' | base64 -w0)\"" &lt; attestations.json &gt; attestations_tampered.json</code></li>
<li><code>SLSA_VERIFIER_EXPERIMENTAL=1 slsa-verifier verify-npm-package supreme-goggles.tgz --attestations-path attestations_tampered.json --builder-id "https://github.com/actions/runner/github-hosted" --package-name "@trishankatdatadog/supreme-goggles" --package-version 1.0.5 --source-uri github.com/trishankatdatadog/supreme-goggles</code></li>
<li>The result is that <code>slsa-verifier</code> fails to detect this tampering of the publish attestation (unlike with the provenance attestation) and returns <code>PASSED</code>.</li>
</ol>
<h3 id="impact">Impact</h3>
<p>An attacker who controls what packages and attestations are shown to a user <em>can</em> associate a package with an arbitrary name and version that do <em>not</em> match what the user expects from the publish attestation. Furthermore, the package digest in the publish attestation need <em>not</em> match its counterpart in the provenance attestation. However, the attacker <em>cannot</em> associate the given package with an arbitrary source and builder that the user does not expect from the provenance attestation. Thus, the attacker could, for example, convince package managers to install authentic but older versions of packages that contain known, exploitable vulnerabilities.</p>
<p>Severity is considered low because 1) it does not invalidate the provenance and 2) support for npm is currently experimental.</p>
<h3 id="patches">Patches</h3>
<p>Fixed by PR <a href="https://github.com/slsa-framework/slsa-verifier/pull/705">#705</a> and released in versions <code>&gt;=2.4.1</code>.</p>
<h3 id="workarounds">Workarounds</h3>
<p>There is no easy way for users to fix or remediate this vulnerability without upgrading, short of verifying npm's publish attestations themselves, <em>and</em> cross-verifying it against GHA's provenance attestations.</p>
<h3 id="references">References</h3>
<ul>
<li><a href="https://openssf.slack.com/archives/C03PDLFET5W/p1695330038983179">Original OpenSSF Slack thread</a></li>
</ul>
<h3 id="references-1">References</h3>
<ul>
<li><a href="https://github.com/slsa-framework/slsa-verifier/security/advisories/GHSA-r2xv-vpr2-42m9">https://github.com/slsa-framework/slsa-verifier/security/advisories/GHSA-r2xv-vpr2-42m9</a></li>
<li><a href="https://github.com/slsa-framework/slsa-verifier/pull/705">https://github.com/slsa-framework/slsa-verifier/pull/705</a></li>
<li><a href="https://github.com/slsa-framework/slsa-verifier/commit/f6ae402f458b347d2c414f1d053fc1f8257888d0">https://github.com/slsa-framework/slsa-verifier/commit/f6ae402f458b347d2c414f1d053fc1f8257888d0</a></li>
<li><a href="https://github.com/npm/attestation/tree/main/specs/publish/v0.1">https://github.com/npm/attestation/tree/main/specs/publish/v0.1</a></li>
<li><a href="https://openssf.slack.com/archives/C03PDLFET5W/p1695330038983179">https://openssf.slack.com/archives/C03PDLFET5W/p1695330038983179</a></li>
<li><a href="https://github.com/advisories/GHSA-r2xv-vpr2-42m9">https://github.com/advisories/GHSA-r2xv-vpr2-42m9</a></li>
</ul>
]]></content>
        <author>
            <name>GitHub</name>
            <email>GitHub@noreply.github.com</email>
            <uri>https://github.com/advisories/GHSA-r2xv-vpr2-42m9</uri>
        </author>
        <category label="severity" term="LOW"/>
        <published>2023-11-08T19:15:55.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[[github.com/consensys/gnark-crypto] gnark-crypto's exponentiation in the pairing target group GT using GLV can give incorrect results]]></title>
        <id>https://github.com/advisories/GHSA-pffg-92cg-xf5c</id>
        <link href="https://github.com/advisories/GHSA-pffg-92cg-xf5c"/>
        <updated>2023-11-08T18:36:33.000Z</updated>
        <content type="html"><![CDATA[<h3 id="impact">Impact</h3>
<p>When the exponent is bigger than <code>r</code>, the group order of the pairing target group <code>GT</code>, the exponentiation  la GLV (<code>ExpGLV</code>) can <em>sometimes</em> give incorrect results compared to normal exponentiation (<code>Exp</code>). </p>
<p>The issue impacts all users using <code>ExpGLV</code> for exponentiations in <code>GT</code>. This does not impact <code>Exp</code> and <code>ExpCyclotomic</code> which are sound. Also note that GLV methods in G1 and G2 are sound and <em>not</em> impacted.</p>
<h3 id="patches">Patches</h3>
<p>Fix has been implemented in pull request <a href="https://github.com/Consensys/gnark-crypto/pull/451">https://github.com/Consensys/gnark-crypto/pull/451</a> and merged in commit <a href="https://github.com/Consensys/gnark-crypto/commit/ec6be1a037f7c496d595c541a8a8d31c47bcfa3d">https://github.com/Consensys/gnark-crypto/commit/ec6be1a037f7c496d595c541a8a8d31c47bcfa3d</a> to master branch.</p>
<p>The fix increased the bounds of the sub-scalars by 1. In fact, since <a href="https://github.com/Consensys/gnark-crypto/pull/213">https://github.com/Consensys/gnark-crypto/pull/213</a>, we use a fast scalar decomposition that tradeoffs divisions (needed in the Babai rounding) by right-shifts. We precompute <code>b=2^m*v/d (m &gt; log2(d))</code> and then at runtime compute <code>scalar*b/2^m</code> (<code>v</code> is a lattice vector and <code>d</code> the lattice determinant). This increases the bounds on sub-scalars by 1 which we check at runtime before increasing the loop size (we don't target constant-timeness). <code>m</code> is chosen to be a machine word twice big than <code>log2(d)</code> so that we rarely need to increase the loop size. Hence why the issue happens only <em>sometimes</em> if we omit to increase the bounds. This bounds increase was implemented in G1 and G2 but forgot in GT.</p>
<h3 id="workarounds">Workarounds</h3>
<p>Updating to <code>v0.12.1+</code>. Alternatively, use <code>Exp</code> or <code>ExpCyclotomic</code> instead. We are not aware of any users using <code>ExpGLV</code> anyway.</p>
<h3 id="references">References</h3>
<ul>
<li>Fix PR: <a href="https://github.com/Consensys/gnark-crypto/pull/451">https://github.com/Consensys/gnark-crypto/pull/451</a> </li>
<li>Fast scalar decomposition PR: <a href="https://github.com/Consensys/gnark-crypto/pull/213">https://github.com/Consensys/gnark-crypto/pull/213</a></li>
<li><a href="https://eprint.iacr.org/2015/565">https://eprint.iacr.org/2015/565</a> Sec.4.2</li>
</ul>
<h3 id="acknowledgement">Acknowledgement</h3>
<p>The vulnerability was reported by <a href="https://github.com/asanso">Antonio Sanso</a> @ <a href="https://crypto.ethereum.org/">EF</a>.</p>
<h3 id="references-1">References</h3>
<ul>
<li><a href="https://github.com/Consensys/gnark-crypto/security/advisories/GHSA-pffg-92cg-xf5c">https://github.com/Consensys/gnark-crypto/security/advisories/GHSA-pffg-92cg-xf5c</a></li>
<li><a href="https://github.com/Consensys/gnark-crypto/pull/213">https://github.com/Consensys/gnark-crypto/pull/213</a></li>
<li><a href="https://github.com/Consensys/gnark-crypto/pull/451">https://github.com/Consensys/gnark-crypto/pull/451</a></li>
<li><a href="https://github.com/Consensys/gnark-crypto/commit/ec6be1a037f7c496d595c541a8a8d31c47bcfa3d">https://github.com/Consensys/gnark-crypto/commit/ec6be1a037f7c496d595c541a8a8d31c47bcfa3d</a></li>
<li><a href="https://eprint.iacr.org/2015/565">https://eprint.iacr.org/2015/565</a></li>
<li><a href="https://github.com/advisories/GHSA-pffg-92cg-xf5c">https://github.com/advisories/GHSA-pffg-92cg-xf5c</a></li>
</ul>
]]></content>
        <author>
            <name>GitHub</name>
            <email>GitHub@noreply.github.com</email>
            <uri>https://github.com/advisories/GHSA-pffg-92cg-xf5c</uri>
        </author>
        <category label="severity" term="LOW"/>
        <published>2023-10-05T20:57:20.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[[github.com/zitadel/zitadel] ZITADEL race condition in lockout policy execution]]></title>
        <id>https://github.com/advisories/GHSA-7h8m-vrxx-vr4m</id>
        <link href="https://github.com/advisories/GHSA-7h8m-vrxx-vr4m"/>
        <updated>2023-11-09T16:14:20.000Z</updated>
        <content type="html"><![CDATA[<h3 id="impact">Impact</h3>
<p>ZITADEL provides administrators the possibility to define a <code>Lockout Policy</code> with a maximum amount of failed password check attempts. On every failed password check, the amount of failed checks is compared against the configured maximum.
Exceeding the limit, will lock the user and prevent further authentication.</p>
<p>In the affected implementation it was possible for an attacker to start multiple parallel password checks, giving him the possibility to try out more combinations than configured in the <code>Lockout Policy</code>.</p>
<h3 id="patches">Patches</h3>
<p>2.x versions are fixed on &gt;= <a href="https://github.com/zitadel/zitadel/releases/tag/v2.40.5">2.40.5</a>
2.38.x versions are fixed on &gt;= <a href="https://github.com/zitadel/zitadel/releases/tag/v2.38.3">2.38.3</a></p>
<h3 id="workarounds">Workarounds</h3>
<p>There is no workaround since a patch is already available.</p>
<h3 id="references">References</h3>
<p>None</p>
<h3 id="questions">Questions</h3>
<p>If you have any questions or comments about this advisory, please email us at <a href="mailto:security@zitadel.com">security@zitadel.com</a></p>
<h3 id="references-1">References</h3>
<ul>
<li><a href="https://github.com/zitadel/zitadel/security/advisories/GHSA-7h8m-vrxx-vr4m">https://github.com/zitadel/zitadel/security/advisories/GHSA-7h8m-vrxx-vr4m</a></li>
<li><a href="https://github.com/zitadel/zitadel/commit/22e2d5599918864877e054ebe82fb834a5aa1077">https://github.com/zitadel/zitadel/commit/22e2d5599918864877e054ebe82fb834a5aa1077</a></li>
<li><a href="https://github.com/zitadel/zitadel/releases/tag/v2.38.3">https://github.com/zitadel/zitadel/releases/tag/v2.38.3</a></li>
<li><a href="https://github.com/zitadel/zitadel/releases/tag/v2.40.5">https://github.com/zitadel/zitadel/releases/tag/v2.40.5</a></li>
<li><a href="https://nvd.nist.gov/vuln/detail/CVE-2023-47111">https://nvd.nist.gov/vuln/detail/CVE-2023-47111</a></li>
<li><a href="https://github.com/advisories/GHSA-7h8m-vrxx-vr4m">https://github.com/advisories/GHSA-7h8m-vrxx-vr4m</a></li>
</ul>
]]></content>
        <author>
            <name>GitHub</name>
            <email>GitHub@noreply.github.com</email>
            <uri>https://github.com/advisories/GHSA-7h8m-vrxx-vr4m</uri>
        </author>
        <category label="severity" term="HIGH"/>
        <published>2023-11-08T17:52:50.000Z</published>
    </entry>
</feed>