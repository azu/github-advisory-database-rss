<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://azu.github.io/github-advisory-database-rss/pip.rss</id>
    <title>Security Advisory for Python packages hosted at PyPI.org</title>
    <updated>2023-11-18T22:01:17.790Z</updated>
    <generator>github-advisory-database-rss</generator>
    <link rel="alternate" href="https://github.com/advisories?query=type%3Areviewed+ecosystem%3Apip"/>
    <subtitle>Security Advisory for Python packages hosted at PyPI.org on GitHub</subtitle>
    <rights>github-advisory-database-rss</rights>
    <category term="CRITICAL"/>
    <category term="HIGH"/>
    <category term="MODERATE"/>
    <category term="LOW"/>
    <entry>
        <title type="html"><![CDATA[[mlflow] MLflow authentication requirement bypass can allow a user to arbitrarily create an account]]></title>
        <id>https://github.com/advisories/GHSA-4qq5-mxxx-m6gg</id>
        <link href="https://github.com/advisories/GHSA-4qq5-mxxx-m6gg"/>
        <updated>2023-11-17T22:49:28.000Z</updated>
        <content type="html"><![CDATA[<p>An attacker is able to arbitrarily create an account in MLflow bypassing any authentication requirement.</p>
<h3 id="references">References</h3>
<ul>
<li><a href="https://nvd.nist.gov/vuln/detail/CVE-2023-6014">https://nvd.nist.gov/vuln/detail/CVE-2023-6014</a></li>
<li><a href="https://huntr.com/bounties/3e64df69-ddc2-463e-9809-d07c24dc1de4">https://huntr.com/bounties/3e64df69-ddc2-463e-9809-d07c24dc1de4</a></li>
<li><a href="https://github.com/advisories/GHSA-4qq5-mxxx-m6gg">https://github.com/advisories/GHSA-4qq5-mxxx-m6gg</a></li>
</ul>
]]></content>
        <author>
            <name>GitHub</name>
            <email>GitHub@noreply.github.com</email>
            <uri>https://github.com/advisories/GHSA-4qq5-mxxx-m6gg</uri>
        </author>
        <category label="severity" term="CRITICAL"/>
        <published>2023-11-16T21:30:46.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[[ibis-framework] Ibis PyArrow dependency allows arbitrary code execution when loading a malicious data file]]></title>
        <id>https://github.com/advisories/GHSA-x563-6hqv-26mr</id>
        <link href="https://github.com/advisories/GHSA-x563-6hqv-26mr"/>
        <updated>2023-11-17T21:47:11.000Z</updated>
        <content type="html"><![CDATA[<h3 id="impact">Impact</h3>
<p>Deserialization of untrusted data in IPC and Parquet readers in PyArrow versions 0.14.0 to 14.0.0 allows arbitrary code execution. An application is vulnerable if it reads Arrow IPC, Feather or Parquet data from untrusted sources (for example user-supplied input files). This vulnerability only affects PyArrow, not other Apache Arrow implementations or bindings.</p>
<p>Note that Ibis itself makes <strong>extremely limited</strong> use of <code>pyarrow.parquet.read_table</code>:</p>
<ol>
<li><code>read_table</code> is used in tests, where the input file is entirely controlled by the Ibis developers</li>
<li><code>read_table</code> is used in the <code>ibis/examples/__init__.py</code> as a fallback for backends that don't support reading Parquet directly. Parquet data used in <code>ibis.examples</code> are also managed by the Ibis developers. This Parquet data is generated from CSV files and SQLite databases.</li>
<li>The Pandas and Dask backends both use PyArrow to read Parquet files and are therefore affected.</li>
</ol>
<p>Ibis <strong>does not</strong> make use of APIs that directly read from either Arrow IPC files or Feather files.</p>
<h3 id="patches">Patches</h3>
<p>Ibis imports the <code>pyarrow_hotfix</code> package wherever pyarrow is used, as of version 7.1.0.</p>
<p>Upgrading to Arrow 14.0.1 is also a possible solution, starting in Ibis 7.1.0.</p>
<h3 id="workarounds">Workarounds</h3>
<p>Install <a href="https://pypi.org/project/pyarrow-hotfix/"><code>pyarrow_hotfix</code></a> and run <code>import pyarrow_hotfix</code> ahead of any and all <code>import ibis</code> statements.</p>
<p>For example:</p>
<pre><code class="language-python">import ibis
</code></pre>
<p>becomes</p>
<pre><code class="language-python">import pyarrow_hotfix
import ibis
</code></pre>
<h3 id="references">References</h3>
<p><a href="https://www.cve.org/CVERecord?id=CVE-2023-47248">https://www.cve.org/CVERecord?id=CVE-2023-47248</a>
<a href="https://nvd.nist.gov/vuln/detail/CVE-2023-47248">https://nvd.nist.gov/vuln/detail/CVE-2023-47248</a></p>
<h3 id="references-1">References</h3>
<ul>
<li><a href="https://github.com/ibis-project/ibis/security/advisories/GHSA-x563-6hqv-26mr">https://github.com/ibis-project/ibis/security/advisories/GHSA-x563-6hqv-26mr</a></li>
<li><a href="https://github.com/ibis-project/ibis/commit/0fa1e5dc06783c01e912e8de4d7e10186ca0e364">https://github.com/ibis-project/ibis/commit/0fa1e5dc06783c01e912e8de4d7e10186ca0e364</a></li>
<li><a href="https://github.com/ibis-project/ibis/releases/tag/7.1.0">https://github.com/ibis-project/ibis/releases/tag/7.1.0</a></li>
<li><a href="https://github.com/advisories/GHSA-x563-6hqv-26mr">https://github.com/advisories/GHSA-x563-6hqv-26mr</a></li>
</ul>
]]></content>
        <author>
            <name>GitHub</name>
            <email>GitHub@noreply.github.com</email>
            <uri>https://github.com/advisories/GHSA-x563-6hqv-26mr</uri>
        </author>
        <category label="severity" term="CRITICAL"/>
        <published>2023-11-17T21:47:11.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[[pypinksign] PyPinkSign uses a non-random or static IV for Cipher Block Chaining (CBC) mode in AES encryption]]></title>
        <id>https://github.com/advisories/GHSA-fxff-wxxv-c2jc</id>
        <link href="https://github.com/advisories/GHSA-fxff-wxxv-c2jc"/>
        <updated>2023-11-17T21:42:39.000Z</updated>
        <content type="html"><![CDATA[<p>PyPinkSign v0.5.1 uses a non-random or static IV for Cipher Block Chaining (CBC) mode in AES encryption. This vulnerability can lead to the disclosure of information and communications.</p>
<h3 id="references">References</h3>
<ul>
<li><a href="https://nvd.nist.gov/vuln/detail/CVE-2023-48056">https://nvd.nist.gov/vuln/detail/CVE-2023-48056</a></li>
<li><a href="https://gxx777.github.io/PyPinkSign_v0.5.1_Cryptographic_API_Misuse_Vulnerability.md">https://gxx777.github.io/PyPinkSign_v0.5.1_Cryptographic_API_Misuse_Vulnerability.md</a></li>
<li><a href="http://bandoche.com">http://bandoche.com</a></li>
<li><a href="http://pypinksign.com">http://pypinksign.com</a></li>
<li><a href="https://github.com/bandoche/PyPinkSign/issues/29">https://github.com/bandoche/PyPinkSign/issues/29</a></li>
<li><a href="https://github.com/bandoche/PyPinkSign/commit/e1809ddf6a266e9007e10f0486b462fa7f89a43d">https://github.com/bandoche/PyPinkSign/commit/e1809ddf6a266e9007e10f0486b462fa7f89a43d</a></li>
<li><a href="https://github.com/bandoche/PyPinkSign/blob/main/pypinksign/pypinksign.py#L504">https://github.com/bandoche/PyPinkSign/blob/main/pypinksign/pypinksign.py#L504</a></li>
<li><a href="https://github.com/bandoche/PyPinkSign/blob/main/pypinksign/pypinksign.py#L537">https://github.com/bandoche/PyPinkSign/blob/main/pypinksign/pypinksign.py#L537</a></li>
<li><a href="https://github.com/advisories/GHSA-fxff-wxxv-c2jc">https://github.com/advisories/GHSA-fxff-wxxv-c2jc</a></li>
</ul>
]]></content>
        <author>
            <name>GitHub</name>
            <email>GitHub@noreply.github.com</email>
            <uri>https://github.com/advisories/GHSA-fxff-wxxv-c2jc</uri>
        </author>
        <category label="severity" term="MODERATE"/>
        <published>2023-11-16T18:30:31.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[[pyarrow] PyArrow: Arbitrary code execution when loading a malicious data file]]></title>
        <id>https://github.com/advisories/GHSA-5wvp-7f3h-6wmm</id>
        <link href="https://github.com/advisories/GHSA-5wvp-7f3h-6wmm"/>
        <updated>2023-11-17T19:01:54.000Z</updated>
        <content type="html"><![CDATA[<p>Deserialization of untrusted data in IPC and Parquet readers in PyArrow versions 0.14.0 to 14.0.0 allows arbitrary code execution. An application is vulnerable if it reads Arrow IPC, Feather or Parquet data from untrusted sources (for example user-supplied input files).</p>
<p>This vulnerability only affects PyArrow, not other Apache Arrow implementations or bindings.</p>
<p>It is recommended that users of PyArrow upgrade to 14.0.1. Similarly, it is recommended that downstream libraries upgrade their dependency requirements to PyArrow 14.0.1 or later. PyPI packages are already available, and we hope that conda-forge packages will be available soon.</p>
<p>If it is not possible to upgrade, maintainers provide a separate package <code>pyarrow-hotfix</code> that disables the vulnerability on older PyArrow versions. See <a href="https://pypi.org/project/pyarrow-hotfix/">https://pypi.org/project/pyarrow-hotfix/</a>  for instructions.</p>
<h3 id="references">References</h3>
<ul>
<li><a href="https://nvd.nist.gov/vuln/detail/CVE-2023-47248">https://nvd.nist.gov/vuln/detail/CVE-2023-47248</a></li>
<li><a href="https://lists.apache.org/thread/yhy7tdfjf9hrl9vfrtzo8p2cyjq87v7n">https://lists.apache.org/thread/yhy7tdfjf9hrl9vfrtzo8p2cyjq87v7n</a></li>
<li><a href="https://pypi.org/project/pyarrow-hotfix/">https://pypi.org/project/pyarrow-hotfix/</a></li>
<li><a href="https://github.com/apache/arrow/commit/f14170976372436ec1d03a724d8d3f3925484ecf">https://github.com/apache/arrow/commit/f14170976372436ec1d03a724d8d3f3925484ecf</a></li>
<li><a href="https://github.com/advisories/GHSA-5wvp-7f3h-6wmm">https://github.com/advisories/GHSA-5wvp-7f3h-6wmm</a></li>
</ul>
]]></content>
        <author>
            <name>GitHub</name>
            <email>GitHub@noreply.github.com</email>
            <uri>https://github.com/advisories/GHSA-5wvp-7f3h-6wmm</uri>
        </author>
        <category label="severity" term="CRITICAL"/>
        <published>2023-11-09T09:30:26.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[[httpie] HTTPie allows attackers to eavesdrop on communications between the host and server via a man-in-the-middle attack]]></title>
        <id>https://github.com/advisories/GHSA-8r96-8889-qg2x</id>
        <link href="https://github.com/advisories/GHSA-8r96-8889-qg2x"/>
        <updated>2023-11-16T22:16:45.000Z</updated>
        <content type="html"><![CDATA[<p>Missing SSL certificate validation in HTTPie v3.2.2 allows attackers to eavesdrop on communications between the host and server via a man-in-the-middle attack.</p>
<h3 id="references">References</h3>
<ul>
<li><a href="https://nvd.nist.gov/vuln/detail/CVE-2023-48052">https://nvd.nist.gov/vuln/detail/CVE-2023-48052</a></li>
<li><a href="https://gxx777.github.io/HTTPie_3.2.2_Cryptographic_API_Misuse_Vulnerability.md">https://gxx777.github.io/HTTPie_3.2.2_Cryptographic_API_Misuse_Vulnerability.md</a></li>
<li><a href="https://github.com/httpie/cli/blob/master/httpie/client.py#L33">https://github.com/httpie/cli/blob/master/httpie/client.py#L33</a></li>
<li><a href="https://github.com/httpie/cli/blob/master/httpie/internal/update_warnings.py#L44">https://github.com/httpie/cli/blob/master/httpie/internal/update_warnings.py#L44</a></li>
<li><a href="https://github.com/advisories/GHSA-8r96-8889-qg2x">https://github.com/advisories/GHSA-8r96-8889-qg2x</a></li>
</ul>
]]></content>
        <author>
            <name>GitHub</name>
            <email>GitHub@noreply.github.com</email>
            <uri>https://github.com/advisories/GHSA-8r96-8889-qg2x</uri>
        </author>
        <category label="severity" term="MODERATE"/>
        <published>2023-11-16T18:30:31.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[[mlflow] MLflow allowed arbitrary files to be PUT onto the server]]></title>
        <id>https://github.com/advisories/GHSA-f798-qm4r-23r5</id>
        <link href="https://github.com/advisories/GHSA-f798-qm4r-23r5"/>
        <updated>2023-11-16T21:25:20.000Z</updated>
        <content type="html"><![CDATA[<p>MLflow allowed arbitrary files to be PUT onto the server.</p>
<h3 id="references">References</h3>
<ul>
<li><a href="https://nvd.nist.gov/vuln/detail/CVE-2023-6015">https://nvd.nist.gov/vuln/detail/CVE-2023-6015</a></li>
<li><a href="https://huntr.com/bounties/43e6fb72-676e-4670-a225-15d6836f65d3">https://huntr.com/bounties/43e6fb72-676e-4670-a225-15d6836f65d3</a></li>
<li><a href="https://github.com/mlflow/mlflow/pull/10330">https://github.com/mlflow/mlflow/pull/10330</a></li>
<li><a href="https://github.com/mlflow/mlflow/commit/cf83dad4df26dd4a850622fe8a51ccab1471a5e7">https://github.com/mlflow/mlflow/commit/cf83dad4df26dd4a850622fe8a51ccab1471a5e7</a></li>
<li><a href="https://github.com/advisories/GHSA-f798-qm4r-23r5">https://github.com/advisories/GHSA-f798-qm4r-23r5</a></li>
</ul>
]]></content>
        <author>
            <name>GitHub</name>
            <email>GitHub@noreply.github.com</email>
            <uri>https://github.com/advisories/GHSA-f798-qm4r-23r5</uri>
        </author>
        <category label="severity" term="CRITICAL"/>
        <published>2023-11-16T18:30:31.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[[galaxy-importer] Ansible galaxy-importer Path Traversal vulnerability]]></title>
        <id>https://github.com/advisories/GHSA-55g2-vm3q-7w52</id>
        <link href="https://github.com/advisories/GHSA-55g2-vm3q-7w52"/>
        <updated>2023-11-16T20:16:05.000Z</updated>
        <content type="html"><![CDATA[<p>A path traversal vulnerability exists in Ansible when extracting tarballs. An attacker could craft a malicious tarball so that when using the galaxy importer of Ansible Automation Hub, a symlink could be dropped on the disk, resulting in files being overwritten.</p>
<h3 id="references">References</h3>
<ul>
<li><a href="https://nvd.nist.gov/vuln/detail/CVE-2023-5189">https://nvd.nist.gov/vuln/detail/CVE-2023-5189</a></li>
<li><a href="https://access.redhat.com/security/cve/CVE-2023-5189">https://access.redhat.com/security/cve/CVE-2023-5189</a></li>
<li><a href="https://bugzilla.redhat.com/show_bug.cgi?id=2234387">https://bugzilla.redhat.com/show_bug.cgi?id=2234387</a></li>
<li><a href="https://github.com/ansible/galaxy-importer/blob/2c5c7c05fdfb0835878234b36de32902c703616d/galaxy_importer/collection.py#L160-L165">https://github.com/ansible/galaxy-importer/blob/2c5c7c05fdfb0835878234b36de32902c703616d/galaxy_importer/collection.py#L160-L165</a></li>
<li><a href="https://github.com/advisories/GHSA-55g2-vm3q-7w52">https://github.com/advisories/GHSA-55g2-vm3q-7w52</a></li>
</ul>
]]></content>
        <author>
            <name>GitHub</name>
            <email>GitHub@noreply.github.com</email>
            <uri>https://github.com/advisories/GHSA-55g2-vm3q-7w52</uri>
        </author>
        <category label="severity" term="MODERATE"/>
        <published>2023-11-15T00:31:08.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[[ethyca-fides] Ethyca Fides Cryptographically Weak Generation of One-Time Codes for Identity Verification]]></title>
        <id>https://github.com/advisories/GHSA-82vr-5769-6358</id>
        <link href="https://github.com/advisories/GHSA-82vr-5769-6358"/>
        <updated>2023-11-16T14:33:07.000Z</updated>
        <content type="html"><![CDATA[<h3 id="impact">Impact</h3>
<p>The Fides Privacy Center allows data subject users to submit privacy and consent requests to data controller users of the Fides web application.</p>
<p>Privacy requests allow data subjects to submit a request to access all person data held by the data controller, or delete/erase it.  Consent request allows data subject users to modify their privacy preferences for how the data controller uses their personal data e.g. data sales and sharing consent opt-in/opt-out.</p>
<p>If <code>subject_identity_verification_required</code> in the <code>[execution]</code> section of <code>fides.toml</code> or the env var <code>FIDES__EXECUTION__SUBJECT_IDENTITY_VERIFICATION_REQUIRED</code> is set to <code>True</code> on the fides webserver backend, data subjects are sent a one-time code to their email address or phone number, depending on messaging configuration, and the one-time code must be entered in the Privacy Center UI by the data subject before the privacy or consent request is submitted.</p>
<p>It was identified that the one-time code values for these requests were generated by the python <code>random</code> module, a cryptographically weak pseduo-random number generator (PNRG). If an attacker generates several hundred consecutive one-time codes, this vulnerability allows the attacker to predict all future one-time code values during the lifetime of the backend python process.</p>
<p>There is no security impact on data access requests as the personal data download package is not shared in the Privacy Center itself. However, this vulnerability allows an attacker to (i) submit a verified data erasure request, resulting in deletion of data for the targeted user and (ii) submit a verified consent request, modifying a user's privacy preferences.</p>
<h3 id="patches">Patches</h3>
<p>The vulnerability has been patched in Fides version <code>2.24.0</code>. Users are advised to upgrade to this version or later to secure their systems against this threat.</p>
<h3 id="workarounds">Workarounds</h3>
<p>None</p>
<h3 id="references">References</h3>
<ul>
<li><a href="https://peps.python.org/pep-0506/">https://peps.python.org/pep-0506/</a></li>
</ul>
<h3 id="references-1">References</h3>
<ul>
<li><a href="https://github.com/ethyca/fides/security/advisories/GHSA-82vr-5769-6358">https://github.com/ethyca/fides/security/advisories/GHSA-82vr-5769-6358</a></li>
<li><a href="https://nvd.nist.gov/vuln/detail/CVE-2023-48224">https://nvd.nist.gov/vuln/detail/CVE-2023-48224</a></li>
<li><a href="https://github.com/ethyca/fides/commit/685bae61c203d29ed189f4b066a5223a9bb774c6">https://github.com/ethyca/fides/commit/685bae61c203d29ed189f4b066a5223a9bb774c6</a></li>
<li><a href="https://peps.python.org/pep-0506/">https://peps.python.org/pep-0506/</a></li>
<li><a href="https://github.com/advisories/GHSA-82vr-5769-6358">https://github.com/advisories/GHSA-82vr-5769-6358</a></li>
</ul>
]]></content>
        <author>
            <name>GitHub</name>
            <email>GitHub@noreply.github.com</email>
            <uri>https://github.com/advisories/GHSA-82vr-5769-6358</uri>
        </author>
        <category label="severity" term="HIGH"/>
        <published>2023-11-16T14:33:06.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[[python-jose] python-jose failure to use a constant time comparison for HMAC keys]]></title>
        <id>https://github.com/advisories/GHSA-w799-prg3-cx77</id>
        <link href="https://github.com/advisories/GHSA-w799-prg3-cx77"/>
        <updated>2023-11-16T05:04:43.000Z</updated>
        <content type="html"><![CDATA[<p>python-jose before 1.3.2 allows attackers to have unspecified impact by leveraging failure to use a constant time comparison for HMAC keys.</p>
<h3 id="references">References</h3>
<ul>
<li><a href="https://nvd.nist.gov/vuln/detail/CVE-2016-7036">https://nvd.nist.gov/vuln/detail/CVE-2016-7036</a></li>
<li><a href="https://github.com/mpdavis/python-jose/releases/tag/1.3.2">https://github.com/mpdavis/python-jose/releases/tag/1.3.2</a></li>
<li><a href="https://web.archive.org/web/20210123221523/http://www.securityfocus.com/bid/95845">https://web.archive.org/web/20210123221523/http://www.securityfocus.com/bid/95845</a></li>
<li><a href="https://github.com/mpdavis/python-jose/commit/73007d6887a7517ac07c6e755e494baee49ef513">https://github.com/mpdavis/python-jose/commit/73007d6887a7517ac07c6e755e494baee49ef513</a></li>
<li><a href="https://github.com/advisories/GHSA-w799-prg3-cx77">https://github.com/advisories/GHSA-w799-prg3-cx77</a></li>
</ul>
]]></content>
        <author>
            <name>GitHub</name>
            <email>GitHub@noreply.github.com</email>
            <uri>https://github.com/advisories/GHSA-w799-prg3-cx77</uri>
        </author>
        <category label="severity" term="CRITICAL"/>
        <published>2022-05-17T03:02:29.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[[scrapy] Scrapy before 2.6.2 and 1.8.3 vulnerable to one proxy sending credentials to another]]></title>
        <id>https://github.com/advisories/GHSA-9x8m-2xpf-crp3</id>
        <link href="https://github.com/advisories/GHSA-9x8m-2xpf-crp3"/>
        <updated>2023-11-15T18:31:23.000Z</updated>
        <content type="html"><![CDATA[<h3 id="impact">Impact</h3>
<p>When the <a href="https://docs.scrapy.org/en/2.6/topics/downloader-middleware.html#module-scrapy.downloadermiddlewares.httpproxy">built-in HTTP proxy downloader middleware</a> processes a request with <code>proxy</code> metadata, and that <code>proxy</code> metadata includes proxy credentials, the built-in HTTP proxy downloader middleware sets the <code>Proxy-Authentication</code> header, but only if that header is not already set.</p>
<p>There are third-party proxy-rotation downloader middlewares that set different <code>proxy</code> metadata every time they process a request.</p>
<p>Because of request retries and redirects, the same request can be processed by downloader middlewares more than once, including both the built-in HTTP proxy downloader middleware and any third-party proxy-rotation downloader middleware.</p>
<p>These third-party proxy-rotation downloader middlewares could change the <code>proxy</code> metadata of a request to a new value, but fail to remove the <code>Proxy-Authentication</code> header from the previous value of the <code>proxy</code> metadata, causing the credentials of one proxy to be leaked to a different proxy.</p>
<p>If you rotate proxies from different proxy providers, and any of those proxies requires credentials, you are affected, unless you are handling proxy rotation as described under <strong>Workarounds</strong> below. If you use a third-party downloader middleware for proxy rotation, the same applies to that downloader middleware, and installing a patched version of Scrapy may not be enough; patching that downloader middlware may be necessary as well.</p>
<h3 id="patches">Patches</h3>
<p>Upgrade to Scrapy 2.6.2.</p>
<p>If you are using Scrapy 1.8 or a lower version, and upgrading to Scrapy 2.6.2 is not an option, you may upgrade to Scrapy 1.8.3 instead.</p>
<h3 id="workarounds">Workarounds</h3>
<p>If you cannot upgrade, make sure that any code that changes the value of the <code>proxy</code> request meta also removes the <code>Proxy-Authorization</code> header from the request if present.</p>
<h3 id="for-more-information">For more information</h3>
<p>If you have any questions or comments about this advisory:</p>
<ul>
<li><a href="https://github.com/scrapy/scrapy/issues">Open an issue</a></li>
<li><a href="mailto:opensource@zyte.com">Email us</a></li>
</ul>
<h3 id="references">References</h3>
<ul>
<li><a href="https://github.com/scrapy/scrapy/security/advisories/GHSA-9x8m-2xpf-crp3">https://github.com/scrapy/scrapy/security/advisories/GHSA-9x8m-2xpf-crp3</a></li>
<li><a href="https://github.com/scrapy/scrapy/commit/af7dd16d8ded3e6cb2946603688f4f4a5212e80f">https://github.com/scrapy/scrapy/commit/af7dd16d8ded3e6cb2946603688f4f4a5212e80f</a></li>
<li><a href="https://github.com/advisories/GHSA-9x8m-2xpf-crp3">https://github.com/advisories/GHSA-9x8m-2xpf-crp3</a></li>
</ul>
]]></content>
        <author>
            <name>GitHub</name>
            <email>GitHub@noreply.github.com</email>
            <uri>https://github.com/advisories/GHSA-9x8m-2xpf-crp3</uri>
        </author>
        <category label="severity" term="MODERATE"/>
        <published>2022-07-29T22:26:57.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[[scrapy] Scrapy before 2.6.2 and 1.8.3 vulnerable to one proxy sending credentials to another]]></title>
        <id>https://github.com/advisories/GHSA-9x8m-2xpf-crp3</id>
        <link href="https://github.com/advisories/GHSA-9x8m-2xpf-crp3"/>
        <updated>2023-11-15T18:31:23.000Z</updated>
        <content type="html"><![CDATA[<h3 id="impact">Impact</h3>
<p>When the <a href="https://docs.scrapy.org/en/2.6/topics/downloader-middleware.html#module-scrapy.downloadermiddlewares.httpproxy">built-in HTTP proxy downloader middleware</a> processes a request with <code>proxy</code> metadata, and that <code>proxy</code> metadata includes proxy credentials, the built-in HTTP proxy downloader middleware sets the <code>Proxy-Authentication</code> header, but only if that header is not already set.</p>
<p>There are third-party proxy-rotation downloader middlewares that set different <code>proxy</code> metadata every time they process a request.</p>
<p>Because of request retries and redirects, the same request can be processed by downloader middlewares more than once, including both the built-in HTTP proxy downloader middleware and any third-party proxy-rotation downloader middleware.</p>
<p>These third-party proxy-rotation downloader middlewares could change the <code>proxy</code> metadata of a request to a new value, but fail to remove the <code>Proxy-Authentication</code> header from the previous value of the <code>proxy</code> metadata, causing the credentials of one proxy to be leaked to a different proxy.</p>
<p>If you rotate proxies from different proxy providers, and any of those proxies requires credentials, you are affected, unless you are handling proxy rotation as described under <strong>Workarounds</strong> below. If you use a third-party downloader middleware for proxy rotation, the same applies to that downloader middleware, and installing a patched version of Scrapy may not be enough; patching that downloader middlware may be necessary as well.</p>
<h3 id="patches">Patches</h3>
<p>Upgrade to Scrapy 2.6.2.</p>
<p>If you are using Scrapy 1.8 or a lower version, and upgrading to Scrapy 2.6.2 is not an option, you may upgrade to Scrapy 1.8.3 instead.</p>
<h3 id="workarounds">Workarounds</h3>
<p>If you cannot upgrade, make sure that any code that changes the value of the <code>proxy</code> request meta also removes the <code>Proxy-Authorization</code> header from the request if present.</p>
<h3 id="for-more-information">For more information</h3>
<p>If you have any questions or comments about this advisory:</p>
<ul>
<li><a href="https://github.com/scrapy/scrapy/issues">Open an issue</a></li>
<li><a href="mailto:opensource@zyte.com">Email us</a></li>
</ul>
<h3 id="references">References</h3>
<ul>
<li><a href="https://github.com/scrapy/scrapy/security/advisories/GHSA-9x8m-2xpf-crp3">https://github.com/scrapy/scrapy/security/advisories/GHSA-9x8m-2xpf-crp3</a></li>
<li><a href="https://github.com/scrapy/scrapy/commit/af7dd16d8ded3e6cb2946603688f4f4a5212e80f">https://github.com/scrapy/scrapy/commit/af7dd16d8ded3e6cb2946603688f4f4a5212e80f</a></li>
<li><a href="https://github.com/advisories/GHSA-9x8m-2xpf-crp3">https://github.com/advisories/GHSA-9x8m-2xpf-crp3</a></li>
</ul>
]]></content>
        <author>
            <name>GitHub</name>
            <email>GitHub@noreply.github.com</email>
            <uri>https://github.com/advisories/GHSA-9x8m-2xpf-crp3</uri>
        </author>
        <category label="severity" term="MODERATE"/>
        <published>2022-07-29T22:26:57.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[[scrapy] Scrapy cookie-setting is not restricted based on the public suffix list]]></title>
        <id>https://github.com/advisories/GHSA-mfjm-vh54-3f96</id>
        <link href="https://github.com/advisories/GHSA-mfjm-vh54-3f96"/>
        <updated>2023-11-15T18:30:38.000Z</updated>
        <content type="html"><![CDATA[<h3 id="impact">Impact</h3>
<p>Responses from domain names whose public domain name suffix contains 1 or more periods (e.g. responses from <code>example.co.uk</code>, given its public domain name suffix is <code>co.uk</code>) are able to set cookies that are included in requests to any other domain sharing the same domain name suffix.</p>
<h3 id="patches">Patches</h3>
<p>Upgrade to Scrapy 2.6.0, which restricts cookies with their domain set to any of those in the <a href="https://publicsuffix.org/">public suffix list</a>.</p>
<p>If you are using Scrapy 1.8 or a lower version, and upgrading to Scrapy 2.6.0 is not an option, you may upgrade to Scrapy 1.8.2 instead.</p>
<h3 id="workarounds">Workarounds</h3>
<p>The only workaround for unpatched versions of Scrapy is to <a href="https://docs.scrapy.org/en/latest/topics/downloader-middleware.html#std-setting-COOKIES_ENABLED">disable cookies altogether</a>, or <a href="https://docs.scrapy.org/en/latest/topics/spiders.html#scrapy.spiders.Spider.allowed_domains">limit target domains</a> to a subset that does not include domain names with one of the public domain suffixes affected (those with 1 or more periods).</p>
<h3 id="references">References</h3>
<ul>
<li><a href="https://publicsuffix.org/">https://publicsuffix.org/</a></li>
</ul>
<h3 id="for-more-information">For more information</h3>
<p>If you have any questions or comments about this advisory:</p>
<ul>
<li><a href="https://github.com/scrapy/scrapy/issues">Open an issue</a></li>
<li><a href="mailto:opensource@zyte.com">Email us</a></li>
</ul>
<h3 id="references-1">References</h3>
<ul>
<li><a href="https://github.com/scrapy/scrapy/security/advisories/GHSA-mfjm-vh54-3f96">https://github.com/scrapy/scrapy/security/advisories/GHSA-mfjm-vh54-3f96</a></li>
<li><a href="https://github.com/scrapy/scrapy/commit/e865c4430e58a4faa0e0766b23830f8423d6167a">https://github.com/scrapy/scrapy/commit/e865c4430e58a4faa0e0766b23830f8423d6167a</a></li>
<li><a href="https://github.com/advisories/GHSA-mfjm-vh54-3f96">https://github.com/advisories/GHSA-mfjm-vh54-3f96</a></li>
</ul>
]]></content>
        <author>
            <name>GitHub</name>
            <email>GitHub@noreply.github.com</email>
            <uri>https://github.com/advisories/GHSA-mfjm-vh54-3f96</uri>
        </author>
        <category label="severity" term="MODERATE"/>
        <published>2022-03-01T22:13:28.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[[scrapy] Scrapy cookie-setting is not restricted based on the public suffix list]]></title>
        <id>https://github.com/advisories/GHSA-mfjm-vh54-3f96</id>
        <link href="https://github.com/advisories/GHSA-mfjm-vh54-3f96"/>
        <updated>2023-11-15T18:30:38.000Z</updated>
        <content type="html"><![CDATA[<h3 id="impact">Impact</h3>
<p>Responses from domain names whose public domain name suffix contains 1 or more periods (e.g. responses from <code>example.co.uk</code>, given its public domain name suffix is <code>co.uk</code>) are able to set cookies that are included in requests to any other domain sharing the same domain name suffix.</p>
<h3 id="patches">Patches</h3>
<p>Upgrade to Scrapy 2.6.0, which restricts cookies with their domain set to any of those in the <a href="https://publicsuffix.org/">public suffix list</a>.</p>
<p>If you are using Scrapy 1.8 or a lower version, and upgrading to Scrapy 2.6.0 is not an option, you may upgrade to Scrapy 1.8.2 instead.</p>
<h3 id="workarounds">Workarounds</h3>
<p>The only workaround for unpatched versions of Scrapy is to <a href="https://docs.scrapy.org/en/latest/topics/downloader-middleware.html#std-setting-COOKIES_ENABLED">disable cookies altogether</a>, or <a href="https://docs.scrapy.org/en/latest/topics/spiders.html#scrapy.spiders.Spider.allowed_domains">limit target domains</a> to a subset that does not include domain names with one of the public domain suffixes affected (those with 1 or more periods).</p>
<h3 id="references">References</h3>
<ul>
<li><a href="https://publicsuffix.org/">https://publicsuffix.org/</a></li>
</ul>
<h3 id="for-more-information">For more information</h3>
<p>If you have any questions or comments about this advisory:</p>
<ul>
<li><a href="https://github.com/scrapy/scrapy/issues">Open an issue</a></li>
<li><a href="mailto:opensource@zyte.com">Email us</a></li>
</ul>
<h3 id="references-1">References</h3>
<ul>
<li><a href="https://github.com/scrapy/scrapy/security/advisories/GHSA-mfjm-vh54-3f96">https://github.com/scrapy/scrapy/security/advisories/GHSA-mfjm-vh54-3f96</a></li>
<li><a href="https://github.com/scrapy/scrapy/commit/e865c4430e58a4faa0e0766b23830f8423d6167a">https://github.com/scrapy/scrapy/commit/e865c4430e58a4faa0e0766b23830f8423d6167a</a></li>
<li><a href="https://github.com/advisories/GHSA-mfjm-vh54-3f96">https://github.com/advisories/GHSA-mfjm-vh54-3f96</a></li>
</ul>
]]></content>
        <author>
            <name>GitHub</name>
            <email>GitHub@noreply.github.com</email>
            <uri>https://github.com/advisories/GHSA-mfjm-vh54-3f96</uri>
        </author>
        <category label="severity" term="MODERATE"/>
        <published>2022-03-01T22:13:28.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[[scrapy] Incorrect Authorization and Exposure of Sensitive Information to an Unauthorized Actor in scrapy]]></title>
        <id>https://github.com/advisories/GHSA-cjvr-mfj7-j4j8</id>
        <link href="https://github.com/advisories/GHSA-cjvr-mfj7-j4j8"/>
        <updated>2023-11-15T18:29:54.000Z</updated>
        <content type="html"><![CDATA[<h3 id="impact">Impact</h3>
<p>If you manually define cookies on a <a href="https://docs.scrapy.org/en/latest/topics/request-response.html#scrapy.http.Request"><code>Request</code></a> object, and that <code>Request</code> object gets a redirect response, the new <code>Request</code> object scheduled to follow the redirect keeps those user-defined cookies, regardless of the target domain.</p>
<h3 id="patches">Patches</h3>
<p>Upgrade to Scrapy 2.6.0, which resets cookies when creating <code>Request</code> objects to follow redirects¹, and drops the <code>Cookie</code> header if manually-defined if the redirect target URL domain name does not match the source URL domain name².</p>
<p>If you are using Scrapy 1.8 or a lower version, and upgrading to Scrapy 2.6.0 is not an option, you may upgrade to Scrapy 1.8.2 instead.</p>
<p>¹ At that point the original, user-set cookies have been processed by the cookie middleware into the global or request-specific cookiejar, with their domain restricted to the domain of the original URL, so when the cookie middleware processes the new (redirect) request it will incorporate those cookies into the new request as long as the domain of the new request matches the domain of the original request.</p>
<p>² This prevents cookie leaks to unintended domains even if the cookies middleware is not used.</p>
<h3 id="workarounds">Workarounds</h3>
<p>If you cannot upgrade, set your cookies using a list of dictionaries instead of a single dictionary, as described in the <a href="https://docs.scrapy.org/en/latest/topics/request-response.html#scrapy.http.Request"><code>Request</code> documentation</a>, and set the right domain for each cookie.</p>
<p>Alternatively, you can <a href="https://docs.scrapy.org/en/latest/topics/downloader-middleware.html#std-setting-COOKIES_ENABLED">disable cookies altogether</a>, or <a href="https://docs.scrapy.org/en/latest/topics/spiders.html#scrapy.spiders.Spider.allowed_domains">limit target domains</a> to domains that you trust with all your user-set cookies.</p>
<h3 id="references">References</h3>
<ul>
<li>Originally reported at <a href="https://huntr.dev/bounties/3da527b1-2348-4f69-9e88-2e11a96ac585/">huntr.dev</a></li>
</ul>
<h3 id="for-more-information">For more information</h3>
<p>If you have any questions or comments about this advisory:</p>
<ul>
<li><a href="https://github.com/scrapy/scrapy/issues">Open an issue</a></li>
<li><a href="mailto:opensource@zyte.com">Email us</a></li>
</ul>
<h3 id="references-1">References</h3>
<ul>
<li><a href="https://github.com/scrapy/scrapy/security/advisories/GHSA-cjvr-mfj7-j4j8">https://github.com/scrapy/scrapy/security/advisories/GHSA-cjvr-mfj7-j4j8</a></li>
<li><a href="https://github.com/scrapy/scrapy/commit/8ce01b3b76d4634f55067d6cfdf632ec70ba304a">https://github.com/scrapy/scrapy/commit/8ce01b3b76d4634f55067d6cfdf632ec70ba304a</a></li>
<li><a href="https://nvd.nist.gov/vuln/detail/CVE-2022-0577">https://nvd.nist.gov/vuln/detail/CVE-2022-0577</a></li>
<li><a href="https://huntr.dev/bounties/3da527b1-2348-4f69-9e88-2e11a96ac585">https://huntr.dev/bounties/3da527b1-2348-4f69-9e88-2e11a96ac585</a></li>
<li><a href="https://lists.debian.org/debian-lts-announce/2022/03/msg00021.html">https://lists.debian.org/debian-lts-announce/2022/03/msg00021.html</a></li>
<li><a href="https://github.com/pypa/advisory-database/tree/main/vulns/scrapy/PYSEC-2022-159.yaml">https://github.com/pypa/advisory-database/tree/main/vulns/scrapy/PYSEC-2022-159.yaml</a></li>
<li><a href="https://github.com/advisories/GHSA-cjvr-mfj7-j4j8">https://github.com/advisories/GHSA-cjvr-mfj7-j4j8</a></li>
</ul>
]]></content>
        <author>
            <name>GitHub</name>
            <email>GitHub@noreply.github.com</email>
            <uri>https://github.com/advisories/GHSA-cjvr-mfj7-j4j8</uri>
        </author>
        <category label="severity" term="MODERATE"/>
        <published>2022-03-01T22:12:47.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[[scrapy] Incorrect Authorization and Exposure of Sensitive Information to an Unauthorized Actor in scrapy]]></title>
        <id>https://github.com/advisories/GHSA-cjvr-mfj7-j4j8</id>
        <link href="https://github.com/advisories/GHSA-cjvr-mfj7-j4j8"/>
        <updated>2023-11-15T18:29:54.000Z</updated>
        <content type="html"><![CDATA[<h3 id="impact">Impact</h3>
<p>If you manually define cookies on a <a href="https://docs.scrapy.org/en/latest/topics/request-response.html#scrapy.http.Request"><code>Request</code></a> object, and that <code>Request</code> object gets a redirect response, the new <code>Request</code> object scheduled to follow the redirect keeps those user-defined cookies, regardless of the target domain.</p>
<h3 id="patches">Patches</h3>
<p>Upgrade to Scrapy 2.6.0, which resets cookies when creating <code>Request</code> objects to follow redirects¹, and drops the <code>Cookie</code> header if manually-defined if the redirect target URL domain name does not match the source URL domain name².</p>
<p>If you are using Scrapy 1.8 or a lower version, and upgrading to Scrapy 2.6.0 is not an option, you may upgrade to Scrapy 1.8.2 instead.</p>
<p>¹ At that point the original, user-set cookies have been processed by the cookie middleware into the global or request-specific cookiejar, with their domain restricted to the domain of the original URL, so when the cookie middleware processes the new (redirect) request it will incorporate those cookies into the new request as long as the domain of the new request matches the domain of the original request.</p>
<p>² This prevents cookie leaks to unintended domains even if the cookies middleware is not used.</p>
<h3 id="workarounds">Workarounds</h3>
<p>If you cannot upgrade, set your cookies using a list of dictionaries instead of a single dictionary, as described in the <a href="https://docs.scrapy.org/en/latest/topics/request-response.html#scrapy.http.Request"><code>Request</code> documentation</a>, and set the right domain for each cookie.</p>
<p>Alternatively, you can <a href="https://docs.scrapy.org/en/latest/topics/downloader-middleware.html#std-setting-COOKIES_ENABLED">disable cookies altogether</a>, or <a href="https://docs.scrapy.org/en/latest/topics/spiders.html#scrapy.spiders.Spider.allowed_domains">limit target domains</a> to domains that you trust with all your user-set cookies.</p>
<h3 id="references">References</h3>
<ul>
<li>Originally reported at <a href="https://huntr.dev/bounties/3da527b1-2348-4f69-9e88-2e11a96ac585/">huntr.dev</a></li>
</ul>
<h3 id="for-more-information">For more information</h3>
<p>If you have any questions or comments about this advisory:</p>
<ul>
<li><a href="https://github.com/scrapy/scrapy/issues">Open an issue</a></li>
<li><a href="mailto:opensource@zyte.com">Email us</a></li>
</ul>
<h3 id="references-1">References</h3>
<ul>
<li><a href="https://github.com/scrapy/scrapy/security/advisories/GHSA-cjvr-mfj7-j4j8">https://github.com/scrapy/scrapy/security/advisories/GHSA-cjvr-mfj7-j4j8</a></li>
<li><a href="https://github.com/scrapy/scrapy/commit/8ce01b3b76d4634f55067d6cfdf632ec70ba304a">https://github.com/scrapy/scrapy/commit/8ce01b3b76d4634f55067d6cfdf632ec70ba304a</a></li>
<li><a href="https://nvd.nist.gov/vuln/detail/CVE-2022-0577">https://nvd.nist.gov/vuln/detail/CVE-2022-0577</a></li>
<li><a href="https://huntr.dev/bounties/3da527b1-2348-4f69-9e88-2e11a96ac585">https://huntr.dev/bounties/3da527b1-2348-4f69-9e88-2e11a96ac585</a></li>
<li><a href="https://lists.debian.org/debian-lts-announce/2022/03/msg00021.html">https://lists.debian.org/debian-lts-announce/2022/03/msg00021.html</a></li>
<li><a href="https://github.com/pypa/advisory-database/tree/main/vulns/scrapy/PYSEC-2022-159.yaml">https://github.com/pypa/advisory-database/tree/main/vulns/scrapy/PYSEC-2022-159.yaml</a></li>
<li><a href="https://github.com/advisories/GHSA-cjvr-mfj7-j4j8">https://github.com/advisories/GHSA-cjvr-mfj7-j4j8</a></li>
</ul>
]]></content>
        <author>
            <name>GitHub</name>
            <email>GitHub@noreply.github.com</email>
            <uri>https://github.com/advisories/GHSA-cjvr-mfj7-j4j8</uri>
        </author>
        <category label="severity" term="MODERATE"/>
        <published>2022-03-01T22:12:47.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[[Scrapy] Scrapy HTTP authentication credentials potentially leaked to target websites ]]></title>
        <id>https://github.com/advisories/GHSA-jwqp-28gf-p498</id>
        <link href="https://github.com/advisories/GHSA-jwqp-28gf-p498"/>
        <updated>2023-11-15T18:27:38.000Z</updated>
        <content type="html"><![CDATA[<h3 id="impact">Impact</h3>
<p>If you use <a href="http://doc.scrapy.org/en/latest/topics/downloader-middleware.html#module-scrapy.downloadermiddlewares.httpauth"><code>HttpAuthMiddleware</code></a> (i.e. the <code>http_user</code> and <code>http_pass</code> spider attributes) for HTTP authentication, all requests will expose your credentials to the request target.</p>
<p>This includes requests generated by Scrapy components, such as <code>robots.txt</code> requests sent by Scrapy when the <code>ROBOTSTXT_OBEY</code> setting is set to <code>True</code>, or as requests reached through redirects.</p>
<h3 id="patches">Patches</h3>
<p>Upgrade to Scrapy 2.5.1 and use the new <code>http_auth_domain</code> spider attribute to control which domains are allowed to receive the configured HTTP authentication credentials.</p>
<p>If you are using Scrapy 1.8 or a lower version, and upgrading to Scrapy 2.5.1 is not an option, you may upgrade to Scrapy 1.8.1 instead.</p>
<h3 id="workarounds">Workarounds</h3>
<p>If you cannot upgrade, set your HTTP authentication credentials on a per-request basis, using for example the <a href="https://w3lib.readthedocs.io/en/latest/w3lib.html#w3lib.http.basic_auth_header"><code>w3lib.http.basic_auth_header</code></a> function to convert your credentials into a value that you can assign to the <code>Authorization</code> header of your request, instead of defining your credentials globally using <a href="http://doc.scrapy.org/en/latest/topics/downloader-middleware.html#module-scrapy.downloadermiddlewares.httpauth"><code>HttpAuthMiddleware</code></a>.</p>
<h3 id="for-more-information">For more information</h3>
<p>If you have any questions or comments about this advisory:</p>
<ul>
<li><a href="https://github.com/scrapy/scrapy/issues">Open an issue</a></li>
<li><a href="mailto:opensource@zyte.com">Email us</a></li>
</ul>
<h3 id="references">References</h3>
<ul>
<li><a href="https://github.com/scrapy/scrapy/security/advisories/GHSA-jwqp-28gf-p498">https://github.com/scrapy/scrapy/security/advisories/GHSA-jwqp-28gf-p498</a></li>
<li><a href="https://github.com/scrapy/scrapy/commit/b01d69a1bf48060daec8f751368622352d8b85a6">https://github.com/scrapy/scrapy/commit/b01d69a1bf48060daec8f751368622352d8b85a6</a></li>
<li><a href="https://w3lib.readthedocs.io/en/latest/w3lib.html#w3lib.http.basic_auth_header">https://w3lib.readthedocs.io/en/latest/w3lib.html#w3lib.http.basic_auth_header</a></li>
<li><a href="http://doc.scrapy.org/en/latest/topics/downloader-middleware.html#module-scrapy.downloadermiddlewares.httpauth">http://doc.scrapy.org/en/latest/topics/downloader-middleware.html#module-scrapy.downloadermiddlewares.httpauth</a></li>
<li><a href="https://nvd.nist.gov/vuln/detail/CVE-2021-41125">https://nvd.nist.gov/vuln/detail/CVE-2021-41125</a></li>
<li><a href="https://lists.debian.org/debian-lts-announce/2022/03/msg00021.html">https://lists.debian.org/debian-lts-announce/2022/03/msg00021.html</a></li>
<li><a href="https://github.com/advisories/GHSA-jwqp-28gf-p498">https://github.com/advisories/GHSA-jwqp-28gf-p498</a></li>
</ul>
]]></content>
        <author>
            <name>GitHub</name>
            <email>GitHub@noreply.github.com</email>
            <uri>https://github.com/advisories/GHSA-jwqp-28gf-p498</uri>
        </author>
        <category label="severity" term="MODERATE"/>
        <published>2021-10-06T17:46:22.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[[Scrapy] Scrapy HTTP authentication credentials potentially leaked to target websites ]]></title>
        <id>https://github.com/advisories/GHSA-jwqp-28gf-p498</id>
        <link href="https://github.com/advisories/GHSA-jwqp-28gf-p498"/>
        <updated>2023-11-15T18:27:38.000Z</updated>
        <content type="html"><![CDATA[<h3 id="impact">Impact</h3>
<p>If you use <a href="http://doc.scrapy.org/en/latest/topics/downloader-middleware.html#module-scrapy.downloadermiddlewares.httpauth"><code>HttpAuthMiddleware</code></a> (i.e. the <code>http_user</code> and <code>http_pass</code> spider attributes) for HTTP authentication, all requests will expose your credentials to the request target.</p>
<p>This includes requests generated by Scrapy components, such as <code>robots.txt</code> requests sent by Scrapy when the <code>ROBOTSTXT_OBEY</code> setting is set to <code>True</code>, or as requests reached through redirects.</p>
<h3 id="patches">Patches</h3>
<p>Upgrade to Scrapy 2.5.1 and use the new <code>http_auth_domain</code> spider attribute to control which domains are allowed to receive the configured HTTP authentication credentials.</p>
<p>If you are using Scrapy 1.8 or a lower version, and upgrading to Scrapy 2.5.1 is not an option, you may upgrade to Scrapy 1.8.1 instead.</p>
<h3 id="workarounds">Workarounds</h3>
<p>If you cannot upgrade, set your HTTP authentication credentials on a per-request basis, using for example the <a href="https://w3lib.readthedocs.io/en/latest/w3lib.html#w3lib.http.basic_auth_header"><code>w3lib.http.basic_auth_header</code></a> function to convert your credentials into a value that you can assign to the <code>Authorization</code> header of your request, instead of defining your credentials globally using <a href="http://doc.scrapy.org/en/latest/topics/downloader-middleware.html#module-scrapy.downloadermiddlewares.httpauth"><code>HttpAuthMiddleware</code></a>.</p>
<h3 id="for-more-information">For more information</h3>
<p>If you have any questions or comments about this advisory:</p>
<ul>
<li><a href="https://github.com/scrapy/scrapy/issues">Open an issue</a></li>
<li><a href="mailto:opensource@zyte.com">Email us</a></li>
</ul>
<h3 id="references">References</h3>
<ul>
<li><a href="https://github.com/scrapy/scrapy/security/advisories/GHSA-jwqp-28gf-p498">https://github.com/scrapy/scrapy/security/advisories/GHSA-jwqp-28gf-p498</a></li>
<li><a href="https://github.com/scrapy/scrapy/commit/b01d69a1bf48060daec8f751368622352d8b85a6">https://github.com/scrapy/scrapy/commit/b01d69a1bf48060daec8f751368622352d8b85a6</a></li>
<li><a href="https://w3lib.readthedocs.io/en/latest/w3lib.html#w3lib.http.basic_auth_header">https://w3lib.readthedocs.io/en/latest/w3lib.html#w3lib.http.basic_auth_header</a></li>
<li><a href="http://doc.scrapy.org/en/latest/topics/downloader-middleware.html#module-scrapy.downloadermiddlewares.httpauth">http://doc.scrapy.org/en/latest/topics/downloader-middleware.html#module-scrapy.downloadermiddlewares.httpauth</a></li>
<li><a href="https://nvd.nist.gov/vuln/detail/CVE-2021-41125">https://nvd.nist.gov/vuln/detail/CVE-2021-41125</a></li>
<li><a href="https://lists.debian.org/debian-lts-announce/2022/03/msg00021.html">https://lists.debian.org/debian-lts-announce/2022/03/msg00021.html</a></li>
<li><a href="https://github.com/advisories/GHSA-jwqp-28gf-p498">https://github.com/advisories/GHSA-jwqp-28gf-p498</a></li>
</ul>
]]></content>
        <author>
            <name>GitHub</name>
            <email>GitHub@noreply.github.com</email>
            <uri>https://github.com/advisories/GHSA-jwqp-28gf-p498</uri>
        </author>
        <category label="severity" term="MODERATE"/>
        <published>2021-10-06T17:46:22.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[[yt-dlp] yt-dlp Generic Extractor MITM Vulnerability via Arbitrary Proxy Injection]]></title>
        <id>https://github.com/advisories/GHSA-3ch3-jhc6-5r8x</id>
        <link href="https://github.com/advisories/GHSA-3ch3-jhc6-5r8x"/>
        <updated>2023-11-15T14:48:25.000Z</updated>
        <content type="html"><![CDATA[<h3 id="impact">Impact</h3>
<p>The Generic Extractor in yt-dlp is vulnerable to an attacker setting an arbitrary proxy for a request to an arbitrary url, allowing the attacker to MITM the request made from yt-dlp's HTTP session. This could lead to cookie exfiltration in some cases.</p>
<details>

<p>To pass extra control data between extractors (such as headers like <code>Referer</code>), yt-dlp employs a concept of "url smuggling". This works by adding this extra data as json to the url fragment ("smuggling") that is then passed on to an extractor. The receiving extractor then "unsmuggles" the data from the input url. This functionality is intended to be internal only.</p>
<p>Currently, the Generic extractor supports receiving an arbitrary dictionary of HTTP headers in a smuggled url, of which it extracts and adds them to the initial request it makes to such url. This is useful when a url sent to the Generic extractor needs a <code>Referer</code> header sent with it, for example.</p>
<p>Additionally, yt-dlp has internal headers to set a proxy for a request: <code>Ytdl-request-proxy</code> and <code>Ytdl-socks-proxy</code>. While these are deprecated, internally <code>Ytdl-request-proxy</code> is still used for <code>--geo-verification-proxy</code>.</p>
<p>However, it is possible for a maliciously crafted site include these smuggled options in a url which then the Generic extractor extracts and redirects to itself.  This allows a malicious website to <strong>set an arbitrary proxy for an arbitrary url that the Generic extractor will request.</strong></p>
<p>This could allow for the following, but not limited too:</p>
<ul>
<li>An attacker can MITM a request it asks yt-dlp to make to <strong>any</strong> website.<ul>
<li>If a user has loaded cookies into yt-dlp for the target site, which are not marked as <a href="https://en.wikipedia.org/wiki/Secure_cookie">secure</a>, they could be exfiltrated by the attacker.</li>
<li>Fortunately most sites are HTTPS and should be setting cookies as secure.</li>
</ul>
</li>
<li>An attacker can set cookies for an arbitrary site.</li>
</ul>
<p>An example malicious webpage:</p>
<pre><code class="language-html">&lt;!DOCTYPE html&gt;
&lt;cinerama.embedPlayer('t','{{ target_site }}#__youtubedl_smuggle=%7B%22http_headers%22:%7B%22Ytdl-request-proxy%22:%22{{ proxy url }}%22%7D,%22fake%22:%22.smil/manifest%22%7D')
</code></pre>
<p>Where <code>{{ target_site }}</code> is the URL Generic extractor will request and <code>{{ proxy url }}</code> is the proxy to proxy the request for this url through.</p>
</details>

<h3 id="patches">Patches</h3>
<ul>
<li>We have removed the ability to smuggle <code>http_headers</code> to the Generic extractor, as well as other extractors that use the same pattern.</li>
</ul>
<h3 id="workarounds">Workarounds</h3>
<ul>
<li>Disable Generic extractor (<code>--ies default,-generic</code>), or only pass trusted sites with trusted content.</li>
<li>Take caution when using <code>--no-check-certificate</code>.</li>
</ul>
<h3 id="references">References</h3>
<ul>
<li><a href="https://github.com/yt-dlp/yt-dlp/security/advisories/GHSA-3ch3-jhc6-5r8x">https://github.com/yt-dlp/yt-dlp/security/advisories/GHSA-3ch3-jhc6-5r8x</a></li>
<li><a href="https://nvd.nist.gov/vuln/detail/CVE-2023-46121">https://nvd.nist.gov/vuln/detail/CVE-2023-46121</a></li>
<li><a href="https://github.com/yt-dlp/yt-dlp/releases/tag/2023.11.14">https://github.com/yt-dlp/yt-dlp/releases/tag/2023.11.14</a></li>
<li><a href="https://github.com/yt-dlp/yt-dlp/commit/f04b5bedad7b281bee9814686bba1762bae092eb">https://github.com/yt-dlp/yt-dlp/commit/f04b5bedad7b281bee9814686bba1762bae092eb</a></li>
</ul>
<h3 id="references-1">References</h3>
<ul>
<li><a href="https://github.com/yt-dlp/yt-dlp/security/advisories/GHSA-3ch3-jhc6-5r8x">https://github.com/yt-dlp/yt-dlp/security/advisories/GHSA-3ch3-jhc6-5r8x</a></li>
<li><a href="https://nvd.nist.gov/vuln/detail/CVE-2023-46121">https://nvd.nist.gov/vuln/detail/CVE-2023-46121</a></li>
<li><a href="https://github.com/yt-dlp/yt-dlp/commit/f04b5bedad7b281bee9814686bba1762bae092eb">https://github.com/yt-dlp/yt-dlp/commit/f04b5bedad7b281bee9814686bba1762bae092eb</a></li>
<li><a href="https://github.com/yt-dlp/yt-dlp/releases/tag/2023.11.14">https://github.com/yt-dlp/yt-dlp/releases/tag/2023.11.14</a></li>
<li><a href="https://github.com/advisories/GHSA-3ch3-jhc6-5r8x">https://github.com/advisories/GHSA-3ch3-jhc6-5r8x</a></li>
</ul>
]]></content>
        <author>
            <name>GitHub</name>
            <email>GitHub@noreply.github.com</email>
            <uri>https://github.com/advisories/GHSA-3ch3-jhc6-5r8x</uri>
        </author>
        <category label="severity" term="MODERATE"/>
        <published>2023-11-15T14:48:24.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[[vantage6-server] vantage6-server node accepts non-whitelisted algorithms from malicious server]]></title>
        <id>https://github.com/advisories/GHSA-vc3v-ppc7-v486</id>
        <link href="https://github.com/advisories/GHSA-vc3v-ppc7-v486"/>
        <updated>2023-11-14T22:21:58.000Z</updated>
        <content type="html"><![CDATA[<h3 id="impact">Impact</h3>
<p>A node does not check if an image is allowed to run if a <code>parent_id</code> is set. A malicious party that breaches the server may modify it to set a fake <code>parent_id</code> and send a task of a non-whitelisted algorithm. The node will then execute it because the <code>parent_id</code> that is set prevents checks from being run. Relevant node code <a href="https://github.com/vantage6/vantage6/blob/version/4.1.1/vantage6-node/vantage6/node/docker/docker_manager.py#L265-L268">here</a></p>
<p>This impacts all servers that are breached by an expert user</p>
<h3 id="patches">Patches</h3>
<p>Fixed in v4.1.2</p>
<h3 id="workarounds">Workarounds</h3>
<p>None</p>
<h3 id="references">References</h3>
<ul>
<li><a href="https://github.com/vantage6/vantage6/security/advisories/GHSA-vc3v-ppc7-v486">https://github.com/vantage6/vantage6/security/advisories/GHSA-vc3v-ppc7-v486</a></li>
<li><a href="https://nvd.nist.gov/vuln/detail/CVE-2023-47631">https://nvd.nist.gov/vuln/detail/CVE-2023-47631</a></li>
<li><a href="https://github.com/vantage6/vantage6/commit/bf83521eb12fa80aa5fc92ef1692010a9a7f8243">https://github.com/vantage6/vantage6/commit/bf83521eb12fa80aa5fc92ef1692010a9a7f8243</a></li>
<li><a href="https://github.com/vantage6/vantage6/blob/version/4.1.1/vantage6-node/vantage6/node/docker/docker_manager.py#L265-L268">https://github.com/vantage6/vantage6/blob/version/4.1.1/vantage6-node/vantage6/node/docker/docker_manager.py#L265-L268</a></li>
<li><a href="https://github.com/advisories/GHSA-vc3v-ppc7-v486">https://github.com/advisories/GHSA-vc3v-ppc7-v486</a></li>
</ul>
]]></content>
        <author>
            <name>GitHub</name>
            <email>GitHub@noreply.github.com</email>
            <uri>https://github.com/advisories/GHSA-vc3v-ppc7-v486</uri>
        </author>
        <category label="severity" term="HIGH"/>
        <published>2023-11-14T22:21:57.000Z</published>
    </entry>
    <entry>
        <title type="html"><![CDATA[[aiohttp] AIOHTTP has problems in HTTP parser (the python one, not llhttp)]]></title>
        <id>https://github.com/advisories/GHSA-gfw2-4jvh-wgfg</id>
        <link href="https://github.com/advisories/GHSA-gfw2-4jvh-wgfg"/>
        <updated>2023-11-14T22:21:00.000Z</updated>
        <content type="html"><![CDATA[<h1 id="summary">Summary</h1>
<p>The HTTP parser in AIOHTTP has numerous problems with header parsing, which could lead to request smuggling.
This parser is only used when <code>AIOHTTP_NO_EXTENSIONS</code> is enabled (or not using a prebuilt wheel).</p>
<h1 id="details">Details</h1>
<h2 id="bug-1-bad-parsing-of-content-length-values">Bug 1: Bad parsing of <code>Content-Length</code> values</h2>
<h3 id="description">Description</h3>
<p>RFC 9110 says this:</p>
<blockquote>
<p><code>Content-Length = 1*DIGIT</code></p>
</blockquote>
<p>AIOHTTP does not enforce this rule, presumably because of an incorrect usage of the builtin <code>int</code> constructor. Because the <code>int</code> constructor accepts <code>+</code> and <code>-</code> prefixes, and digit-separating underscores, using <code>int</code> to parse CL values leads AIOHTTP to significant misinterpretation.</p>
<h3 id="examples">Examples</h3>
<pre><code>GET / HTTP/1.1\r\n
Content-Length: -0\r\n
\r\n
X
</code></pre>
<pre><code>GET / HTTP/1.1\r\n
Content-Length: +0_1\r\n
\r\n
X
</code></pre>
<h3 id="suggested-action">Suggested action</h3>
<p>Verify that a <code>Content-Length</code> value consists only of ASCII digits before parsing, as the standard requires.</p>
<h2 id="bug-2-improper-handling-of-nul-cr-and-lf-in-header-values">Bug 2: Improper handling of NUL, CR, and LF in header values</h2>
<h3 id="description-1">Description</h3>
<p>RFC 9110 says this:</p>
<blockquote>
<p>Field values containing CR, LF, or NUL characters are invalid and dangerous, due to the varying ways that implementations might parse and interpret those characters; a recipient of CR, LF, or NUL within a field value MUST either reject the message or replace each of those characters with SP before further processing or forwarding of that message.</p>
</blockquote>
<p>AIOHTTP's HTTP parser does not enforce this rule, and will happily process header values containing these three forbidden characters without replacing them with SP.</p>
<h3 id="examples-1">Examples</h3>
<pre><code>GET / HTTP/1.1\r\n
Header: v\x00alue\r\n
\r\n
</code></pre>
<pre><code>GET / HTTP/1.1\r\n
Header: v\ralue\r\n
\r\n
</code></pre>
<pre><code>GET / HTTP/1.1\r\n
Header: v\nalue\r\n
\r\n
</code></pre>
<h3 id="suggested-action-1">Suggested action</h3>
<p>Reject all messages with NUL, CR, or LF in a header value. The translation to space thing, while technically allowed, does not seem like a good idea to me.</p>
<h2 id="bug-3-improper-stripping-of-whitespace-before-colon-in-http-headers">Bug 3: Improper stripping of whitespace before colon in HTTP headers</h2>
<h3 id="description-2">Description</h3>
<p>RFC 9112 says this:</p>
<blockquote>
<p>No whitespace is allowed between the field name and colon. In the past, differences in the handling of such whitespace have led to security vulnerabilities in request routing and response handling. A server MUST reject, with a response status code of 400 (Bad Request), any received request message that contains whitespace between a header field name and colon.</p>
</blockquote>
<p>AIOHTTP does not enforce this rule, and will simply strip any whitespace before the colon in an HTTP header.</p>
<h3 id="example">Example</h3>
<pre><code>GET / HTTP/1.1\r\n
Content-Length : 1\r\n
\r\n
X
</code></pre>
<h3 id="suggested-action-2">Suggested action</h3>
<p>Reject all messages with whitespace before a colon in a header field, as the standard requires.</p>
<h1 id="poc">PoC</h1>
<p>Example requests are embedded in the previous section. To reproduce these bugs, start an AIOHTTP server without llhttp (i.e. <code>AIOHTTP_NO_EXTENSIONS=1</code>) and send the requests given in the previous section. (e.g. by <code>printf</code>ing into <code>nc</code>)</p>
<h1 id="impact">Impact</h1>
<p>Each of these bugs can be used for request smuggling.</p>
<h3 id="references">References</h3>
<ul>
<li><a href="https://github.com/aio-libs/aiohttp/security/advisories/GHSA-gfw2-4jvh-wgfg">https://github.com/aio-libs/aiohttp/security/advisories/GHSA-gfw2-4jvh-wgfg</a></li>
<li><a href="https://nvd.nist.gov/vuln/detail/CVE-2023-47627">https://nvd.nist.gov/vuln/detail/CVE-2023-47627</a></li>
<li><a href="https://github.com/aio-libs/aiohttp/commit/d5c12ba890557a575c313bb3017910d7616fce3d">https://github.com/aio-libs/aiohttp/commit/d5c12ba890557a575c313bb3017910d7616fce3d</a></li>
<li><a href="https://github.com/aio-libs/aiohttp/releases/tag/v3.8.6">https://github.com/aio-libs/aiohttp/releases/tag/v3.8.6</a></li>
<li><a href="https://github.com/advisories/GHSA-gfw2-4jvh-wgfg">https://github.com/advisories/GHSA-gfw2-4jvh-wgfg</a></li>
</ul>
]]></content>
        <author>
            <name>GitHub</name>
            <email>GitHub@noreply.github.com</email>
            <uri>https://github.com/advisories/GHSA-gfw2-4jvh-wgfg</uri>
        </author>
        <category label="severity" term="MODERATE"/>
        <published>2023-11-14T22:20:59.000Z</published>
    </entry>
</feed>